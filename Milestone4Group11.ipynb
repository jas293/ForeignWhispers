{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4da96864fcda454286a86716b9c929f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c8e8722184ed4c7fba35e23cb13ef287",
              "IPY_MODEL_1fb95ec203da484bbd271e561c13c6ba",
              "IPY_MODEL_b7ac34252200484ab1510a94ca4972ec"
            ],
            "layout": "IPY_MODEL_287bee8eb7cc43d39ade128986457fd2"
          }
        },
        "c8e8722184ed4c7fba35e23cb13ef287": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab0c7b82ec1943bcad7423b3ea7f953d",
            "placeholder": "​",
            "style": "IPY_MODEL_0486051bd18942f09559170bd1d6d41a",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1fb95ec203da484bbd271e561c13c6ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96a350955bc84f7aa09436269b684f18",
            "max": 44,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bfbb97c9b00944f3a10de016775239ab",
            "value": 44
          }
        },
        "b7ac34252200484ab1510a94ca4972ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fab2ac9fafba40c385544ce3fd872362",
            "placeholder": "​",
            "style": "IPY_MODEL_0b69ecee48174aa69e3ff5030e12f5a5",
            "value": " 44.0/44.0 [00:00&lt;00:00, 2.11kB/s]"
          }
        },
        "287bee8eb7cc43d39ade128986457fd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab0c7b82ec1943bcad7423b3ea7f953d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0486051bd18942f09559170bd1d6d41a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96a350955bc84f7aa09436269b684f18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfbb97c9b00944f3a10de016775239ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fab2ac9fafba40c385544ce3fd872362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b69ecee48174aa69e3ff5030e12f5a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1abecce6fea4493283b65af85262497b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_479d7e2d083a492989f40b872359905e",
              "IPY_MODEL_e820ef3380204ffabc6570ad7cad032f",
              "IPY_MODEL_395bf8b9c52e4e5cbadb2adfa8b5228e"
            ],
            "layout": "IPY_MODEL_4e71504d51a140ab9d3609e0a129045c"
          }
        },
        "479d7e2d083a492989f40b872359905e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6cc153be4a15467ab868010eafb83a78",
            "placeholder": "​",
            "style": "IPY_MODEL_bb64e1f245b94382b6d9c52f243f9f36",
            "value": "source.spm: 100%"
          }
        },
        "e820ef3380204ffabc6570ad7cad032f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ea42e403e2a4255aa0ebbf6006d1a1f",
            "max": 801636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45ca3f0d38924c61ab88a3d9e2d8a62e",
            "value": 801636
          }
        },
        "395bf8b9c52e4e5cbadb2adfa8b5228e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_091ee00302474b5cb91a722e7db8b2df",
            "placeholder": "​",
            "style": "IPY_MODEL_c682021f8750498caafd1524c90dec0e",
            "value": " 802k/802k [00:00&lt;00:00, 1.02MB/s]"
          }
        },
        "4e71504d51a140ab9d3609e0a129045c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cc153be4a15467ab868010eafb83a78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb64e1f245b94382b6d9c52f243f9f36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ea42e403e2a4255aa0ebbf6006d1a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45ca3f0d38924c61ab88a3d9e2d8a62e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "091ee00302474b5cb91a722e7db8b2df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c682021f8750498caafd1524c90dec0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d37582065bbe44f0bf0a0f68bb1c204f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9440ce10403f4c8ca8a6ac70fa467a5a",
              "IPY_MODEL_ae67c56428944a7faab0e3a54aefc6a0",
              "IPY_MODEL_c9f1601eae094848a0e4bf8574a9f4fc"
            ],
            "layout": "IPY_MODEL_85a2c0a1a7d345c28ae8ecdb8235c151"
          }
        },
        "9440ce10403f4c8ca8a6ac70fa467a5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e2363caaa1e4b53a53ad9f19989b3fd",
            "placeholder": "​",
            "style": "IPY_MODEL_7eff89d854884a8f9a8857f4652e9df9",
            "value": "target.spm: 100%"
          }
        },
        "ae67c56428944a7faab0e3a54aefc6a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b267f39b073e41298b25dbc390c049ec",
            "max": 825924,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c531ee5a04844c46a676429aa23bd1e3",
            "value": 825924
          }
        },
        "c9f1601eae094848a0e4bf8574a9f4fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f41a44c3cef94ef588b15ff293e6065d",
            "placeholder": "​",
            "style": "IPY_MODEL_87418997ae184d7e8b0619e9a9707e84",
            "value": " 826k/826k [00:00&lt;00:00, 1.06MB/s]"
          }
        },
        "85a2c0a1a7d345c28ae8ecdb8235c151": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e2363caaa1e4b53a53ad9f19989b3fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7eff89d854884a8f9a8857f4652e9df9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b267f39b073e41298b25dbc390c049ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c531ee5a04844c46a676429aa23bd1e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f41a44c3cef94ef588b15ff293e6065d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87418997ae184d7e8b0619e9a9707e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1bd5c2e51b2144a0bb4683389dd3cd33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d88bac91b2544e5a97fe8b346ddc5395",
              "IPY_MODEL_48d055827c224cb9ac2a9ff611030819",
              "IPY_MODEL_b9ced05c255543a4ae0521240029e912"
            ],
            "layout": "IPY_MODEL_d0ea945b979447bba50e3ed4d4ce64fb"
          }
        },
        "d88bac91b2544e5a97fe8b346ddc5395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a63cf8e7e17343a6a6fde5b084ea6d86",
            "placeholder": "​",
            "style": "IPY_MODEL_c92905648d534464894950a456503cfa",
            "value": "vocab.json: 100%"
          }
        },
        "48d055827c224cb9ac2a9ff611030819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fa5d0e68c4e434ab68a8064c0058943",
            "max": 1590040,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45ce4f11815b41bc84058208ddc883bc",
            "value": 1590040
          }
        },
        "b9ced05c255543a4ae0521240029e912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b9e61a5ee8d4c0a80ec337cd676de93",
            "placeholder": "​",
            "style": "IPY_MODEL_67f9ec5572f248f3941dc54baa6cd8fa",
            "value": " 1.59M/1.59M [00:00&lt;00:00, 1.64MB/s]"
          }
        },
        "d0ea945b979447bba50e3ed4d4ce64fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a63cf8e7e17343a6a6fde5b084ea6d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c92905648d534464894950a456503cfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4fa5d0e68c4e434ab68a8064c0058943": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "45ce4f11815b41bc84058208ddc883bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9b9e61a5ee8d4c0a80ec337cd676de93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67f9ec5572f248f3941dc54baa6cd8fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "46a43b51fcb248c5bd22959dd1ae5a2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d32204dae9945838fb89011ec335f84",
              "IPY_MODEL_c3a0df171c9b4f8c84e11a0fd63e128f",
              "IPY_MODEL_fdbe12a08ab64d35802bb200a5e259e3"
            ],
            "layout": "IPY_MODEL_78d10be74d4e43d3b4e90f48db9ebf3f"
          }
        },
        "6d32204dae9945838fb89011ec335f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7345f36e6d9f4df998e1a845733d932e",
            "placeholder": "​",
            "style": "IPY_MODEL_25a04206e9a74ddcbecb14b2731f372d",
            "value": "config.json: 100%"
          }
        },
        "c3a0df171c9b4f8c84e11a0fd63e128f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7127aefef6bc421e94c774a6682277a2",
            "max": 1473,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_be8d55fb147749bdb96f80878497fb86",
            "value": 1473
          }
        },
        "fdbe12a08ab64d35802bb200a5e259e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_743730f40b2942f09d1cbdfe6ccd3407",
            "placeholder": "​",
            "style": "IPY_MODEL_232c535ebe9b4fde831a4f41694c7ce2",
            "value": " 1.47k/1.47k [00:00&lt;00:00, 57.6kB/s]"
          }
        },
        "78d10be74d4e43d3b4e90f48db9ebf3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7345f36e6d9f4df998e1a845733d932e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25a04206e9a74ddcbecb14b2731f372d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7127aefef6bc421e94c774a6682277a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be8d55fb147749bdb96f80878497fb86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "743730f40b2942f09d1cbdfe6ccd3407": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "232c535ebe9b4fde831a4f41694c7ce2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06ced31d97144cc9a3b47059eb1a92a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ff6ca319e154f2498a5d586a8ca5893",
              "IPY_MODEL_fe9069503ca24587881cfd22070615bf",
              "IPY_MODEL_1e7c89593dd64d7396d7b01e29427a24"
            ],
            "layout": "IPY_MODEL_a8a21b238c0a42c6be2aba38665aeb3c"
          }
        },
        "9ff6ca319e154f2498a5d586a8ca5893": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47f1de607d864cd1a69f902f83ce12c2",
            "placeholder": "​",
            "style": "IPY_MODEL_80f0a61750fd44a793c3330532987d95",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "fe9069503ca24587881cfd22070615bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc7cd422b71a4fc6a39e558f82ce8d00",
            "max": 312087523,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c24f1cffb1de4d40a99e084e8f6cf1f6",
            "value": 312087523
          }
        },
        "1e7c89593dd64d7396d7b01e29427a24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f939d55e2c54f60a481fdd774a66632",
            "placeholder": "​",
            "style": "IPY_MODEL_43660bafd4e64089b9b418ebfc8f404a",
            "value": " 312M/312M [00:16&lt;00:00, 20.3MB/s]"
          }
        },
        "a8a21b238c0a42c6be2aba38665aeb3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47f1de607d864cd1a69f902f83ce12c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f0a61750fd44a793c3330532987d95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc7cd422b71a4fc6a39e558f82ce8d00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c24f1cffb1de4d40a99e084e8f6cf1f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f939d55e2c54f60a481fdd774a66632": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43660bafd4e64089b9b418ebfc8f404a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bdd39fe99b4a4e4dbbd84e5448dda722": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c963bcafa31427ab5a7ffdeb53e3c19",
              "IPY_MODEL_66a170400d1643da9922b96c5f9334cf",
              "IPY_MODEL_4cecc4e65c6e4baa812216301b6ae6dc"
            ],
            "layout": "IPY_MODEL_1f9dd784b23a4f0cba6fcad7da64a2ad"
          }
        },
        "7c963bcafa31427ab5a7ffdeb53e3c19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5311f61f01494e209fc5cfce46f9a5ba",
            "placeholder": "​",
            "style": "IPY_MODEL_93e0c69f27fb479d9729e10b2d260a48",
            "value": "generation_config.json: 100%"
          }
        },
        "66a170400d1643da9922b96c5f9334cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ae6c325d94e4476a524bf8a2acba142",
            "max": 293,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_64dca70eda5648f5ba13c1eede77148e",
            "value": 293
          }
        },
        "4cecc4e65c6e4baa812216301b6ae6dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_699e8fd737214c9a89ee82c4f962ee84",
            "placeholder": "​",
            "style": "IPY_MODEL_fedb97e5b004420da2fbfa33e6b283c5",
            "value": " 293/293 [00:00&lt;00:00, 20.3kB/s]"
          }
        },
        "1f9dd784b23a4f0cba6fcad7da64a2ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5311f61f01494e209fc5cfce46f9a5ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93e0c69f27fb479d9729e10b2d260a48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ae6c325d94e4476a524bf8a2acba142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64dca70eda5648f5ba13c1eede77148e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "699e8fd737214c9a89ee82c4f962ee84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fedb97e5b004420da2fbfa33e6b283c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Milestone 2 Group 11\n",
        "\n",
        "Collaborators: Jill Shah & Dhruvik Patel"
      ],
      "metadata": {
        "id": "cYtI92Tu2OIV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pytube\n",
        "%pip install youtube_transcript_api"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KivGUaZGZ2Eb",
        "outputId": "903e46ec-fb4d-424a-da3a-79d09536cc43"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytube\n",
            "  Downloading pytube-15.0.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-15.0.0\n",
            "Collecting youtube_transcript_api\n",
            "  Downloading youtube_transcript_api-0.6.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.7.22)\n",
            "Installing collected packages: youtube_transcript_api\n",
            "Successfully installed youtube_transcript_api-0.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from pytube import Playlist, YouTube\n",
        "from pytube.exceptions import AgeRestrictedError\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "\n",
        "def download_playlist(playlist_url, resolution):\n",
        "  playlist = Playlist(playlist_url)\n",
        "  playlist_name = re.sub(r'\\W+', '-', playlist.title)\n",
        "\n",
        "  if not os.path.exists(playlist_name):\n",
        "    os.mkdir(playlist_name)\n",
        "    for index, v in enumerate(playlist.videos[:10], start=1):\n",
        "      try:\n",
        "        video = YouTube(v.watch_url)\n",
        "        video_resolution = video.streams.filter(res=resolution).first()\n",
        "        video_filename = f\"{index}. {video_resolution.default_filename}\"\n",
        "        video_path = os.path.join(playlist_name, video_filename)\n",
        "        video_streams = video.streams.filter(res=resolution)\n",
        "\n",
        "        if not video_streams:\n",
        "          highest_resolution_stream = video.streams.get_highest_resolution()\n",
        "          video_name = highest_resolution_stream.default_filename\n",
        "          print(\n",
        "              f\"Downloading {video_name} in {highest_resolution_stream.resolution}\")\n",
        "          highest_resolution_stream.download(filename=video_path)\n",
        "\n",
        "\n",
        "        else:\n",
        "          video_stream = video_streams.first()\n",
        "          video_name = video_stream.default_filename\n",
        "          print(\n",
        "              f\"Downloading video for {video_name} in {resolution}\")\n",
        "          video_stream.download(filename=\"video.mp4\")\n",
        "\n",
        "\n",
        "          audio_stream = video.streams.get_audio_only()\n",
        "          print(\n",
        "              f\"Downloading audio for {video_name}\")\n",
        "          audio_stream.download(filename=\"audio.mp4\")\n",
        "          os.system(\n",
        "              \"ffmpeg -y -i video.mp4 -i audio.mp4 -c:v copy -c:a aac final.mp4 -loglevel quiet -stats\")\n",
        "          os.rename(\"final.mp4\", video_path)\n",
        "          os.remove(\"video.mp4\")\n",
        "          os.remove(\"audio.mp4\")\n",
        "\n",
        "          srt = YouTubeTranscriptApi.get_transcript(video.video_id)\n",
        "          caption_file = f\"{video_path}.srt\"\n",
        "          with open(caption_file, 'w') as f:\n",
        "            for line in srt:\n",
        "              end=line[\"start\"]+line[\"duration\"]\n",
        "              f.write(str(line[\"start\"]) + \" -- \" + str(end) + \"\\n\")\n",
        "              f.write(line[\"text\"] + \"\\n\")\n",
        "\n",
        "      except AgeRestrictedError:\n",
        "                print(f\"Video {v.title} is age-restricted and has been skipped.\")\n",
        "                continue\n",
        "\n",
        "\n",
        "playlist_url = \"https://www.youtube.com/playlist?list=PLI1yx5Z0Lrv77D_g1tvF9u3FVqnrNbCRL\"\n",
        "resolution = \"720p\"\n",
        "download_playlist(playlist_url, resolution)"
      ],
      "metadata": {
        "id": "NUPOtPKKZwMc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fc3b609-41ee-4d73-dd38-51ff3e2e368e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading video for Vice President Kamala Harris The 2023 60 Minutes Interview.mp4 in 720p\n",
            "Downloading audio for Vice President Kamala Harris The 2023 60 Minutes Interview.mp4\n",
            "Downloading video for Pink The 60 Minutes Interview.mp4 in 720p\n",
            "Downloading audio for Pink The 60 Minutes Interview.mp4\n",
            "Video President Joe Biden: The 2023 60 Minutes Interview is age-restricted and has been skipped.\n",
            "Downloading video for Rich Paul The 60 Minutes Interview.mp4 in 720p\n",
            "Downloading audio for Rich Paul The 60 Minutes Interview.mp4\n",
            "Downloading video for Godfather of AI Geoffrey Hinton The 60 Minutes Interview.mp4 in 720p\n",
            "Downloading audio for Godfather of AI Geoffrey Hinton The 60 Minutes Interview.mp4\n",
            "Downloading video for Gen Mark Milley The 60 Minutes Interview.mp4 in 720p\n",
            "Downloading audio for Gen Mark Milley The 60 Minutes Interview.mp4\n",
            "Downloading video for Attorney General Merrick Garland The 60 Minutes Interview.mp4 in 720p\n",
            "Downloading audio for Attorney General Merrick Garland The 60 Minutes Interview.mp4\n",
            "Downloading video for Deion Sanders The 2023 60 Minutes Interview.mp4 in 720p\n",
            "Downloading audio for Deion Sanders The 2023 60 Minutes Interview.mp4\n",
            "Downloading video for Volodymyr Zelenskyy The 2023 60 Minutes Interview.mp4 in 720p\n",
            "Downloading audio for Volodymyr Zelenskyy The 2023 60 Minutes Interview.mp4\n",
            "Downloading video for Denzel Washington  60 Minutes Archive.mp4 in 720p\n",
            "Downloading audio for Denzel Washington  60 Minutes Archive.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install moviepy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bVY6q7Y8DSM",
        "outputId": "2b833f87-bfe5-4831-a059-0bcb57acd792"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (1.0.3)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.10/dist-packages (from moviepy) (4.66.1)\n",
            "Requirement already satisfied: requests<3.0,>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.0)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.1.10)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from moviepy) (1.23.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy) (0.4.9)\n",
            "Requirement already satisfied: pillow<10.1.0,>=8.3.2 in /usr/local/lib/python3.10/dist-packages (from imageio<3.0,>=2.5->moviepy) (9.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from imageio-ffmpeg>=0.2.0->moviepy) (67.7.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.8.1->moviepy) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mkdir audio"
      ],
      "metadata": {
        "id": "LVamlIb0Bulb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from moviepy.editor import *\n",
        "\n",
        "# Directory containing your videos\n",
        "video_dir = '/content/Interviews'\n",
        "# Directory to save audio files\n",
        "audio_dir = '/content/audio'\n",
        "\n",
        "# Ensure the audio directory exists\n",
        "os.makedirs(audio_dir, exist_ok=True)\n",
        "\n",
        "def process_video(video_path):\n",
        "    # Load the video file\n",
        "    video = VideoFileClip(video_path)\n",
        "\n",
        "    # Get the audio from the video\n",
        "    audio = video.audio\n",
        "\n",
        "    # Build the audio file path\n",
        "    audio_file_name = os.path.basename(video_path).replace('.mp4', '.mp3')\n",
        "    audio_file_path = os.path.join(audio_dir, audio_file_name)\n",
        "\n",
        "    # Write the audio to file\n",
        "    audio.write_audiofile(audio_file_path)\n",
        "\n",
        "# Get all video files in the video directory\n",
        "video_files = [f for f in os.listdir(video_dir) if f.endswith('.mp4')]\n",
        "\n",
        "# Process each video file\n",
        "for video_file in video_files:\n",
        "    video_path = os.path.join(video_dir, video_file)\n",
        "    process_video(video_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sjjd7cpk88xe",
        "outputId": "6f002838-5f24-4b0c-a854-2dd48bc9d8dd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Writing audio in /content/audio/9. Volodymyr Zelenskyy The 2023 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/audio/10. Denzel Washington  60 Minutes Archive.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/audio/1. Vice President Kamala Harris The 2023 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/audio/5. Godfather of AI Geoffrey Hinton The 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/audio/4. Rich Paul The 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/audio/6. Gen Mark Milley The 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/audio/2. Pink The 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/audio/7. Attorney General Merrick Garland The 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/audio/8. Deion Sanders The 2023 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install git+https://github.com/openai/whisper.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dAR7zlZ9L8pC",
        "outputId": "ee58dffc-a078-434e-d5da-9f5ae6af6d0a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-5rfi7lro\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-5rfi7lro\n",
            "  Resolved https://github.com/openai/whisper.git to commit e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231117)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=801356 sha256=d73d2152b029cf61ab36842c4f73316a22b3e467570f3f18efc8457a46c520db\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1qxbbf8y/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231117 tiktoken-0.5.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "import os\n",
        "\n",
        "def convert_audio_to_text_whisper_and_save(audio_directory):\n",
        "    \"\"\"\n",
        "    This function will take the directory containing audio files, load each audio file,\n",
        "    run Whisper's speech recognition on it, and save the transcribed text into a text file\n",
        "    with the same name as the audio file in the same directory.\n",
        "    \"\"\"\n",
        "    # Initialize the model\n",
        "    model = whisper.load_model(\"base.en\")\n",
        "\n",
        "    # List all the audio files in the directory\n",
        "    audio_files = [f for f in os.listdir(audio_directory) if f.endswith('.mp3')]\n",
        "\n",
        "    # Process each audio file\n",
        "    for audio_file in audio_files:\n",
        "        audio_path = os.path.join(audio_directory, audio_file)\n",
        "        # Load the audio file\n",
        "        result = model.transcribe(audio_path)\n",
        "        # Build the text file path\n",
        "        text_file_path = audio_path.replace('.mp3', '.txt')\n",
        "        # Write the transcription to the text file\n",
        "        with open(text_file_path, 'w') as text_file:\n",
        "            text_file.write(result['text'])\n",
        "\n",
        "convert_audio_to_text_whisper_and_save('/content/audio')"
      ],
      "metadata": {
        "id": "c1Nl5LrqM0LN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173df6e7-b166-4b80-a07e-937433f3bef2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:11<00:00, 12.7MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install pytube\n",
        "%pip install youtube_transcript_api\n",
        "%pip install git+https://github.com/openai/whisper.git\n",
        "%pip install sacremoses\n",
        "%pip install sentencepiece\n",
        "%pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "um6aYncfYQ-O",
        "outputId": "ba43b980-3274-47f7-8d62-a6c99601791f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytube in /usr/local/lib/python3.10/dist-packages (15.0.0)\n",
            "Requirement already satisfied: youtube_transcript_api in /usr/local/lib/python3.10/dist-packages (0.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from youtube_transcript_api) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->youtube_transcript_api) (2023.7.22)\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-t3u1foby\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-t3u1foby\n",
            "  Resolved https://github.com/openai/whisper.git to commit e58f28804528831904c3b6f2c0e473f346223433\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacremoses) (2023.6.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from sacremoses) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from sacremoses) (1.3.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sacremoses) (4.66.1)\n",
            "Installing collected packages: sacremoses\n",
            "Successfully installed sacremoses-0.1.1\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import whisper\n",
        "import difflib\n",
        "from pytube import Playlist\n",
        "from moviepy.editor import *\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "\n",
        "def convert(seconds):\n",
        "    seconds = seconds % 3600\n",
        "    minutes = seconds / 60\n",
        "    seconds %= 60\n",
        "    return \"%02d:%02d\" % (minutes, seconds)\n",
        "\n",
        "def download_video_and_transcript(link):\n",
        "    # Loadig the playlist from the link\n",
        "    playlist = Playlist(link)\n",
        "\n",
        "    # Getting the name of the playlist\n",
        "    playlist_name = re.sub(r'\\W+', '-', playlist.title)\n",
        "\n",
        "    # Making the directory to store the files\n",
        "    if not os.path.exists(playlist_name):\n",
        "        os.mkdir(playlist_name)\n",
        "\n",
        "    # Making the directory to store the videos\n",
        "    if not os.path.exists(f\"{playlist_name}/video\"):\n",
        "        os.mkdir(f\"{playlist_name}/video\")\n",
        "\n",
        "    # Making the directory to store the closed captions\n",
        "    if not os.path.exists(f\"{playlist_name}/caption\"):\n",
        "        os.mkdir(f\"{playlist_name}/caption\")\n",
        "\n",
        "    # Loop to get the videos from the playlist\n",
        "    for video in playlist.videos[:10]:\n",
        "        # Skipping the age restricted videos\n",
        "        if video.age_restricted:\n",
        "            continue\n",
        "\n",
        "        # Getting the video stream\n",
        "        video_stream = video.streams.get_highest_resolution()\n",
        "\n",
        "        # Getting the video name\n",
        "        video_name = video_stream.default_filename\n",
        "\n",
        "        # Downloading the video\n",
        "        video_stream.download(output_path=f\"{playlist_name}/video\", filename=video_name)\n",
        "\n",
        "        # Getting the video name without \".mp4\" extension\n",
        "        video_name = os.path.splitext(video_name)[0]\n",
        "\n",
        "        # Getting the closed captions\n",
        "        txt = YouTubeTranscriptApi.get_transcript(video.video_id)\n",
        "\n",
        "        # Writing the closed captions into txt file\n",
        "        with open(f\"Interviews/caption/{video_name}.txt\", 'w') as file:\n",
        "            for line in txt:\n",
        "                file.write(convert(line[\"start\"]) + \"\\n\")\n",
        "                file.write(line[\"text\"] + \"\\n\")\n",
        "\n",
        "download_video_and_transcript('https://www.youtube.com/playlist?list=PLI1yx5Z0Lrv77D_g1tvF9u3FVqnrNbCRL')\n",
        "\n",
        "def extract_audio(video_path, audio_path):\n",
        "    # Load the video file\n",
        "    video = VideoFileClip(video_path)\n",
        "\n",
        "    # Get the audio from the video\n",
        "    audio = video.audio\n",
        "\n",
        "    # Write the audio to file\n",
        "    audio.write_audiofile(audio_path)\n",
        "\n",
        "folder_name = \"/content/Interviews\"\n",
        "\n",
        "# Making the directory to store the audios\n",
        "if not os.path.exists(f\"{folder_name}/audio\"):\n",
        "    os.mkdir(f\"{folder_name}/audio\")\n",
        "\n",
        "# Getting all video files in the video directory\n",
        "video_files = [f for f in os.listdir(f\"{folder_name}/video\") if f.endswith('.mp4')]\n",
        "\n",
        "# Loop to get the videos from the directory\n",
        "for video_file in video_files:\n",
        "    # Making the path for video\n",
        "    video_path = os.path.join(f\"{folder_name}/video\", video_file)\n",
        "\n",
        "    # Making the path for audio\n",
        "    audio_file = os.path.basename(video_path).replace('.mp4', '.mp3')\n",
        "    audio_path = os.path.join(f\"{folder_name}/audio\", audio_file)\n",
        "\n",
        "    # Calling the function\n",
        "    extract_audio(video_path, audio_path)\n",
        "\n",
        "def convert_audio_to_text(audio_directory):\n",
        "    # Loading the Whisper model\n",
        "    model = whisper.load_model(\"base.en\")\n",
        "\n",
        "    # Getting all the audio files from the directory\n",
        "    audio_files = [f for f in os.listdir(audio_directory) if f.endswith('.mp3')]\n",
        "\n",
        "    # Loop to get all the audios\n",
        "    for audio_file in audio_files:\n",
        "        # Making the path for audio\n",
        "        audio_path = os.path.join(audio_directory, audio_file)\n",
        "\n",
        "        # Transcribe the audio\n",
        "        result = model.transcribe(audio_path)\n",
        "\n",
        "        # Making the path for txt file\n",
        "        text_file_path = audio_path.replace('.mp3', '.txt')\n",
        "        text_file_path = text_file_path.replace('audio', 'transcript')\n",
        "\n",
        "        # Writing the transcripts into txt file\n",
        "        with open(text_file_path, 'w') as text_file:\n",
        "            text_file.write(result['text'])\n",
        "\n",
        "# Making the directory to store the audios\n",
        "if not os.path.exists(f\"{folder_name}/transcript\"):\n",
        "    os.mkdir(f\"{folder_name}/transcript\")\n",
        "\n",
        "# Calling the function to transcribe\n",
        "convert_audio_to_text(f\"{folder_name}/audio\")\n",
        "\n",
        "def reformat(caption_path, transcript_path):\n",
        "    with open(caption_path, 'r') as caption_file:\n",
        "        caption_lines = caption_file.readlines()\n",
        "    with open(transcript_path, 'r') as transcript_file:\n",
        "        transcript_content = transcript_file.read()\n",
        "    transcript_content = transcript_content.strip()\n",
        "    matched_transcript = []\n",
        "    transcript_content = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|\\!)\\s', transcript_content)\n",
        "\n",
        "    i = 1\n",
        "    for line in transcript_content:\n",
        "        temp = \"\"\n",
        "        matched_transcript.append(caption_lines[i - 1][:-1])\n",
        "        matched_transcript.append(line)\n",
        "        temp = temp + caption_lines[i]\n",
        "        ratio = difflib.SequenceMatcher(None, line, temp).ratio()\n",
        "        prev = ratio\n",
        "        i = i + 2\n",
        "        while prev <= ratio and i < len(caption_lines):\n",
        "            prev = ratio\n",
        "            temp = temp + \" \" + caption_lines[i]\n",
        "            ratio = difflib.SequenceMatcher(None, line, temp).ratio()\n",
        "            i = i + 2\n",
        "        i = i - 2\n",
        "\n",
        "    with open(transcript_path, 'w') as output_file:\n",
        "        for line in matched_transcript:\n",
        "            output_file.write(line + '\\n')\n",
        "\n",
        "caption_files = [f for f in os.listdir(f\"{folder_name}/caption\") if f.endswith('.txt')]\n",
        "transcript_files = [f for f in os.listdir(f\"{folder_name}/transcript\") if f.endswith('.txt')]\n",
        "\n",
        "for caption_file, transcript_file in zip(caption_files, transcript_files):\n",
        "    caption_path = os.path.join(f\"{folder_name}/caption\", caption_file)\n",
        "    transcript_path = os.path.join(f\"{folder_name}/transcript\", transcript_file)\n",
        "\n",
        "    reformat(caption_path, transcript_path)\n",
        "\n",
        "from transformers import MarianMTModel, MarianTokenizer\n",
        "import torch\n",
        "\n",
        "# Load the model and tokenizer once\n",
        "model_name = \"Helsinki-NLP/opus-mt-en-es\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model = MarianMTModel.from_pretrained(model_name)\n",
        "\n",
        "def translate(text_path, translate_path, tokenizer, model):\n",
        "    with open(text_path, 'r') as text_file, open(translate_path, 'w') as translate_file:\n",
        "        for text in text_file:\n",
        "            # Process each line or a small batch of lines\n",
        "            inputs = tokenizer(text.strip(), return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "            translated = model.generate(**inputs)\n",
        "\n",
        "            # Decode and write the translation\n",
        "            translation = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "            translate_file.write(translation + '\\n')\n",
        "\n",
        "            # Clear memory cache (optional, can help in some scenarios)\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "# Usage\n",
        "#translate(text_path, translate_path, tokenizer, model)\n",
        "# Making the directory to store the translations\n",
        "if not os.path.exists(f\"{folder_name}/translated\"):\n",
        "    os.mkdir(f\"{folder_name}/translated\")\n",
        "\n",
        "# Getting all captions files in the audio directory\n",
        "text_files = [f for f in os.listdir(f\"{folder_name}/transcript\") if f.endswith('.txt')]\n",
        "\n",
        "# Loop to get the captions from the directory\n",
        "for text_file in text_files:\n",
        "    # Making the path for caption\n",
        "    text_path = os.path.join(f\"{folder_name}/transcript\", text_file)\n",
        "\n",
        "    # Making the path for translation\n",
        "    translate_path = os.path.join(f\"{folder_name}/translated\", text_file)\n",
        "\n",
        "    print(translate_path)\n",
        "\n",
        "    # Calling the function\n",
        "    translate(text_path, translate_path, tokenizer, model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729,
          "referenced_widgets": [
            "4da96864fcda454286a86716b9c929f0",
            "c8e8722184ed4c7fba35e23cb13ef287",
            "1fb95ec203da484bbd271e561c13c6ba",
            "b7ac34252200484ab1510a94ca4972ec",
            "287bee8eb7cc43d39ade128986457fd2",
            "ab0c7b82ec1943bcad7423b3ea7f953d",
            "0486051bd18942f09559170bd1d6d41a",
            "96a350955bc84f7aa09436269b684f18",
            "bfbb97c9b00944f3a10de016775239ab",
            "fab2ac9fafba40c385544ce3fd872362",
            "0b69ecee48174aa69e3ff5030e12f5a5",
            "1abecce6fea4493283b65af85262497b",
            "479d7e2d083a492989f40b872359905e",
            "e820ef3380204ffabc6570ad7cad032f",
            "395bf8b9c52e4e5cbadb2adfa8b5228e",
            "4e71504d51a140ab9d3609e0a129045c",
            "6cc153be4a15467ab868010eafb83a78",
            "bb64e1f245b94382b6d9c52f243f9f36",
            "5ea42e403e2a4255aa0ebbf6006d1a1f",
            "45ca3f0d38924c61ab88a3d9e2d8a62e",
            "091ee00302474b5cb91a722e7db8b2df",
            "c682021f8750498caafd1524c90dec0e",
            "d37582065bbe44f0bf0a0f68bb1c204f",
            "9440ce10403f4c8ca8a6ac70fa467a5a",
            "ae67c56428944a7faab0e3a54aefc6a0",
            "c9f1601eae094848a0e4bf8574a9f4fc",
            "85a2c0a1a7d345c28ae8ecdb8235c151",
            "3e2363caaa1e4b53a53ad9f19989b3fd",
            "7eff89d854884a8f9a8857f4652e9df9",
            "b267f39b073e41298b25dbc390c049ec",
            "c531ee5a04844c46a676429aa23bd1e3",
            "f41a44c3cef94ef588b15ff293e6065d",
            "87418997ae184d7e8b0619e9a9707e84",
            "1bd5c2e51b2144a0bb4683389dd3cd33",
            "d88bac91b2544e5a97fe8b346ddc5395",
            "48d055827c224cb9ac2a9ff611030819",
            "b9ced05c255543a4ae0521240029e912",
            "d0ea945b979447bba50e3ed4d4ce64fb",
            "a63cf8e7e17343a6a6fde5b084ea6d86",
            "c92905648d534464894950a456503cfa",
            "4fa5d0e68c4e434ab68a8064c0058943",
            "45ce4f11815b41bc84058208ddc883bc",
            "9b9e61a5ee8d4c0a80ec337cd676de93",
            "67f9ec5572f248f3941dc54baa6cd8fa",
            "46a43b51fcb248c5bd22959dd1ae5a2a",
            "6d32204dae9945838fb89011ec335f84",
            "c3a0df171c9b4f8c84e11a0fd63e128f",
            "fdbe12a08ab64d35802bb200a5e259e3",
            "78d10be74d4e43d3b4e90f48db9ebf3f",
            "7345f36e6d9f4df998e1a845733d932e",
            "25a04206e9a74ddcbecb14b2731f372d",
            "7127aefef6bc421e94c774a6682277a2",
            "be8d55fb147749bdb96f80878497fb86",
            "743730f40b2942f09d1cbdfe6ccd3407",
            "232c535ebe9b4fde831a4f41694c7ce2",
            "06ced31d97144cc9a3b47059eb1a92a3",
            "9ff6ca319e154f2498a5d586a8ca5893",
            "fe9069503ca24587881cfd22070615bf",
            "1e7c89593dd64d7396d7b01e29427a24",
            "a8a21b238c0a42c6be2aba38665aeb3c",
            "47f1de607d864cd1a69f902f83ce12c2",
            "80f0a61750fd44a793c3330532987d95",
            "fc7cd422b71a4fc6a39e558f82ce8d00",
            "c24f1cffb1de4d40a99e084e8f6cf1f6",
            "2f939d55e2c54f60a481fdd774a66632",
            "43660bafd4e64089b9b418ebfc8f404a",
            "bdd39fe99b4a4e4dbbd84e5448dda722",
            "7c963bcafa31427ab5a7ffdeb53e3c19",
            "66a170400d1643da9922b96c5f9334cf",
            "4cecc4e65c6e4baa812216301b6ae6dc",
            "1f9dd784b23a4f0cba6fcad7da64a2ad",
            "5311f61f01494e209fc5cfce46f9a5ba",
            "93e0c69f27fb479d9729e10b2d260a48",
            "3ae6c325d94e4476a524bf8a2acba142",
            "64dca70eda5648f5ba13c1eede77148e",
            "699e8fd737214c9a89ee82c4f962ee84",
            "fedb97e5b004420da2fbfa33e6b283c5"
          ]
        },
        "id": "SckV2EbaX4VT",
        "outputId": "8247d86a-15dc-4b03-f71b-c992407f358f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Writing audio in /content/Interviews/audio/Pink The 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/Interviews/audio/Denzel Washington  60 Minutes Archive.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/Interviews/audio/Volodymyr Zelenskyy The 2023 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/Interviews/audio/Vice President Kamala Harris The 2023 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/Interviews/audio/Rich Paul The 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/Interviews/audio/Godfather of AI Geoffrey Hinton The 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/Interviews/audio/Gen Mark Milley The 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/Interviews/audio/Attorney General Merrick Garland The 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n",
            "MoviePy - Writing audio in /content/Interviews/audio/Deion Sanders The 2023 60 Minutes Interview.mp3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MoviePy - Done.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/44.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4da96864fcda454286a86716b9c929f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "source.spm:   0%|          | 0.00/802k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1abecce6fea4493283b65af85262497b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "target.spm:   0%|          | 0.00/826k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d37582065bbe44f0bf0a0f68bb1c204f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1bd5c2e51b2144a0bb4683389dd3cd33"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "46a43b51fcb248c5bd22959dd1ae5a2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/312M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06ced31d97144cc9a3b47059eb1a92a3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bdd39fe99b4a4e4dbbd84e5448dda722"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Interviews/translated/Deion Sanders The 2023 60 Minutes Interview.txt\n",
            "/content/Interviews/translated/Denzel Washington  60 Minutes Archive.txt\n",
            "/content/Interviews/translated/Rich Paul The 60 Minutes Interview.txt\n",
            "/content/Interviews/translated/Attorney General Merrick Garland The 60 Minutes Interview.txt\n",
            "/content/Interviews/translated/Vice President Kamala Harris The 2023 60 Minutes Interview.txt\n",
            "/content/Interviews/translated/Godfather of AI Geoffrey Hinton The 60 Minutes Interview.txt\n",
            "/content/Interviews/translated/Volodymyr Zelenskyy The 2023 60 Minutes Interview.txt\n",
            "/content/Interviews/translated/Pink The 60 Minutes Interview.txt\n",
            "/content/Interviews/translated/Gen Mark Milley The 60 Minutes Interview.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install TTS"
      ],
      "metadata": {
        "id": "XNpU9gFkv1NX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "66e3464f-1adf-4fc8-8659-563df7cef3b8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting TTS\n",
            "  Downloading TTS-0.21.1-cp310-cp310-manylinux1_x86_64.whl (933 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/933.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/933.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m911.4/933.3 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m933.3/933.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cython>=0.29.30 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.0.5)\n",
            "Requirement already satisfied: scipy>=1.11.2 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.11.3)\n",
            "Requirement already satisfied: torch>=2.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (from TTS) (2.1.0+cu118)\n",
            "Requirement already satisfied: soundfile>=0.12.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.12.1)\n",
            "Requirement already satisfied: librosa>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.10.1)\n",
            "Collecting scikit-learn>=1.3.0 (from TTS)\n",
            "  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: inflect>=5.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (7.0.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (4.66.1)\n",
            "Collecting anyascii>=0.3.0 (from TTS)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (6.0.1)\n",
            "Requirement already satisfied: fsspec>=2023.6.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.6)\n",
            "Requirement already satisfied: packaging>=23.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (23.2)\n",
            "Requirement already satisfied: flask>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from TTS) (2.2.5)\n",
            "Collecting pysbd>=0.3.4 (from TTS)\n",
            "  Downloading pysbd-0.3.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting umap-learn>=0.5.1 (from TTS)\n",
            "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas<2.0,>=1.4 in /usr/local/lib/python3.10/dist-packages (from TTS) (1.5.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.7.1)\n",
            "Collecting trainer>=0.0.32 (from TTS)\n",
            "  Downloading trainer-0.0.32-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coqpit>=0.0.16 (from TTS)\n",
            "  Downloading coqpit-0.0.17-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from TTS) (0.42.1)\n",
            "Collecting pypinyin (from TTS)\n",
            "  Downloading pypinyin-0.49.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hangul-romanize (from TTS)\n",
            "  Downloading hangul_romanize-0.1.0-py3-none-any.whl (4.6 kB)\n",
            "Collecting gruut[de,es,fr]==2.2.3 (from TTS)\n",
            "  Downloading gruut-2.2.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.5/73.5 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jamo (from TTS)\n",
            "  Downloading jamo-0.4.1-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from TTS) (3.8.1)\n",
            "Collecting g2pkk>=0.1.1 (from TTS)\n",
            "  Downloading g2pkk-0.1.2-py3-none-any.whl (25 kB)\n",
            "Collecting bangla (from TTS)\n",
            "  Downloading bangla-0.0.2-py2.py3-none-any.whl (6.2 kB)\n",
            "Collecting bnnumerizer (from TTS)\n",
            "  Downloading bnnumerizer-0.0.2.tar.gz (4.7 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting bnunicodenormalizer (from TTS)\n",
            "  Downloading bnunicodenormalizer-0.1.6.tar.gz (39 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting einops>=0.6.0 (from TTS)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=4.33.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (4.35.2)\n",
            "Collecting encodec>=0.1.1 (from TTS)\n",
            "  Downloading encodec-0.1.1.tar.gz (3.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m117.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting unidecode>=1.3.2 (from TTS)\n",
            "  Downloading Unidecode-1.3.7-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.5/235.5 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting num2words (from TTS)\n",
            "  Downloading num2words-0.5.13-py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.3/143.3 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy[ja]>=3 in /usr/local/lib/python3.10/dist-packages (from TTS) (3.6.1)\n",
            "Collecting numpy==1.22.0 (from TTS)\n",
            "  Downloading numpy-1.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m86.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.57.0 in /usr/local/lib/python3.10/dist-packages (from TTS) (0.58.1)\n",
            "Requirement already satisfied: Babel<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from gruut[de,es,fr]==2.2.3->TTS) (2.13.1)\n",
            "Collecting dateparser~=1.1.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading dateparser-1.1.8-py2.py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.8/293.8 kB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut-ipa<1.0,>=0.12.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut-ipa-0.13.0.tar.gz (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_en~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_en-2.0.0.tar.gz (15.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.2/15.2 MB\u001b[0m \u001b[31m76.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jsonlines~=1.2.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading jsonlines-1.2.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting networkx<3.0.0,>=2.5.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading networkx-2.8.8-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m88.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-crfsuite~=0.9.7 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gruut_lang_de~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_de-2.0.0.tar.gz (18.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_es~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_es-2.0.0.tar.gz (31.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gruut_lang_fr~=2.0.0 (from gruut[de,es,fr]==2.2.3->TTS)\n",
            "  Downloading gruut_lang_fr-2.0.2.tar.gz (10.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.9/10.9 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.1->TTS) (1.3.1)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask>=2.0.1->TTS) (8.1.7)\n",
            "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (1.10.13)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from inflect>=5.6.0->TTS) (4.5.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (3.0.1)\n",
            "INFO: pip is looking at multiple versions of librosa to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting librosa>=0.10.0 (from TTS)\n",
            "  Downloading librosa-0.10.0.post2-py3-none-any.whl (253 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading librosa-0.10.0.post1-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading librosa-0.10.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.3.7)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa>=0.10.0->TTS) (1.0.7)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (4.44.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->TTS) (2.8.2)\n",
            "Collecting docopt>=0.6.2 (from num2words->TTS)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57.0->TTS) (0.41.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0,>=1.4->TTS) (2023.3.post1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.3.0->TTS) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.0->TTS) (1.16.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (8.1.12)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.0.10)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (0.10.3)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (6.4.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (2.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy[ja]>=3->TTS) (3.3.0)\n",
            "Collecting sudachipy!=0.6.1,>=0.5.2 (from spacy[ja]>=3->TTS)\n",
            "  Downloading SudachiPy-0.6.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m57.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sudachidict-core>=20211220 (from spacy[ja]>=3->TTS)\n",
            "  Downloading SudachiDict_core-20230927-py3-none-any.whl (71.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/71.7 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (1.12)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1->TTS) (2.1.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (5.9.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from trainer>=0.0.32->TTS) (2.14.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.19.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.33.0->TTS) (0.4.0)\n",
            "Collecting pynndescent>=0.5 (from umap-learn>=0.5.1->TTS)\n",
            "  Downloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.0->TTS) (2.21)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from dateparser~=1.1.0->gruut[de,es,fr]==2.2.3->TTS) (5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask>=2.0.1->TTS) (2.1.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from jsonlines~=1.2.0->gruut[de,es,fr]==2.2.3->TTS) (1.16.0)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa>=0.10.0->TTS) (4.0.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy[ja]>=3->TTS) (2023.7.22)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy[ja]>=3->TTS) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy[ja]>=3->TTS) (0.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1->TTS) (1.3.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.59.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.5.1)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (3.20.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->trainer>=0.0.32->TTS) (0.7.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer>=0.0.32->TTS) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->trainer>=0.0.32->TTS) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->trainer>=0.0.32->TTS) (3.2.2)\n",
            "Building wheels for collected packages: encodec, umap-learn, bnnumerizer, bnunicodenormalizer, docopt, gruut-ipa, gruut_lang_de, gruut_lang_en, gruut_lang_es, gruut_lang_fr, gruut\n",
            "  Building wheel for encodec (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for encodec: filename=encodec-0.1.1-py3-none-any.whl size=45759 sha256=848993ee2127282b15cb691e4c42e53d4a53f0671c759917a945d28e2b81924c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/36/cb/81af8b985a5f5e0815312d5e52b41263237af07b977e6bcbf3\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86831 sha256=17a6e45b2550666cebb4d51915e20d81b8cc1adafdfbb0c96cdbdf957c02ddf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/70/07/428d2b58660a1a3b431db59b806a10da736612ebbc66c1bcc5\n",
            "  Building wheel for bnnumerizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnnumerizer: filename=bnnumerizer-0.0.2-py3-none-any.whl size=5260 sha256=3d54c41aaff28e3f1deff00bf7ef772ced28bcc48898ee3f502679c31ccabe65\n",
            "  Stored in directory: /root/.cache/pip/wheels/59/6b/e8/223172e7d5c9f72df3ea1a0d9258f3a8ab5b28e827728edef5\n",
            "  Building wheel for bnunicodenormalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bnunicodenormalizer: filename=bnunicodenormalizer-0.1.6-py3-none-any.whl size=22779 sha256=b2a8d5119065373b2f50e2382eab8383d7269ee76740b2baec4e8fec829914bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/f4/d7/e9/16732a619cbf5a63fdc9f6e2f9eb5fcf73fa023735237330e9\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=977a5d74b650c21fa6b65e5e5275a092fec734a4ce90862b952baf63fd83fb76\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for gruut-ipa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut-ipa: filename=gruut_ipa-0.13.0-py3-none-any.whl size=104869 sha256=2bf6bb03b5fac2b830a8fd5751e627d892447c97367a976724569854d56b6eda\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/18/49/e4f500ecdf0babe757953f844e4d7cd1ea81c5503c09bfe984\n",
            "  Building wheel for gruut_lang_de (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_de: filename=gruut_lang_de-2.0.0-py3-none-any.whl size=18498181 sha256=b6141806d2364707f9122d2e2d83441dd379a6834b399ddc656c5931290c4c92\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/9a/05/cfce98f0c41a1a540f15708c4a02df190b82d84cf91ef6bc7f\n",
            "  Building wheel for gruut_lang_en (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_en: filename=gruut_lang_en-2.0.0-py3-none-any.whl size=15297179 sha256=4c7640ac0de9b245053788a8d5c5d54b367e9b1fb5901f0021a7e3f1b504d63b\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/9c/fb/77c655a9fbd78cdb9935d0ab65d80ddd0a3bcf7dbe18261650\n",
            "  Building wheel for gruut_lang_es (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_es: filename=gruut_lang_es-2.0.0-py3-none-any.whl size=32173796 sha256=8560a6cfe8285fa517fa2396c712d0f6b042edef99ad64578b8149a2474b160b\n",
            "  Stored in directory: /root/.cache/pip/wheels/9b/0a/90/788d92c07744b329b9283e37b29b064f5db6b1bb0442a1a19b\n",
            "  Building wheel for gruut_lang_fr (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut_lang_fr: filename=gruut_lang_fr-2.0.2-py3-none-any.whl size=10968766 sha256=4660dae519c74743506d95afb5f91b6ec348aa09f2ece7b75ddf68c2860a95fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/21/be/d0436e3f1cf9bf38b9bb9b4a476399c77a1ab19f7172b45e19\n",
            "  Building wheel for gruut (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gruut: filename=gruut-2.2.3-py3-none-any.whl size=75792 sha256=8bb8b8caa844a02b86beb3c79a75247a8a8ad9854863959ce8bac9aff717a133\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/57/a8/f9de532daf5214f53644f20f3a9e6f69269453c87df9c0a817\n",
            "Successfully built encodec umap-learn bnnumerizer bnunicodenormalizer docopt gruut-ipa gruut_lang_de gruut_lang_en gruut_lang_es gruut_lang_fr gruut\n",
            "Installing collected packages: sudachipy, python-crfsuite, jamo, hangul-romanize, gruut_lang_fr, gruut_lang_es, gruut_lang_en, gruut_lang_de, docopt, bnunicodenormalizer, bnnumerizer, bangla, unidecode, sudachidict-core, pysbd, pypinyin, numpy, num2words, networkx, jsonlines, gruut-ipa, einops, coqpit, anyascii, g2pkk, dateparser, scikit-learn, gruut, pynndescent, librosa, encodec, umap-learn, trainer, TTS\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.5\n",
            "    Uninstalling numpy-1.23.5:\n",
            "      Successfully uninstalled numpy-1.23.5\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.2.2\n",
            "    Uninstalling scikit-learn-1.2.2:\n",
            "      Successfully uninstalled scikit-learn-1.2.2\n",
            "  Attempting uninstall: librosa\n",
            "    Found existing installation: librosa 0.10.1\n",
            "    Uninstalling librosa-0.10.1:\n",
            "      Successfully uninstalled librosa-0.10.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "plotnine 0.12.4 requires numpy>=1.23.0, but you have numpy 1.22.0 which is incompatible.\n",
            "tensorflow 2.14.0 requires numpy>=1.23.5, but you have numpy 1.22.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed TTS-0.21.1 anyascii-0.3.2 bangla-0.0.2 bnnumerizer-0.0.2 bnunicodenormalizer-0.1.6 coqpit-0.0.17 dateparser-1.1.8 docopt-0.6.2 einops-0.7.0 encodec-0.1.1 g2pkk-0.1.2 gruut-2.2.3 gruut-ipa-0.13.0 gruut_lang_de-2.0.0 gruut_lang_en-2.0.0 gruut_lang_es-2.0.0 gruut_lang_fr-2.0.2 hangul-romanize-0.1.0 jamo-0.4.1 jsonlines-1.2.0 librosa-0.10.0 networkx-2.8.8 num2words-0.5.13 numpy-1.22.0 pynndescent-0.5.11 pypinyin-0.49.0 pysbd-0.3.4 python-crfsuite-0.9.9 scikit-learn-1.3.2 sudachidict-core-20230927 sudachipy-0.6.7 trainer-0.0.32 umap-learn-0.5.5 unidecode-1.3.7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from TTS.utils.manage import ModelManager\n",
        "from TTS.utils.synthesizer import Synthesizer\n",
        "import site"
      ],
      "metadata": {
        "id": "JPSU9q3VwNks"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "location = site.getsitepackages()[0]\n",
        "\n",
        "path = location+\"/TTS/.models.json\"\n",
        "\n",
        "model_manager = ModelManager(path)\n",
        "\n",
        "\n",
        "\n",
        "model_path, config_path, model_item = model_manager.download_model(\"tts_models/es/mai/tacotron2-DDC\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "voc_path, voc_config_path, _ = model_manager.download_model(model_item[\"default_vocoder\"])\n",
        "\n",
        "synthesizer = Synthesizer(\n",
        "    tts_checkpoint=model_path,\n",
        "    tts_config_path=config_path,\n",
        "    vocoder_checkpoint=voc_path,\n",
        "    vocoder_config=voc_config_path\n",
        ")"
      ],
      "metadata": {
        "id": "ozKCJnNewQO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17348f2-ae1d-42ac-a924-ee2266263026"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Downloading model to /root/.local/share/tts/tts_models--es--mai--tacotron2-DDC\n",
            " > Model's license - MPL\n",
            " > Check https://www.mozilla.org/en-US/MPL/2.0/ for more info.\n",
            " > Downloading model to /root/.local/share/tts/vocoder_models--universal--libri-tts--fullband-melgan\n",
            " > Model's license - MPL\n",
            " > Check https://www.mozilla.org/en-US/MPL/2.0/ for more info.\n",
            " > Using model: Tacotron2\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:16000\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:50.0\n",
            " | > mel_fmax:7600.0\n",
            " | > pitch_fmin:0.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:/root/.local/share/tts/tts_models--es--mai--tacotron2-DDC/scale_stats.npy\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Model's reduction rate `r` is set to: 1\n",
            " > Vocoder Model: fullband_melgan\n",
            " > Setting up Audio Processor...\n",
            " | > sample_rate:24000\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:0\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:50.0\n",
            " | > mel_fmax:7600.0\n",
            " | > pitch_fmin:0.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:1.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:60\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:/root/.local/share/tts/vocoder_models--universal--libri-tts--fullband-melgan/scale_stats.npy\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n",
            " > Generator Model: fullband_melgan_generator\n",
            " > Discriminator Model: melgan_multiscale_discriminator\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install openai-whisper"
      ],
      "metadata": {
        "id": "0qCw4JlTTkfs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3ca48ea-d599-4889-994f-8a1d6f37b5e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20231117)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.22.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2.8.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import whisper\n",
        "import difflib"
      ],
      "metadata": {
        "id": "XJf2wRS6SYZK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "folder_name = \"/content/Interviews\""
      ],
      "metadata": {
        "id": "-gU6GWJzyiqt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_speech(text_path, speech_path, synthesizer):\n",
        "  with open(text_path, 'r') as file:\n",
        "        lines = file.readlines()\n",
        "  text = \"\"\n",
        "  for line in lines:\n",
        "    line = line.strip()\n",
        "    if re.match(r'\\d{2}:\\d{2}', line):\n",
        "      continue\n",
        "    text= text + line\n",
        "  outputs = synthesizer.tts(text)\n",
        "  synthesizer.save_wav(outputs, speech_path)"
      ],
      "metadata": {
        "id": "K75fq_nzy5w-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Making the directory to store the translations\n",
        "if not os.path.exists(f\"{folder_name}/speech\"):\n",
        "    os.mkdir(f\"{folder_name}/speech\")\n",
        "\n",
        "# Getting all captions files in the audio directory\n",
        "text_files = [f for f in os.listdir(f\"{folder_name}/translated\") if f.endswith('.txt')]\n",
        "\n",
        "# Loop to get the captions from the directory\n",
        "for text_file in text_files:\n",
        "    # Making the path for caption\n",
        "    text_path = os.path.join(f\"{folder_name}/translated\", text_file)\n",
        "\n",
        "    # Making the path for translation\n",
        "    speech_path = os.path.join(f\"{folder_name}/speech\", text_file)\n",
        "    speech_path = speech_path.replace('.txt', '.wav')\n",
        "\n",
        "    # Calling the function\n",
        "    text_to_speech(text_path, speech_path, synthesizer)"
      ],
      "metadata": {
        "id": "Xw-nlfl0wT9x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ce553db-bd54-4e65-e6ec-78c42182616c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Text splitted to sentences.\n",
            "['Convencionalmente, 60 minutos no perfilan el mismo tema dos veces en dos temporadas, pero la convención no se cruza con el Salón de Famer, Dion Sanders.', 'El otoño pasado, conocimos a Sanders en Mississippi, donde estaba entrenando a Jackson State a prominencia en una conferencia de universidades históricamente negras.', 'Entonces, el hombre que se hace llamar Coach Prime, se dirigió a Boulder, a la Universidad de Colorado, llevándose su estilo brillantemente singular con él.', 'Allí, no sólo ha despertado un programa inactivo, sino que lo ha transformado en la charla del fútbol universitario, si no en los deportes estadounidenses.', 'Sanders es venerado, es insultado, pero su impacto repentino es indiscutible.', 'Por segunda vez en entornos radicalmente diferentes, sin disculpas como siempre, ha sacudido el deporte como una bola de nieve.', 'La historia continuará en un momento.', 'Esta fue la escena en el vestuario hace dos fines de semana.', 'Para los búfalos de Colorado y su nuevo entrenador Dion Sanders, abrió la temporada un perdedor de 21 puntos en TCU.Colorado estaba recién salido de una temporada 1-en-11.', 'La TCU estaba fresca de jugar en el partido del campeonato nacional de la temporada pasada.', 'Con habilidad y voluntad, los búfalos ganaron 45-42, detrás de su quarterback estrella, Shador Sanders.', 'Pero el verdadero foco, como siempre, estaba en el padre de 56 años de Shador.', 'Fue su primera victoria como entrenador de una escuela de cinco poderes, el más alto nivel de fútbol universitario.', '¿Sientes que te subestimaron?', 'Usted viene aquí y es, no sé si el entrenador Prime puede ganar.', 'Debes haber oído lo que algunos de estos otros entrenadores decían, en secreto y en voz alta.', 'Eso es miedo.', 'Miedo.', 'Sí, eso es miedo.', 'Eso es como, hey hombre, disparar, no queremos dejar que el motor que podría ponerse en marcha, porque si ese motor que podría ponerse en marcha, va a empezar a decir, creo que puedo, creo que puedo.', 'Y tarde o temprano va a empezar a decir, sé que puedo, sé que puedo.', 'Y tarde o temprano va a empezar a decir, yo hice eso.', 'Su debut en Colorado atrajo la atención nacional y la audiencia de la televisión monstruo.', 'El interés se complicó el fin de semana pasado, y los búfalos jugaron ante el público local más grande en 15 años en el rival del beat Nebraska.', 'Este fin de semana, tanto Fox como ESPN envían sus shows previos al juego, el rock incluido, a Boulder.', 'Entonces los búfalos se reunieron tarde para vencer al estado de Colorado en un thriller doble con el tiempo.', 'Tres partidos en la temporada, las estribaciones de los Rockies marcan el poco probable epicentro de todo un deporte.', 'Es un giro como para ti.', 'Ha sido muy divertido.', 'George, que contrató al entrenador Prime, ha sido el director atlético de Colorado durante una década.', 'Es genial para nosotros ser capaces de llevar este programa de nuevo a la relevancia, y habíamos fracasado en mis nueve años anteriores, diez años.', 'Es justo llamar a este pedazo de Ave María.', 'No fue un Ave María, pero fue un momento a tiempo para nuestra universidad y nuestro departamento de atletismo que o íbamos a ser relevantes o íbamos a ser irrelevantes.', 'Es demasiado pronto para cuantificar el efecto principal completo, pero las ventas de mercancías aumentaron un 819% desde la temporada pasada.', 'Los seguidores de Instagram se multiplican por más de diez.', 'Billetes de temporada agotados.', 'Sanders podría ser el entrenador ideal para estos tiempos de cambio en el fútbol universitario.', 'Otro hijo, Dion Jr., es parte del Ejército de Videografistas filmando el equipo sin parar para YouTube y una próxima serie de docu.', 'El equipo ganó un partido la temporada pasada.', '¿Es eso en cierto modo un punto de apelación?', 'Dios no me reubicaría en algo que tuviera éxito.', 'Eso no tiene sentido hacerlo.', 'Tuvo que encontrar la tarea más decepcionante y difícil, y esto es lo que era, y esto es lo que es, y me encanta eso.', 'Esto no era diferente a lo que nos dijo el año pasado, que Dios lo había llamado cobrar para venir a la Universidad Estatal de Jackson y elevar, sí, el programa de fútbol, pero también todos los HBCU.', 'Se quedó tres temporadas, pero la misma noche en diciembre pasado que JSU ganó el campeonato de la conferencia, Sanders anunció que se iba a Colorado para escalar otra montaña.', 'Dejaste Jackson State y te fuiste rápido.', '¿Qué le dijiste a esos niños?', 'No me fui.', '¿Qué le dijiste a esos niños?', 'No me fui rápido.', 'Dejé lo que se suponía que debía dejar.', 'Terminamos.', 'La mayoría de los entrenadores consiguen un nuevo trabajo y conducen rápidamente.', 'Terminé la tarea.', 'Usted dice que terminó la tarea, ¿había más trabajo que podría haber hecho en Jackson o?', 'Creo que hicimos un trabajo tremendo en Jackson.', 'Creo que establecimos un plan tremendo.', 'Intentamos presionar a Sanders sobre las circunstancias que rodearon su abandono de la misión en Jackson State.', 'Ha insinuado que la falta de pensamiento hacia adelante de la escuela puede haber tenido en cuenta su decisión.', 'Pero sobre este tema, él era tan escurridizo como él estaba regresando juegos de palabras para touchdowns en la NFL.', '¿Qué nos dijiste cuando te fuiste?', 'Oportunidad.', 'Llamado.', 'Tarde y temprano en la vida, habría una oportunidad que golpeara tu puerta.', 'Y en esta coyuntura de mi vida, sentí que la oportunidad no sólo para mí, sino para mis hijos también era tremenda.', 'No sólo tomamos varios niños de ese equipo, tres entrenadores, tal vez 12 a 14 empleados.', 'Así que le dimos a la gente una tremenda oportunidad aquí.', 'La distancia entre Jackson y Boulder es de mil millas y mucho más culturalmente.', 'Sanders pasó de una ciudad que es 83% negro a una que es 1% negro.', 'Desde un lugar con una crisis del agua a la clase de ciudad universitaria hipster donde hay una tienda dedicada a las cometas.', '¿Cuáles son tus primeras impresiones?', 'Hermoso, increíble.', 'Sólo una pieza entera y serenidad de todo.', 'Nunca los engordo viniendo.', 'Ni siquiera estoy de vacaciones aquí, hombre.', 'Nunca he estado esquiando o como tú lo llames.', 'El snowboard o lo que sea, todo eso.', 'Sabes, nunca he hecho nada de eso.', 'Ni siquiera vuelas pescado.', 'No, no lo sé.', 'Yo vuelo pescado.', 'Soy blanco como la mosca.', 'Yo pesco, pero no vuelo pescado.', 'Sin embargo, no perdió el tiempo congraciarse en la comunidad, incluyendo una visita a Peggy Coppa, una súper fan de Buffalo de 98 años.', '¿Eres excelente?', '¿Te llamo así o no?', 'No, no, yo me llamo.', 'Oh, bueno, ¿qué tal guapo?', 'Ahí lo tienes.', 'Eso servirá.', 'Estaba menos abrazando a los jugadores de Colorado.', 'En la primera reunión del equipo en diciembre, Sanders animó a los jugadores a entrar en el portal de transferencia, un mercado abierto para los atletas para encontrar nuevas escuelas, y hacer espacio para el talento superior que planeaba traer.', 'Más de 50 jugadores finalmente se trasladaron.', 'Llegaste aquí y no le diste puñetazos.', 'Se lo dijiste a algunos de estos tipos.', '¿Lo he hecho alguna vez?', 'Tomas un equipo que ha ganado un partido, y despides a todo un equipo de entrenamiento.', '¿A quién reclutaron los entrenadores?', 'Los niños.', 'Así que los niños son tan culpables como el personal de entrenamiento.', 'Y llegué a la conclusión de que una multitud de ellos puede ayudarnos a llegar a donde queríamos ir.', 'Le dijiste a la mayoría de estos tipos, cuanto más saltas, más espacio vas a hacer.', 'Aquellos de ustedes que no huimos, vamos a tratar de hacer que renuncies.', 'Sí.', 'Lo dejaste muy claro.', 'Sí.', 'Si fuiste por eso, si fuiste capaz de dejar que las palabras te huyan, no eres para nosotros.', 'Porque somos personal de la vieja escuela.', 'Entrenamos duro.', 'Entrenamos duro.', 'Somos disciplina, Narians.', 'Así que si estás permitiendo que la verborrea te escape porque no te sientes seguro con tu habilidad, no eres para nosotros.', 'Si un chico dijo, ¿sabes qué?', 'No, me quedo.', 'No me vas a echar con tus palabras.', 'Bien.', 'Quédate.', 'Así que pruébalo.', 'Estoy seguro de que algunos apreciaron tu franqueza.', '¿Pero esta política de tierra quemada es buena para el fútbol universitario o para los niños?', 'Creo que la verdad es buena para los niños.', 'Estamos tan ocupados mintiendo.', 'Ya no reconocemos la verdad en la sociedad.', 'Queremos que todos se sientan bien.', 'Así no es la vida.', 'Ahora es mi trabajo asegurarme de que tengo lo que necesitamos para ganar.', 'Eso hace que mucha gente se sienta bien, ganar sí.', 'Tengo que empujar hacia atrás en esto.', 'Eres padre de atletas universitarios.', 'Sí.', 'Y di, oye, tenemos un nuevo entrenador y me están diciendo que entre en el portal de transferencia.', 'Digo, hijo, debes estarlo, no debes estar bien.', 'Eso es lo que estás diciendo.', 'Usted no debe estar haciendo bien porque usted debe ser un activo y no un pasivo.', 'Soy honesto con mis hijos.', 'Sus hijos incluyen a Shadoor, el mariscal de campo estrella, en Shiloh, la seguridad inicial.', '¿Tienen idea de que iban a ser tan buenos y capturar el país como lo han hecho?', 'Sí.', 'Lo hiciste.', 'No viniste aquí, tienes a nuestro padre cerca solo suelto.', 'Hace un año hasta el día, vimos a Shadoor lanzando y lanzando pases de touchdown en Jackson State.', 'Pero había preguntas sobre si podía hacer lo mismo contra una competencia más dura.', 'Bueno, en sus dos primeros partidos en Colorado, lanzó por casi 1.000 yardas sin interceptación.', 'Estás poniendo un gran número en Jackson State.', 'Lo estás haciendo aquí contra equipos de los 10 grandes, 12 grandes, debe ser gratificante.', 'Sí, ahora estos dos juegos son lo más que has pasado por mi carrera.', 'Así que es emocionante saber que, ya sabes, es traducir.', 'Y me subí a un escenario más grande.', 'Me siento mejor.', 'También, y una vez más, es bienvenido a los deportes universitarios de hoy en día, tradujo su éxito en riquezas gracias a NIL, nombre, imagen similar, ingresos.', 'Tanto es así, conduce un Mercedes-Mayback de $190.000.', 'Y Shadoor puede que ni siquiera sea el mejor jugador del equipo.', 'Travis Hunter también siguió al entrenador Prime de Jackson a Colorado.', 'Su entrenador le permite jugar ofensiva en defensa, prácticamente inaudito en un juego moderno de la universidad.', 'Tienes dos jugadores de calidad Heisman muy buenos en este equipo.', 'Sí.', 'Tu hijo y Travis Hunter.', 'Sí, señor.', 'La primera mitad del primer partido de la temporada, ya estás hablando públicamente de las oportunidades de Travis Hunter en Heisman.', '¿Quién hace eso?', '11.30 horas reunión privada Sala 5Un entrenador que ama a sus hijos.', 'El entrenador que entiende eso es lo que esos niños desean.', 'Y supongo que para hacer eso.', 'Eso es lo que les dijimos cuando venían y eligieron jugar para nosotros.', 'Mis hijos que juegan para mí, no eligieron una universidad.', 'Me eligieron a mí.', 'Eso es una diferencia.', 'Los entrenadores han elegido unirse a Sanders también.', 'El personal, que revisó y actualizó, incluye ex entrenadores jefes y ex coordinadores de escuelas como Alabama.', 'Ahora que eres un tipo poderoso, ¿quién es el mejor entrenador en fútbol universitario hoy?', 'Déjame ver un espejo para poder mirarlo.', '¿Sientes eso?', '¿Crees que voy a sentarme aquí y decirte alguien más?', 'Crees que así es como opero.', 'Alguien más me lo dijo.', 'Pero te digo esto, amo y adoro y respeto.', 'Y cada vez que hago un comercial con el entrenador Saban, es un regalo.', 'Solo sentado en su presencia y escuchándolo y lanzando algo más para que pudiera escuchar su punto de vista al respecto porque ha olvidado más cosas de las que yo podría lograr.', 'Así que soy un estudiante admirando a este maravilloso profesor diciendo, simplemente tírame una migaja de lo que sabes.', 'A pesar de todo, hay algo de humildad y la manía actual puede morir un poco mientras Colorado se enfrenta a un welter de oponentes más duros el resto de la temporada.', 'Pero Deon Sanders ha fortalecido un campus, un programa, todo un deporte.', 'Peggy de la bola de juego.', 'Y maldita sea, si no lo ha hecho divertido.', 'Dame mi maldita música.']\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "entonθes, el ombɾe ke se aθe ʎamaɾ koat͡ʃ pɾime, se diɾixʝo a boʎdeɾ, a la unibeɾsidad de koloɾado, ʎebandose su estilo bɾiʎantemente sinɡulaɾ kon el.\n",
            " [!] Character '͡' not found in the vocabulary. Discarding it.\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 297)\n",
            " > after interpolation : torch.Size([1, 80, 445])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 449)\n",
            " > after interpolation : torch.Size([1, 80, 673])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 112)\n",
            " > after interpolation : torch.Size([1, 80, 168])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 199)\n",
            " > after interpolation : torch.Size([1, 80, 298])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 308)\n",
            " > after interpolation : torch.Size([1, 80, 462])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 448)\n",
            " > after interpolation : torch.Size([1, 80, 672])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 304)\n",
            " > after interpolation : torch.Size([1, 80, 456])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 411)\n",
            " > after interpolation : torch.Size([1, 80, 616])\n",
            "¿?\n",
            " [!] Character '¿' not found in the vocabulary. Discarding it.\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 196)\n",
            " > after interpolation : torch.Size([1, 80, 294])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 327)\n",
            " > after interpolation : torch.Size([1, 80, 490])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 49)\n",
            " > after interpolation : torch.Size([1, 80, 73])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 26)\n",
            " > after interpolation : torch.Size([1, 80, 39])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 68)\n",
            " > after interpolation : torch.Size([1, 80, 102])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 238)\n",
            " > after interpolation : torch.Size([1, 80, 357])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 210)\n",
            " > after interpolation : torch.Size([1, 80, 315])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 285)\n",
            " > after interpolation : torch.Size([1, 80, 427])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 389)\n",
            " > after interpolation : torch.Size([1, 80, 583])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 338)\n",
            " > after interpolation : torch.Size([1, 80, 507])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 390)\n",
            " > after interpolation : torch.Size([1, 80, 585])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 78)\n",
            " > after interpolation : torch.Size([1, 80, 117])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 83)\n",
            " > after interpolation : torch.Size([1, 80, 124])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 322)\n",
            " > after interpolation : torch.Size([1, 80, 483])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 150)\n",
            " > after interpolation : torch.Size([1, 80, 225])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 188)\n",
            " > after interpolation : torch.Size([1, 80, 282])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 102)\n",
            " > after interpolation : torch.Size([1, 80, 153])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 285)\n",
            " > after interpolation : torch.Size([1, 80, 427])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 463)\n",
            " > after interpolation : torch.Size([1, 80, 694])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 160)\n",
            " > after interpolation : torch.Size([1, 80, 240])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 158)\n",
            " > after interpolation : torch.Size([1, 80, 237])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 90)\n",
            " > after interpolation : torch.Size([1, 80, 135])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 444)\n",
            " > after interpolation : torch.Size([1, 80, 666])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 154)\n",
            " > after interpolation : torch.Size([1, 80, 231])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 40)\n",
            " > after interpolation : torch.Size([1, 80, 60])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 63)\n",
            " > after interpolation : torch.Size([1, 80, 94])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 129)\n",
            " > after interpolation : torch.Size([1, 80, 193])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 48)\n",
            " > after interpolation : torch.Size([1, 80, 72])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 271)\n",
            " > after interpolation : torch.Size([1, 80, 406])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 56)\n",
            " > after interpolation : torch.Size([1, 80, 84])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 289)\n",
            " > after interpolation : torch.Size([1, 80, 433])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 151)\n",
            " > after interpolation : torch.Size([1, 80, 226])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 120)\n",
            " > after interpolation : torch.Size([1, 80, 180])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 320)\n",
            " > after interpolation : torch.Size([1, 80, 480])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 389)\n",
            " > after interpolation : torch.Size([1, 80, 583])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 440)\n",
            " > after interpolation : torch.Size([1, 80, 660])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 44)\n",
            " > after interpolation : torch.Size([1, 80, 66])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 32)\n",
            " > after interpolation : torch.Size([1, 80, 48])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 263)\n",
            " > after interpolation : torch.Size([1, 80, 394])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 410)\n",
            " > after interpolation : torch.Size([1, 80, 615])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 369)\n",
            " > after interpolation : torch.Size([1, 80, 553])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 187)\n",
            " > after interpolation : torch.Size([1, 80, 280])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 262)\n",
            " > after interpolation : torch.Size([1, 80, 393])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 295)\n",
            " > after interpolation : torch.Size([1, 80, 442])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 462)\n",
            " > after interpolation : torch.Size([1, 80, 693])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 76)\n",
            " > after interpolation : torch.Size([1, 80, 114])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 138)\n",
            " > after interpolation : torch.Size([1, 80, 207])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 90)\n",
            " > after interpolation : torch.Size([1, 80, 135])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 163)\n",
            " > after interpolation : torch.Size([1, 80, 244])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 137)\n",
            " > after interpolation : torch.Size([1, 80, 205])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 111)\n",
            " > after interpolation : torch.Size([1, 80, 166])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 102)\n",
            " > after interpolation : torch.Size([1, 80, 153])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 90)\n",
            " > after interpolation : torch.Size([1, 80, 135])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 46)\n",
            " > after interpolation : torch.Size([1, 80, 69])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 64)\n",
            " > after interpolation : torch.Size([1, 80, 96])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 91)\n",
            " > after interpolation : torch.Size([1, 80, 136])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 132)\n",
            " > after interpolation : torch.Size([1, 80, 198])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 91)\n",
            " > after interpolation : torch.Size([1, 80, 136])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 75)\n",
            " > after interpolation : torch.Size([1, 80, 112])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 50)\n",
            " > after interpolation : torch.Size([1, 80, 75])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 47)\n",
            " > after interpolation : torch.Size([1, 80, 70])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 156)\n",
            " > after interpolation : torch.Size([1, 80, 234])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 167)\n",
            " > after interpolation : torch.Size([1, 80, 250])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 114)\n",
            " > after interpolation : torch.Size([1, 80, 171])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 131)\n",
            " > after interpolation : torch.Size([1, 80, 196])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 306)\n",
            " > after interpolation : torch.Size([1, 80, 459])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 45)\n",
            " > after interpolation : torch.Size([1, 80, 67])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 227)\n",
            " > after interpolation : torch.Size([1, 80, 340])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 328)\n",
            " > after interpolation : torch.Size([1, 80, 492])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 318)\n",
            " > after interpolation : torch.Size([1, 80, 477])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 249)\n",
            " > after interpolation : torch.Size([1, 80, 373])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 71)\n",
            " > after interpolation : torch.Size([1, 80, 106])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 334)\n",
            " > after interpolation : torch.Size([1, 80, 501])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 134)\n",
            " > after interpolation : torch.Size([1, 80, 201])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 57)\n",
            " > after interpolation : torch.Size([1, 80, 85])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 57)\n",
            " > after interpolation : torch.Size([1, 80, 85])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 94)\n",
            " > after interpolation : torch.Size([1, 80, 141])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 457)\n",
            " > after interpolation : torch.Size([1, 80, 685])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 105)\n",
            " > after interpolation : torch.Size([1, 80, 157])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 48)\n",
            " > after interpolation : torch.Size([1, 80, 72])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 109)\n",
            " > after interpolation : torch.Size([1, 80, 163])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 33)\n",
            " > after interpolation : torch.Size([1, 80, 49])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 64)\n",
            " > after interpolation : torch.Size([1, 80, 96])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 184)\n",
            " > after interpolation : torch.Size([1, 80, 276])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 128)\n",
            " > after interpolation : torch.Size([1, 80, 192])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 111)\n",
            " > after interpolation : torch.Size([1, 80, 166])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 137)\n",
            " > after interpolation : torch.Size([1, 80, 205])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 95)\n",
            " > after interpolation : torch.Size([1, 80, 142])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 62)\n",
            " > after interpolation : torch.Size([1, 80, 93])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 228)\n",
            " > after interpolation : torch.Size([1, 80, 342])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 197)\n",
            " > after interpolation : torch.Size([1, 80, 295])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 111)\n",
            " > after interpolation : torch.Size([1, 80, 166])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 128)\n",
            " > after interpolation : torch.Size([1, 80, 192])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 376)\n",
            " > after interpolation : torch.Size([1, 80, 564])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 154)\n",
            " > after interpolation : torch.Size([1, 80, 231])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 85)\n",
            " > after interpolation : torch.Size([1, 80, 127])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 299)\n",
            " > after interpolation : torch.Size([1, 80, 448])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 91)\n",
            " > after interpolation : torch.Size([1, 80, 136])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 358)\n",
            " > after interpolation : torch.Size([1, 80, 537])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 43)\n",
            " > after interpolation : torch.Size([1, 80, 64])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 185)\n",
            " > after interpolation : torch.Size([1, 80, 277])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 332)\n",
            " > after interpolation : torch.Size([1, 80, 498])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 293)\n",
            " > after interpolation : torch.Size([1, 80, 439])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 422)\n",
            " > after interpolation : torch.Size([1, 80, 633])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 156)\n",
            " > after interpolation : torch.Size([1, 80, 234])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 332)\n",
            " > after interpolation : torch.Size([1, 80, 498])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 190)\n",
            " > after interpolation : torch.Size([1, 80, 285])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 197)\n",
            " > after interpolation : torch.Size([1, 80, 295])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 129)\n",
            " > after interpolation : torch.Size([1, 80, 193])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 56)\n",
            " > after interpolation : torch.Size([1, 80, 84])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 259)\n",
            " > after interpolation : torch.Size([1, 80, 388])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 211)\n",
            " > after interpolation : torch.Size([1, 80, 316])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 208)\n",
            " > after interpolation : torch.Size([1, 80, 312])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 415)\n",
            " > after interpolation : torch.Size([1, 80, 622])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 263)\n",
            " > after interpolation : torch.Size([1, 80, 394])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 77)\n",
            " > after interpolation : torch.Size([1, 80, 115])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 43)\n",
            " > after interpolation : torch.Size([1, 80, 64])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 433)\n",
            " > after interpolation : torch.Size([1, 80, 649])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 330)\n",
            " > after interpolation : torch.Size([1, 80, 495])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 198)\n",
            " > after interpolation : torch.Size([1, 80, 297])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 99)\n",
            " > after interpolation : torch.Size([1, 80, 148])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 235)\n",
            " > after interpolation : torch.Size([1, 80, 352])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 215)\n",
            " > after interpolation : torch.Size([1, 80, 322])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 58)\n",
            " > after interpolation : torch.Size([1, 80, 87])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 80)\n",
            " > after interpolation : torch.Size([1, 80, 120])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 164)\n",
            " > after interpolation : torch.Size([1, 80, 246])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 445)\n",
            " > after interpolation : torch.Size([1, 80, 667])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 312)\n",
            " > after interpolation : torch.Size([1, 80, 468])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 141)\n",
            " > after interpolation : torch.Size([1, 80, 211])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 93)\n",
            " > after interpolation : torch.Size([1, 80, 139])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 71)\n",
            " > after interpolation : torch.Size([1, 80, 106])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 157)\n",
            " > after interpolation : torch.Size([1, 80, 235])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 254)\n",
            " > after interpolation : torch.Size([1, 80, 381])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 410)\n",
            " > after interpolation : torch.Size([1, 80, 615])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 277)\n",
            " > after interpolation : torch.Size([1, 80, 415])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 76)\n",
            " > after interpolation : torch.Size([1, 80, 114])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 164)\n",
            " > after interpolation : torch.Size([1, 80, 246])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 85)\n",
            " > after interpolation : torch.Size([1, 80, 127])\n",
            " > Processing time: 534.527857542038\n",
            " > Real-time factor: 0.5272601042648513\n",
            " > Text splitted to sentences.\n",
            "['60 Minutos Rebobinar.', 'Di Denzel, y la mayoría de la gente sabría que estás hablando de uno de los actores mejor pagados y más populares de Hollywood.', 'Pero hace 30 años, Denzel Washington era otro actor de Nueva York.', 'Hoy está jugando el papel principal en una obra de Broadway y ganando salarios sindicales estándar, una fracción de lo que ganaría en Hollywood.', 'Así que fuimos a verlo y recordé una historia que me contó hace cinco años sobre una predicción increíble que dice, empezó todo.', 'Estaba en la tienda de belleza de mi madre y me miraba en el espejo y vi a una mujer sentada al otro lado de la habitación para mí.', 'Y ella le dijo a mi madre, tráeme un pedazo de papel.', 'Ella dijo, tengo una profecía.', 'Porque el honor de Dios es verdad, tengo el pedazo de papel y lo guardo conmigo todo el tiempo.', 'Y escribió, dijo que este chico va a hablar con millones de personas.', 'No hablo mucho de eso, pero me he sentido como, bueno, tal vez tengo algo de trabajo que hacer.', '¿Recuerdas a la mujer que te hablé de la profecía?', 'Eso fue hace 30 años, eso será hace 30 años la semana que viene.', 'Y entonces empecé a actuar ese otoño.', 'Así que es interesante volver ahora, 30 años después, a unas 20 cuadras de donde empecé.', '¡Romanos!', '¿País, tal vez?', 'Y ámanos.', 'La carrera de Denzel Washington comenzó en el oscuro escenario de la Universidad Fortum de Nueva York.', 'Pero hoy está encabezando Broadway, apareciendo en una producción moderna de Julio César de Shakespeare.', 'Interpreta a Bruto, uno de los líderes de un complot para matar a César.', 'No es que quiera menos a César.', 'Pero que amo más a Roma.', '¿Por qué decidiste hacer esta obra ahora?', 'Pensé que era una gran oportunidad para volver al escenario, para volver a mis raíces.', 'Y tengo tan pocas oportunidades de subir al escenario.', 'Así que cuando lo hago realmente me gusta enfrentarme a Shakespeare, que es el más duro y el más gratificante.', 'No hay pases de terror en tus amenazas.', 'Quiero decir, me tomó 30 años, pero finalmente estoy haciendo lo que quería hacer cuando empecé.', 'Los actores con los que empecé en la universidad, y todos éramos esnobs, y pensamos que ganaríamos $600 a la semana en Broadway o lo que fuera en ese entonces.', 'No pensamos en ir a Hollywood.', 'Eso fue un poco de Hollywood.', 'Tú no hiciste eso.', 'Pero lo hizo.', 'Y es su actuación en esas películas de Hollywood lo que ha hecho de Denzel Washington un nombre familiar.', 'Acabas de pagar el cumpleaños de mi madre.', 'Ha estado en más de 30 largometrajes y ganó dos premios de la Academia, el Mejor Actor de Apoyo por su interpretación de un esclavo fugitivo en la película Glory, y en 2002 Mejor Actor por su actuación como el policía sucio Alonzo Harris en el Día de Entrenamiento.', 'No voy a tomarme de la mano.', 'No voy a hacer de niñera.', 'Lo tienes hoy.', 'Y hoy para mostrarme quién y de qué hiciste.', 'Su nombre se ha convertido en sinónimo de los blockbusters de taquilla de Hollywood.', 'Más recientemente interpretó al Mayor Ben Marco en un remake de The Manchurian Candidats.', 'Alguien se metió en nuestras cabezas con grandes botas de acero, cortacables en una motosierra, y se fueron a la ciudad.', 'Has estado trabajando mucho desde que hablamos hace cinco años.', '¿Qué has hecho?', '¿Siete películas desde entonces?', 'Nunca.', '¿Desde qué año fue?', 'Dos, nueve.', 'Noventa y nueve, sí.', 'De acuerdo.', 'Quiero decir que es mucho trabajo.', '¿Lo es?', 'Quiero decir, el trabajo es como, ya sabes, el basurero es trabajo.', 'Actuar no es trabajo.', 'Actuar es un privilegio y es un oficio y todas esas cosas, pero no es trabajo.', 'Leí que ahora tienes 20 millones en película.', 'He oído que tú también ganas tanto dinero.', 'Aún no he llegado.', 'Oh, has terminado.', 'Pensé que estaba empezando a decirte algo firmado a mí y se te olvidó, pero te diriges a la oficina superior.', 'Me entiendes.', 'En 2002 en la película Antoine Fisher, Denzel interpretó a un psiquiatra de la Marina asesorando a un marinero problemático.', 'Corten, corten.', 'De acuerdo.', 'Además, abordar un nuevo papel como director de la película.', 'Quiero estar en el espacio justo en nuestra cara para nuestro primer disparo.', '¿Te ha gustado dirigir?', 'Por supuesto.', 'Voy a hacerlo de nuevo.', 'Y cuando se trata de uno u otro, quiero decir, ¿te gustaría hacer ambos o prefieres actuar antes que dirigir?', 'Miro a Clint Eastwood como modelo.', 'Eso es, me gusta la forma en que está haciendo las cosas y así es como me gustaría hacerlo.', 'Sólo seguí hasta más y más cinematografía.', 'La silla de un director de Hollywood está muy lejos de donde creció en Mount Vernon, un suburbio de clase trabajadora fuera de la ciudad de Nueva York.', 'Su madre, Lennis, manejaba esa tienda de belleza.', 'Su padre, Denzel padre, era un predicador pentecostal que tenía otros dos trabajos.', 'Denzel iba a la iglesia todos los domingos, pero soñaba con convertirse en un atleta profesional.', 'Pasó todo su tiempo libre aquí en lo que entonces era el club de chicos.', 'Este era un lugar importante para ti.', 'Sí.', 'Yo vivía aquí.', 'Mi madre tuvo que venir a buscarme.', '¿Así que tuviste un tiempo en el que tuviste que volver a casa?', 'A las nueve en punto, hombre.', 'Tuve un tiempo.', 'Sabía que tenía que llegar al mercado de pescado a las 854 y al pollo a las 856 para llegar a casa a las nueve.', '¿Alguna vez tuvo que venir a buscarte?', 'Lo hizo.', 'Lo haría.', 'Estábamos en el parque y ella vino.', 'Estábamos como, ah, D, tu madre está aquí y yo me subí al coche y ella estaba gritando.', 'Así que miro a todo el mundo en la ventana como, ya sabes, tengo esto.', 'Mientras me daba la vuelta, pow.', 'Así que puse mi cabeza debajo del salpicadero.', 'Sólo conduce, mamá.', 'Sólo conduce.', 'Denzel dice que su madre, Lennis, le salvó la vida cuando reunió suficiente dinero para enviarlo a la Academia Oakland, un pequeño internado para chicos en el norte del estado de Nueva York.', 'No había estado allí por 20 años y se sorprendió al ver su vieja escuela ser convertido en condominios.', 'Hombre, parece tan poco ahora.', 'Mis armas.', 'Denzel tenía 14 años cuando vino aquí, uno de los pocos estudiantes afroamericanos.', '¿Cómo terminaste aquí?', 'Yo, um, estaba en la escuela pública, en la secundaria Mount Vernon y mi madre decidió que era mejor sacarme de allí antes de que terminara donde muchos de mis amigos están ahora, ya sabes, en la tumba, en la penitenciaría.', '¿Cómo estabas aquí?', '¿Eras un chico malo?', 'No, no, aire enojado a medida que pasaba el tiempo.', '¿Por qué te enfadaste?', 'Vamos, vamos a dar un paseo por aquí.', 'Justo aquí había una silla y yo estaba sentado en el comedor, como lo llamáramos, y me dijeron, tu madre está aquí.', 'Y dije, mi madre dijo, dije, oh, ¿qué hice?', 'Hice algo malo.', 'Y vine por aquí, me senté, y ella dijo, tu padre y yo ya no estamos juntos.', 'Vas a estar conmigo, ¿sabes?', 'No sé qué voy a hacer, pero vamos a solucionarlo.', 'Así que aquí es donde me enteré.', 'Mis padres se estaban divorciando aquí, aquí, aquí.', 'Justo aquí.', 'Lo recuerdo como si fuera ayer.', 'Así que para responder a tu pregunta sobre la ira, creo que empecé a tener un pequeño problema después de eso, empecé a meterme en peleas.', 'Y casi lo echan de la escuela, pero su madre convenció al director para que le diera otra oportunidad.', 'Le debes mucho.', 'Le debo todo.', 'Asumo que te han hablado de eso.', 'En muchos sentidos.', 'La historia continuará después de esto.', 'Denzel se aprovechó de esa segunda oportunidad construyendo una carrera que le ha traído.', 'La fama de Rich y la aclamación crítica.', 'Entonces, ¿por qué un actor que gana millones por una película arriesgaría su reputación al tomar un papel que paga $1,700 a la semana?', '¿Qué sacas de esto?', 'Quiero decir, cuando pasas por esta actuación ocho veces a la semana.', 'Es como reforzar.', 'Las luces se encienden, cuando la cortina sube y es el medio de un actor en el escenario.', 'Y ya sabes, está volando por el asiento de tus pantalones.', 'Tienes que seguir adelante.', 'Es en vivo.', 'Las cosas pasan.', 'Todavía estamos pasando por cosas.', 'Las cosas caen.', 'Las luces no funcionan.', 'Olvidas las líneas o lo que sea que pase.', 'Y eso es bueno.', 'Es un buen ejercicio.', 'Los celulares se apagan.', 'Los celulares se apagan.', 'Uno de estos días voy a responder a él en pentametro Iambic.', 'Contéstale.', 'Mi señor.', 'Mi señor es para usted.', 'Cielos, prefiero acuñar mi corazón.', 'Esta producción ha cambiado las togas y túnicas de la antigua Roma por trajes, corbatas y camuflaje.', 'Está ambientado en tiempos modernos y tiene la intención de evocar las luchas de poder en ciudades como Washington o Bagdad.', '¿Qué hace relevante hoy la obra de Julio César?', 'Bueno, de nuevo, quiero decir, es lo que si.', 'Tenemos líderes en el mundo que piensan que son dioses.', 'Y no son sólo gobiernos, son corporaciones.', 'Es, ya sabes, desafortunadamente no mucho ha cambiado.', 'Creo que es parte de la condición humana.', 'Julio César abrió hace dos semanas a críticas mixtas.', 'Pero Denzel dice que las críticas no le afectan porque no las lee.', 'De todos modos, el espectáculo está casi agotado para sus 112 actuaciones programadas que durarán hasta junio.', 'Actuaciones que le dan algo que no consigue en Hollywood.', '¿Cómo te sientes al final de una actuación?', 'Quiero decir, este no es un papel fácil.', 'Agradecido.', 'Sabes, salgo corriendo del escenario, me limpio el maquillaje.', 'Digo una oración rápida.', 'Oigo a la gente aplaudiendo.', 'Tienes sentido común.', 'Uh oh.', '¿Son dos arcos esta noche?', '¿Es uno?', '¿Son tres?', 'Ya sabes.', 'Y, pero un alivio, ya sabes.', 'Joy.', 'Es, es, no lo consigues en las películas.', 'Hacerlo películas.', 'Tú, tú, todos los sentimientos que estoy teniendo noche tras noche, quiero decir, la gente es como, hombre, tienes cien que ir.', 'Pero estoy como, sí, estoy disfrutando de cada uno de ellos.']\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 92)\n",
            " > after interpolation : torch.Size([1, 80, 138])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 458)\n",
            " > after interpolation : torch.Size([1, 80, 687])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 241)\n",
            " > after interpolation : torch.Size([1, 80, 361])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 478)\n",
            " > after interpolation : torch.Size([1, 80, 717])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 470)\n",
            " > after interpolation : torch.Size([1, 80, 705])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 479)\n",
            " > after interpolation : torch.Size([1, 80, 718])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 181)\n",
            " > after interpolation : torch.Size([1, 80, 271])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 132)\n",
            " > after interpolation : torch.Size([1, 80, 198])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 324)\n",
            " > after interpolation : torch.Size([1, 80, 486])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 224)\n",
            " > after interpolation : torch.Size([1, 80, 336])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 340)\n",
            " > after interpolation : torch.Size([1, 80, 510])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 267)\n",
            " > after interpolation : torch.Size([1, 80, 400])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 128)\n",
            " > after interpolation : torch.Size([1, 80, 192])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 356)\n",
            " > after interpolation : torch.Size([1, 80, 534])\n",
            "¡!\n",
            " [!] Character '¡' not found in the vocabulary. Discarding it.\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 57)\n",
            " > after interpolation : torch.Size([1, 80, 85])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 42)\n",
            " > after interpolation : torch.Size([1, 80, 63])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 306)\n",
            " > after interpolation : torch.Size([1, 80, 459])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 338)\n",
            " > after interpolation : torch.Size([1, 80, 507])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 239)\n",
            " > after interpolation : torch.Size([1, 80, 358])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 100)\n",
            " > after interpolation : torch.Size([1, 80, 150])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 78)\n",
            " > after interpolation : torch.Size([1, 80, 117])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 324)\n",
            " > after interpolation : torch.Size([1, 80, 486])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 184)\n",
            " > after interpolation : torch.Size([1, 80, 276])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 414)\n",
            " > after interpolation : torch.Size([1, 80, 621])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 128)\n",
            " > after interpolation : torch.Size([1, 80, 192])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 349)\n",
            " > after interpolation : torch.Size([1, 80, 523])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 101)\n",
            " > after interpolation : torch.Size([1, 80, 151])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 103)\n",
            " > after interpolation : torch.Size([1, 80, 154])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 63)\n",
            " > after interpolation : torch.Size([1, 80, 94])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 40)\n",
            " > after interpolation : torch.Size([1, 80, 60])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 325)\n",
            " > after interpolation : torch.Size([1, 80, 487])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 133)\n",
            " > after interpolation : torch.Size([1, 80, 199])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 90)\n",
            " > after interpolation : torch.Size([1, 80, 135])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 83)\n",
            " > after interpolation : torch.Size([1, 80, 124])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 48)\n",
            " > after interpolation : torch.Size([1, 80, 72])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 134)\n",
            " > after interpolation : torch.Size([1, 80, 201])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 229)\n",
            " > after interpolation : torch.Size([1, 80, 343])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 303)\n",
            " > after interpolation : torch.Size([1, 80, 454])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 421)\n",
            " > after interpolation : torch.Size([1, 80, 631])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 190)\n",
            " > after interpolation : torch.Size([1, 80, 285])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 30)\n",
            " > after interpolation : torch.Size([1, 80, 45])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 35)\n",
            " > after interpolation : torch.Size([1, 80, 52])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 107)\n",
            " > after interpolation : torch.Size([1, 80, 160])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 39)\n",
            " > after interpolation : torch.Size([1, 80, 58])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 101)\n",
            " > after interpolation : torch.Size([1, 80, 151])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 249)\n",
            " > after interpolation : torch.Size([1, 80, 373])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 72)\n",
            " > after interpolation : torch.Size([1, 80, 108])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 295)\n",
            " > after interpolation : torch.Size([1, 80, 442])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 144)\n",
            " > after interpolation : torch.Size([1, 80, 216])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 134)\n",
            " > after interpolation : torch.Size([1, 80, 201])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 59)\n",
            " > after interpolation : torch.Size([1, 80, 88])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 54)\n",
            " > after interpolation : torch.Size([1, 80, 81])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 401)\n",
            " > after interpolation : torch.Size([1, 80, 601])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 52)\n",
            " > after interpolation : torch.Size([1, 80, 78])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 55)\n",
            " > after interpolation : torch.Size([1, 80, 82])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 39)\n",
            " > after interpolation : torch.Size([1, 80, 58])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 196)\n",
            " > after interpolation : torch.Size([1, 80, 294])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 225)\n",
            " > after interpolation : torch.Size([1, 80, 337])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 45)\n",
            " > after interpolation : torch.Size([1, 80, 67])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 68)\n",
            " > after interpolation : torch.Size([1, 80, 102])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 406)\n",
            " > after interpolation : torch.Size([1, 80, 609])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 124)\n",
            " > after interpolation : torch.Size([1, 80, 186])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 295)\n",
            " > after interpolation : torch.Size([1, 80, 442])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 154)\n",
            " > after interpolation : torch.Size([1, 80, 231])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 473)\n",
            " > after interpolation : torch.Size([1, 80, 709])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 177)\n",
            " > after interpolation : torch.Size([1, 80, 265])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 315)\n",
            " > after interpolation : torch.Size([1, 80, 472])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 302)\n",
            " > after interpolation : torch.Size([1, 80, 453])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 225)\n",
            " > after interpolation : torch.Size([1, 80, 337])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 132)\n",
            " > after interpolation : torch.Size([1, 80, 198])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 50)\n",
            " > after interpolation : torch.Size([1, 80, 75])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 98)\n",
            " > after interpolation : torch.Size([1, 80, 147])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 105)\n",
            " > after interpolation : torch.Size([1, 80, 157])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 46)\n",
            " > after interpolation : torch.Size([1, 80, 69])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 28)\n",
            " > after interpolation : torch.Size([1, 80, 42])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 32)\n",
            " > after interpolation : torch.Size([1, 80, 48])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 132)\n",
            " > after interpolation : torch.Size([1, 80, 198])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 322)\n",
            " > after interpolation : torch.Size([1, 80, 483])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 278)\n",
            " > after interpolation : torch.Size([1, 80, 417])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 106)\n",
            " > after interpolation : torch.Size([1, 80, 159])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 164)\n",
            " > after interpolation : torch.Size([1, 80, 246])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 77)\n",
            " > after interpolation : torch.Size([1, 80, 115])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 56)\n",
            " > after interpolation : torch.Size([1, 80, 84])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 330)\n",
            " > after interpolation : torch.Size([1, 80, 495])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 103)\n",
            " > after interpolation : torch.Size([1, 80, 154])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 46)\n",
            " > after interpolation : torch.Size([1, 80, 69])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 359)\n",
            " > after interpolation : torch.Size([1, 80, 538])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 182)\n",
            " > after interpolation : torch.Size([1, 80, 273])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 116)\n",
            " > after interpolation : torch.Size([1, 80, 174])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 419)\n",
            " > after interpolation : torch.Size([1, 80, 628])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 183)\n",
            " > after interpolation : torch.Size([1, 80, 274])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 52)\n",
            " > after interpolation : torch.Size([1, 80, 78])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 287)\n",
            " > after interpolation : torch.Size([1, 80, 430])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 96)\n",
            " > after interpolation : torch.Size([1, 80, 144])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 182)\n",
            " > after interpolation : torch.Size([1, 80, 273])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 107)\n",
            " > after interpolation : torch.Size([1, 80, 160])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 201)\n",
            " > after interpolation : torch.Size([1, 80, 301])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 36)\n",
            " > after interpolation : torch.Size([1, 80, 54])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 102)\n",
            " > after interpolation : torch.Size([1, 80, 153])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 341)\n",
            " > after interpolation : torch.Size([1, 80, 511])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 57)\n",
            " > after interpolation : torch.Size([1, 80, 85])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 47)\n",
            " > after interpolation : torch.Size([1, 80, 70])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 97)\n",
            " > after interpolation : torch.Size([1, 80, 145])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 69)\n",
            " > after interpolation : torch.Size([1, 80, 103])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 113)\n",
            " > after interpolation : torch.Size([1, 80, 169])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 278)\n",
            " > after interpolation : torch.Size([1, 80, 417])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 141)\n",
            " > after interpolation : torch.Size([1, 80, 211])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 218)\n",
            " > after interpolation : torch.Size([1, 80, 327])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 60)\n",
            " > after interpolation : torch.Size([1, 80, 90])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 302)\n",
            " > after interpolation : torch.Size([1, 80, 453])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 197)\n",
            " > after interpolation : torch.Size([1, 80, 295])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 86)\n",
            " > after interpolation : torch.Size([1, 80, 129])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 45)\n",
            " > after interpolation : torch.Size([1, 80, 67])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 56)\n",
            " > after interpolation : torch.Size([1, 80, 84])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 121)\n",
            " > after interpolation : torch.Size([1, 80, 181])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 52)\n",
            " > after interpolation : torch.Size([1, 80, 78])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 79)\n",
            " > after interpolation : torch.Size([1, 80, 118])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 126)\n",
            " > after interpolation : torch.Size([1, 80, 189])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 49)\n",
            " > after interpolation : torch.Size([1, 80, 73])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 90)\n",
            " > after interpolation : torch.Size([1, 80, 135])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 79)\n",
            " > after interpolation : torch.Size([1, 80, 118])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 79)\n",
            " > after interpolation : torch.Size([1, 80, 118])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 199)\n",
            " > after interpolation : torch.Size([1, 80, 298])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 36)\n",
            " > after interpolation : torch.Size([1, 80, 54])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 42)\n",
            " > after interpolation : torch.Size([1, 80, 63])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 69)\n",
            " > after interpolation : torch.Size([1, 80, 103])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 139)\n",
            " > after interpolation : torch.Size([1, 80, 208])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 368)\n",
            " > after interpolation : torch.Size([1, 80, 552])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 398)\n",
            " > after interpolation : torch.Size([1, 80, 597])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 154)\n",
            " > after interpolation : torch.Size([1, 80, 231])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 180)\n",
            " > after interpolation : torch.Size([1, 80, 270])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 186)\n",
            " > after interpolation : torch.Size([1, 80, 279])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 214)\n",
            " > after interpolation : torch.Size([1, 80, 321])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 113)\n",
            " > after interpolation : torch.Size([1, 80, 169])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 179)\n",
            " > after interpolation : torch.Size([1, 80, 268])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 185)\n",
            " > after interpolation : torch.Size([1, 80, 277])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 448)\n",
            " > after interpolation : torch.Size([1, 80, 672])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 162)\n",
            " > after interpolation : torch.Size([1, 80, 243])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 147)\n",
            " > after interpolation : torch.Size([1, 80, 220])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 48)\n",
            " > after interpolation : torch.Size([1, 80, 72])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 235)\n",
            " > after interpolation : torch.Size([1, 80, 352])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 92)\n",
            " > after interpolation : torch.Size([1, 80, 138])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 79)\n",
            " > after interpolation : torch.Size([1, 80, 118])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 71)\n",
            " > after interpolation : torch.Size([1, 80, 106])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 20)\n",
            " > after interpolation : torch.Size([1, 80, 30])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 43)\n",
            " > after interpolation : torch.Size([1, 80, 64])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 99)\n",
            " > after interpolation : torch.Size([1, 80, 148])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 17)\n",
            " > after interpolation : torch.Size([1, 80, 25])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 150)\n",
            " > after interpolation : torch.Size([1, 80, 225])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 75)\n",
            " > after interpolation : torch.Size([1, 80, 112])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 467)\n",
            " > after interpolation : torch.Size([1, 80, 700])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 234)\n",
            " > after interpolation : torch.Size([1, 80, 351])\n",
            " > Processing time: 406.4509348869324\n",
            " > Real-time factor: 0.48172933248661887\n",
            " > Text splitted to sentences.\n",
            "['Rich Paul se ha convertido en uno de los principales agentes en los deportes profesionales.', 'Cuenta a LeBron James como un amigo cercano y cliente.', 'La agencia que fundó, Clutch Sports Group, hizo tratos por valor de casi 900 millones de dólares el verano pasado solo para sus clientes de la NBA.Paul perfeccionó sus instintos de hacer tratos de niño, navegando por lo que llamó las calles hostiles de su vecindario de Cleveland.', 'Hoy a los 42 está reescribiendo el libro de jugadas para representar a los atletas.', 'Rich Paul nos dijo que tuvo suerte y cuando escuches su historia creemos que entenderás por qué.', 'La historia continuará en un momento.', '¿Así que el uso para venir a los juegos cuando eras más joven?', 'Fui una vez cuando tuve que sentarme todo el camino arriba y realmente no podías ver a la persona.', 'Y ahora, ahora es ahora, estás sentado en el suelo.', 'Nos unimos a Rich Paul Courtside en un partido de Cleveland Cavaliers la temporada pasada.', 'Parecía conocer a todo el mundo.', 'Y parecía que todos querían conocerlo.', 'Muchas gracias, amigo.', 'Gracias, hermano.', 'Te lo agradezco.', 'El año pasado Paul consiguió a la estrella de Cleveland, Darius Garland, un trato de $200 millones, el más rico en la historia de la franquicia.', 'Garland es uno de los casi 200 atletas en la lista de Paul.', '¿Quiénes eran algunos de los grandes nombres que todos reconoceríamos?', 'Qué deporte quieres.', 'Quiero decir, acabamos de tener a Jalen Hertz y Devontay Smith tocando el Super Bowl para los Philadelphia Eagles y luego tienes a Anthony Davis y Draymond Green y obviamente a LeBron.', '¿Sabes el valor total del contrato que has negociado?', 'Yo diría que es cerca de $3 mil millones, creo.', 'Son más de $4 mil millones, pero es difícil seguir la pista cuando siempre estás en movimiento.', 'Hora del espectáculo, nena.', 'Antes del draft de la NBA en Nueva York, lo vimos trabajar los teléfonos.', 'Ya sabes, es día de reclutamiento, hombre.', 'Cualquier cosa puede pasar.', 'Trabaja en la habitación.', 'Hola, CoSell.', '¿Cómo estás, hombre?', 'Gusto en verte.', 'Y trabajar los ángulos para mover a clientes como Duke Center, Eric Lively II, en el draft board.', 'En la universidad, Lively era conocido por su defensa, pero Paul le hizo trabajar en su tiro de tres puntos y antes del draft, invitó a los equipos a ver.', 'Vivamente disparado hasta la 12a toma, unos 10 puntos más altos que los proyectados por primera vez.', 'Puede que no lo parezca, pero Rich Paul es una figura imponente en la NBA.Siempre he sido el tipo más pequeño en la habitación dispuesto a tomar el mayor columpio.', 'Algunos de sus mayores columpios han sido para su mayor cliente, LeBron James.', 'Paul negoció sus saltos de Miami a Cleveland a Los Ángeles, acuerdos que beneficiaron a James $400 millones y lo establecieron para ganar dos de sus cuatro campeonatos.', 'Nos dijo que trabaja para dar ventaja a los jugadores.', 'Algunas personas dicen que estás destruyendo la lealtad del jugador a los equipos y los fans.', '¿Lealtad al jugador a qué?', 'Si pudiera ser traspasado en medio de la noche a otro equipo, lo que debería ser es educarme a donde si esto no va como se suponía que iba a ir, puedo cambiar.', '¿Verdad?', 'No vamos a tener opciones.', 'Tengo opciones.', '¿Qué es el sistema que tiene dinero sin opciones?', 'Aparentemente es cómo se sintió la superestrella Anthony Davis en 2018.', 'El Centro de Nueva Orleans tenía un contrato de 127 millones de dólares, pero estaba cansado de perder, así que despidió a su agente y contrató a Rich Paul.', 'Paul desobedeció las reglas de la NBA exigiendo públicamente un comercio, ganando la ira de los fans y una multa de $50,000 para Davis.', 'El drama puso a Paul en la portada de Sports Illustrated, que lo llamó la figura más polarizante de la NBA.Cuando era alguien que no se parecía a mí, era genial.', 'Por eso tienes un agente de poder.', 'Pero cuando soy yo, estoy destruyendo la liga.', 'Quiero decir, esas cosas son absurdas.', 'Consiguió a Davis lo que quería, un anillo de campeonato y un trato que ahora vale $270 millones.', 'Hay un dicho que dice, si no tienes enemigos, no vas a aparecer.', 'Así que debes estar apareciendo.', 'Creo que estoy saltando un poco.', 'Estaba apareciendo mucho en su All-Star Game Party anual este invierno pasado en Salt Lake City.', 'Entramos y vimos gigantes de la corte mezclándose con raperos, dueños de equipos y titanes de la industria sobre cócteles y toldos.', 'Rich Paul tenía un plato lleno de opciones de negocio, una del presidente de Gatorade.', 'Quiero estar en la primera llamada.', 'Hecho.', 'Mientras conversamos con él, el guerrero Golden State, Dremon Green, entró.', 'El cuatro veces campeón de la NBA recorrió a través de otros dos agentes antes de firmar con Rich Paul, quien le consiguió un contrato de $100 millones durante el verano.', 'Así que terminas siendo un joven negro que ha ganado más dinero del que puedas imaginar, pero no sabes cómo vivir con ello.', 'No sabes qué hacer con él.', '¿Y a qué se dedica?', 'La mayoría de los agentes tratan a los atletas como si los atletas trabajaran para ellos.', 'Pero hay un negocio de miles de millones de dólares alrededor de la mayoría de los atletas que no entienden, pero no tienen una parte rica de la camiseta.', 'Y eso es lo que tiene de especial.', 'El improbable viaje de Paul, el tema de sus nuevas memorias esta semana, comenzó en el lado este de Cleveland a principios de 1980, justo cuando la cocaína crack salió a las calles.', 'Cuando tenía unos cuatro años, se enteró de que su madre Minerva estaba enganchada al crack.', 'Su padre, Big Rich, reconoció la inteligencia de su hijo y lo mantuvo cerca, aunque vivían separados.', 'Era dueño de la tienda del barrio.', 'La tienda de tu padre estaba justo aquí.', 'Sí.', 'Y este era mi mundo.', 'Esta esquina ahora vacía era un semillero de actividad, legal e ilegal.', 'Fue un tiroteo aquí en esta esquina.', 'Big Rich le enseñó a su hijo a pensar siempre dos pasos adelante.', 'Reunió el dinero para enviarlo a una escuela católica lejos del vecindario.', 'Sin embargo, no había manera de evitar las calles.', 'No sabes en lo que estás.', 'Esa es tu norma.', 'Esa es mi norma.', 'Sardinas, Dr. Cane, esa era la versión de hoy de Atún Tartar en la azotea de Waldorf.', 'Esta fue mi educación, sin embargo.', 'Esta era mi Harvard, mi Michigan, mi Morehouse, y las mismas cosas que aprendí en esta esquina, las llevo a la sala de juntas.', 'Porque lo único que esto te enseña que no creo que puedas aprender de esas instituciones son las personas, los personajes.', 'Y en estas calles, no hay mejor manera de aprender carácter porque vienen con todo.', 'Su padre le enseñó otra habilidad, una manera de ganar dinero si todo lo demás falla con un par de dados.', 'Paul y su mejor amigo, Edward Givens, eran habituales en un casino al aire libre en el parque.50 personas se amontonaron alrededor de esta pequeña área y la energía era alta, era una arena.', 'Y Rich Paul era natural.', '¿Y cuánto ganarías?', 'Quiero decir, un día lento fue de $1.000.¿Y un día no lento?', 'No, 4.000 dólares.', '¿4.000 dólares?', 'Sí, tranquilo.', 'Si tenías 14, 15, 16.', 'Oh, sí.', '¿Qué aprendiste de esta experiencia?', 'Ganaste una resistencia aquí.', 'Ganamos la mayoría del tiempo.', 'Pero también tenías que aprender a perder.', 'Sufrió su mayor pérdida cuando tenía 19 años.', 'Su padre murió de cáncer.', 'Y Paul salió por las calles vendiendo marihuana y cocaína crack.', 'Esta es la misma droga en la que tu madre estaba enganchada.', 'La ausencia de mi padre me permitió dar ese paso porque nunca habría hecho eso si hubiera estado por aquí.', 'Tenía demasiado respeto por él.', 'Si no es algo que me sentaría aquí y glorificaría.', 'Casi suena como si fuéramos un estafador de tiempo completo.', 'Oh, sí.', 'Pero Jeff Bezos es un estafador.', 'Creo que no.', 'Phil Knight era el máximo estafador.', 'La diferencia es que podrían ir con su plan y su idea de negocio y conseguir que alguien crea en ellos.', 'No importaba la idea que tuviera.', 'No hay camino para llegar allí.', 'Encontró uno a través de un golpe de suerte.', 'En el aeropuerto de Akron Canton en 2001, Paul llevaba una camiseta de retroceso como esta que llamó la atención de otro viajero, sensación de aro de la escuela secundaria LeBron James.', '¿Qué viste en él?', 'Empezó con él, ya sabes, usando una camiseta de retroceso que, ya sabes, amaba.', 'Pero a medida que hablamos de deportes, empezamos a evolucionar e incluso a hablar más y más sólo de la vida y de nuestra educación, de nuestras madres y nuestras comunidades y cosas de esa naturaleza y que simplemente golpeó un núcleo.', 'Cuando James entró en la NBA, contrató a Rich Paul como mano derecha.', 'Paul continuó trabajando para el agente de LeBron y observó, escuchó y aprendió.', 'Entiendo que irías a reuniones con gente como Warren Buffett.', 'Estar en esas habitaciones es mucho mejor escuchar que hablar.', 'Si escuchas, podrías aprender algo y empezar a trabajar por tu cuenta.', 'Después de sólo cuatro años, no tuvo éxito por su cuenta y lanzó Clutch Sports Group en 2012.', 'LeBron James fue con él.', 'Cuando empezaste esto, te subestimaron.', 'No sólo se me subestimó, sino que tampoco se me quería.', 'No parecía el éxito de nuestra industria, especialmente de un lugar de toma de decisiones.', 'Y quería interrumpir la industria.', 'Quería ser impactante, pero quería venir de un lugar de propósito.', 'En 2013, con su primera negociación como agente de la guardia de Phoenix Sun, Eric Bledso, demostró que los detractores estaban equivocados.', 'Dijo que los soles habían ofrecido $28 millones.', 'Y luego 48 millones de dólares.', '¿Y lo rechazaste?', 'Sí.', 'Pero, ¿qué había en la línea?', '¿Mi carrera?', 'Todo el mundo llamaba y decía que estaba loco.', 'No sabe lo que está haciendo.', 'Tiene experiencia.', 'Suena como si estuvieras muy cómodo rodando los dados.', 'Nací como un patinete de dados.', 'Su apuesta valió la pena.', 'Después de aguantar duro durante un año, Clutch consiguió a Bledso un trato de 70 millones de dólares, 42 millones más que la primera oferta del sol.', 'Gran habitación.', 'Hoy, Clutch tiene 70 empleados con oficinas en Los Ángeles, Nueva York y Atlanta.', 'Ambos están en la misma clase de draft.', 'Paul se asoció con Powerhouse Agency, UTA, para ampliar el alcance de Clutch.', 'Tuve que construir una compañía de varios $100 millones para que la gente creyera en mí.', 'Y siguen siendo dudas.', 'Los críticos dicen que sólo tiene éxito por su relación contigo.', 'Quiero decir, es decepcionante escuchar eso.', 'Pero le diste una oportunidad.', 'Sí.', 'Y no le doy muchas oportunidades a la gente.', 'Y se fue más allá de lo que se imaginaba.', 'Rich Paul ahora tiene un nuevo zapato de la firma del equilibrio, una primera vez para un agente.', 'Su compañero es más famoso que él.', 'Lleva dos años y medio en una relación con Adele.', 'Adele, ella le dio un grito a los Grammys.', 'Oh, Dios, Rich.', 'Pensó que había dicho, no llores.', 'Si ganas algo esta noche, no llores.', 'Y aquí estoy llorando.', 'Un par de semanas más tarde en su fiesta de juego all-star, los amigos de Paul reconocieron sus logros con un reloj de $140,000.Vaya.', 'Vaya.', 'Vaya.', '¿Tienes que pellizcarte a veces?', 'Todo el tiempo, lo tuve peor que mucha gente, pero evolucioné, maduré, transformé.', '¿Cómo se siente?', 'Se siente genial.', 'Se siente ganado.', 'Sabes, no se dio con seguridad.', 'Se ganó, lo cual es bueno.', 'Me gusta eso.']\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 288)\n",
            " > after interpolation : torch.Size([1, 80, 432])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 198)\n",
            " > after interpolation : torch.Size([1, 80, 297])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 310)\n",
            " > after interpolation : torch.Size([1, 80, 465])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 313)\n",
            " > after interpolation : torch.Size([1, 80, 469])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 112)\n",
            " > after interpolation : torch.Size([1, 80, 168])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 341)\n",
            " > after interpolation : torch.Size([1, 80, 511])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 169)\n",
            " > after interpolation : torch.Size([1, 80, 253])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 338)\n",
            " > after interpolation : torch.Size([1, 80, 507])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 108)\n",
            " > after interpolation : torch.Size([1, 80, 162])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 120)\n",
            " > after interpolation : torch.Size([1, 80, 180])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 84)\n",
            " > after interpolation : torch.Size([1, 80, 126])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 63)\n",
            " > after interpolation : torch.Size([1, 80, 94])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 53)\n",
            " > after interpolation : torch.Size([1, 80, 79])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 477)\n",
            " > after interpolation : torch.Size([1, 80, 715])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 196)\n",
            " > after interpolation : torch.Size([1, 80, 294])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 70)\n",
            " > after interpolation : torch.Size([1, 80, 105])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 203)\n",
            " > after interpolation : torch.Size([1, 80, 304])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 363)\n",
            " > after interpolation : torch.Size([1, 80, 544])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 119)\n",
            " > after interpolation : torch.Size([1, 80, 178])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 235)\n",
            " > after interpolation : torch.Size([1, 80, 352])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 207)\n",
            " > after interpolation : torch.Size([1, 80, 310])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 78)\n",
            " > after interpolation : torch.Size([1, 80, 117])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 74)\n",
            " > after interpolation : torch.Size([1, 80, 111])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 40)\n",
            " > after interpolation : torch.Size([1, 80, 60])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 67)\n",
            " > after interpolation : torch.Size([1, 80, 100])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 50)\n",
            " > after interpolation : torch.Size([1, 80, 75])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 334)\n",
            " > after interpolation : torch.Size([1, 80, 501])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 350)\n",
            " > after interpolation : torch.Size([1, 80, 525])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 285)\n",
            " > after interpolation : torch.Size([1, 80, 427])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 179)\n",
            " > after interpolation : torch.Size([1, 80, 268])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 293)\n",
            " > after interpolation : torch.Size([1, 80, 439])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 83)\n",
            " > after interpolation : torch.Size([1, 80, 124])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 55)\n",
            " > after interpolation : torch.Size([1, 80, 82])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 275)\n",
            " > after interpolation : torch.Size([1, 80, 412])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 110)\n",
            " > after interpolation : torch.Size([1, 80, 165])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 147)\n",
            " > after interpolation : torch.Size([1, 80, 220])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 158)\n",
            " > after interpolation : torch.Size([1, 80, 237])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 380)\n",
            " > after interpolation : torch.Size([1, 80, 570])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 260)\n",
            " > after interpolation : torch.Size([1, 80, 390])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 107)\n",
            " > after interpolation : torch.Size([1, 80, 160])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 101)\n",
            " > after interpolation : torch.Size([1, 80, 151])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 324)\n",
            " > after interpolation : torch.Size([1, 80, 486])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 459)\n",
            " > after interpolation : torch.Size([1, 80, 688])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 329)\n",
            " > after interpolation : torch.Size([1, 80, 493])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 100)\n",
            " > after interpolation : torch.Size([1, 80, 150])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 24)\n",
            " > after interpolation : torch.Size([1, 80, 36])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 270)\n",
            " > after interpolation : torch.Size([1, 80, 405])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 422)\n",
            " > after interpolation : torch.Size([1, 80, 633])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 81)\n",
            " > after interpolation : torch.Size([1, 80, 121])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 286)\n",
            " > after interpolation : torch.Size([1, 80, 429])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 116)\n",
            " > after interpolation : torch.Size([1, 80, 174])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 301)\n",
            " > after interpolation : torch.Size([1, 80, 451])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 427)\n",
            " > after interpolation : torch.Size([1, 80, 640])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 100)\n",
            " > after interpolation : torch.Size([1, 80, 150])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 118)\n",
            " > after interpolation : torch.Size([1, 80, 177])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 70)\n",
            " > after interpolation : torch.Size([1, 80, 105])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 290)\n",
            " > after interpolation : torch.Size([1, 80, 435])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 117)\n",
            " > after interpolation : torch.Size([1, 80, 175])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 202)\n",
            " > after interpolation : torch.Size([1, 80, 303])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 235)\n",
            " > after interpolation : torch.Size([1, 80, 352])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 181)\n",
            " > after interpolation : torch.Size([1, 80, 271])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 79)\n",
            " > after interpolation : torch.Size([1, 80, 118])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 56)\n",
            " > after interpolation : torch.Size([1, 80, 84])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 55)\n",
            " > after interpolation : torch.Size([1, 80, 82])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 338)\n",
            " > after interpolation : torch.Size([1, 80, 507])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 124)\n",
            " > after interpolation : torch.Size([1, 80, 186])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 461)\n",
            " > after interpolation : torch.Size([1, 80, 691])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 410)\n",
            " > after interpolation : torch.Size([1, 80, 615])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 277)\n",
            " > after interpolation : torch.Size([1, 80, 415])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 392)\n",
            " > after interpolation : torch.Size([1, 80, 588])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 82)\n",
            " > after interpolation : torch.Size([1, 80, 123])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 258)\n",
            " > after interpolation : torch.Size([1, 80, 387])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 95)\n",
            " > after interpolation : torch.Size([1, 80, 142])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 52)\n",
            " > after interpolation : torch.Size([1, 80, 78])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 137)\n",
            " > after interpolation : torch.Size([1, 80, 205])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 27)\n",
            " > after interpolation : torch.Size([1, 80, 40])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 96)\n",
            " > after interpolation : torch.Size([1, 80, 144])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 103)\n",
            " > after interpolation : torch.Size([1, 80, 154])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 127)\n",
            " > after interpolation : torch.Size([1, 80, 190])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 188)\n",
            " > after interpolation : torch.Size([1, 80, 282])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 104)\n",
            " > after interpolation : torch.Size([1, 80, 156])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 236)\n",
            " > after interpolation : torch.Size([1, 80, 354])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 185)\n",
            " > after interpolation : torch.Size([1, 80, 277])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 324)\n",
            " > after interpolation : torch.Size([1, 80, 486])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 115)\n",
            " > after interpolation : torch.Size([1, 80, 172])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 163)\n",
            " > after interpolation : torch.Size([1, 80, 244])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 203)\n",
            " > after interpolation : torch.Size([1, 80, 304])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 27)\n",
            " > after interpolation : torch.Size([1, 80, 40])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 116)\n",
            " > after interpolation : torch.Size([1, 80, 174])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 37)\n",
            " > after interpolation : torch.Size([1, 80, 55])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 113)\n",
            " > after interpolation : torch.Size([1, 80, 169])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 336)\n",
            " > after interpolation : torch.Size([1, 80, 504])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 103)\n",
            " > after interpolation : torch.Size([1, 80, 154])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 93)\n",
            " > after interpolation : torch.Size([1, 80, 139])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 140)\n",
            " > after interpolation : torch.Size([1, 80, 210])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 349)\n",
            " > after interpolation : torch.Size([1, 80, 523])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 229)\n",
            " > after interpolation : torch.Size([1, 80, 343])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 293)\n",
            " > after interpolation : torch.Size([1, 80, 439])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 191)\n",
            " > after interpolation : torch.Size([1, 80, 286])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 187)\n",
            " > after interpolation : torch.Size([1, 80, 280])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 229)\n",
            " > after interpolation : torch.Size([1, 80, 343])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 355)\n",
            " > after interpolation : torch.Size([1, 80, 532])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 82)\n",
            " > after interpolation : torch.Size([1, 80, 123])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 141)\n",
            " > after interpolation : torch.Size([1, 80, 211])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 211)\n",
            " > after interpolation : torch.Size([1, 80, 316])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 324)\n",
            " > after interpolation : torch.Size([1, 80, 486])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 106)\n",
            " > after interpolation : torch.Size([1, 80, 159])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 242)\n",
            " > after interpolation : torch.Size([1, 80, 363])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 219)\n",
            " > after interpolation : torch.Size([1, 80, 328])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 131)\n",
            " > after interpolation : torch.Size([1, 80, 196])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 81)\n",
            " > after interpolation : torch.Size([1, 80, 121])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 130)\n",
            " > after interpolation : torch.Size([1, 80, 195])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 79)\n",
            " > after interpolation : torch.Size([1, 80, 118])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 59)\n",
            " > after interpolation : torch.Size([1, 80, 88])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 195)\n",
            " > after interpolation : torch.Size([1, 80, 292])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 114)\n",
            " > after interpolation : torch.Size([1, 80, 171])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 88)\n",
            " > after interpolation : torch.Size([1, 80, 132])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 54)\n",
            " > after interpolation : torch.Size([1, 80, 81])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 321)\n",
            " > after interpolation : torch.Size([1, 80, 481])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 128)\n",
            " > after interpolation : torch.Size([1, 80, 192])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 271)\n",
            " > after interpolation : torch.Size([1, 80, 406])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 327)\n",
            " > after interpolation : torch.Size([1, 80, 490])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 80)\n",
            " > after interpolation : torch.Size([1, 80, 120])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 220)\n",
            " > after interpolation : torch.Size([1, 80, 330])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 165)\n",
            " > after interpolation : torch.Size([1, 80, 247])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 94)\n",
            " > after interpolation : torch.Size([1, 80, 141])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 139)\n",
            " > after interpolation : torch.Size([1, 80, 208])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 129)\n",
            " > after interpolation : torch.Size([1, 80, 193])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 332)\n",
            " > after interpolation : torch.Size([1, 80, 498])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 113)\n",
            " > after interpolation : torch.Size([1, 80, 169])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 184)\n",
            " > after interpolation : torch.Size([1, 80, 276])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 141)\n",
            " > after interpolation : torch.Size([1, 80, 211])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 61)\n",
            " > after interpolation : torch.Size([1, 80, 91])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 109)\n",
            " > after interpolation : torch.Size([1, 80, 163])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 114)\n",
            " > after interpolation : torch.Size([1, 80, 171])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 66)\n",
            " > after interpolation : torch.Size([1, 80, 99])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 479)\n",
            " > after interpolation : torch.Size([1, 80, 718])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 28)\n",
            " > after interpolation : torch.Size([1, 80, 42])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 28)\n",
            " > after interpolation : torch.Size([1, 80, 42])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 279)\n",
            " > after interpolation : torch.Size([1, 80, 418])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 65)\n",
            " > after interpolation : torch.Size([1, 80, 97])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 65)\n",
            " > after interpolation : torch.Size([1, 80, 97])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 116)\n",
            " > after interpolation : torch.Size([1, 80, 174])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 84)\n",
            " > after interpolation : torch.Size([1, 80, 126])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 53)\n",
            " > after interpolation : torch.Size([1, 80, 79])\n",
            " > Processing time: 492.6797671318054\n",
            " > Real-time factor: 0.5143031278386537\n",
            " > Text splitted to sentences.\n",
            "['No desde que Watergate ha estado un Fiscal General en el centro de tal tormenta de fuego.', 'El Departamento de Justicia de Merrick Garland está procesando tanto al ex presidente Trump como al hijo del presidente Biden.', 'Atrapado en el medio como este ex fiscal de 70 años y juez respetado con una larga historia como moderado.', 'Vimos a Garland el viernes en Washington.', 'Nos dijo que dedicó su vida al estado de derecho debido a la lucha de su familia por escapar del Holocausto.', 'Ahora es responsable de los enjuiciamientos que darán forma al futuro de la nación.', 'En una rara entrevista, el Fiscal General nos dijo que en los juicios de Trump y Biden que se avecinan, sus fiscales perseguirán la justicia sin temor y sin favor.', 'La historia continuará en un momento.', 'No tenemos una regla para los republicanos y otra para los demócratas.', 'No tenemos una regla para los enemigos y otra para los amigos.', 'No tenemos una regla para los poderosos y otra para los impotentes, para los más ricos, para los pobres, basada en el origen étnico.', 'Sólo tenemos una regla.', 'Y esa regla es que seguimos los hechos y la ley, y llegamos a las decisiones requeridas por la Constitución, y protegemos las libertades civiles.', '¿Está diciendo esencialmente, como Fiscal General del pueblo americano, que confíe en mí?', 'Bueno, al final, supongo que sí.', 'Al final, ven a confiar.', 'Pero no soy solo yo.', 'Son décadas de las normas de este departamento que son parte del ADN de los fiscales de carrera que están dirigiendo la investigación y supervisando las investigaciones de las que estás hablando.', 'El ex presidente Trump enfrenta dos juicios federales.', 'Y por supuestamente acumular documentos clasificados y encubrirlo.', 'El otro, por supuestamente conspirar para tomar el poder después de las elecciones de 2020.', 'El Fiscal General Garland ha dicho poco sobre esto, y queríamos entender por qué.', 'Bueno, creo que lo primero que hay que entender es porque estos son casos pendientes, porque hay dos acusaciones federales, la regla de larga data en el Departamento de Justicia es que no podemos comentar sobre casos pendientes.', '¿De dónde viene esa regla?', '¿Cuál es el punto?', 'Una razón es proteger la privacidad y las libertades civiles de la persona que está bajo investigación.', 'Es para proteger a los testigos que también pueden o no hacerse públicos más tarde en una investigación.', 'Y finalmente, es para proteger la propia investigación.', 'Las investigaciones se llevan a cabo en muchas direcciones diferentes, llegando finalmente a una fructificación, una decisión de cobrar o no cobrar, sobre una cosa en particular o no.', 'Y si los testigos y los posibles sujetos sabían todo lo que los investigadores habían mirado previamente y estaban a punto de mirar, bien podría cambiar el testimonio.', 'Podría hacer que los testigos no estuvieran disponibles para nosotros.', 'Y esto no es propio de las investigaciones de Trump.', 'Esta es una regla para todas las investigaciones.', 'Esto es parte de lo que llamamos nuestro Manual de Justicia.', 'Ha estado allí por lo menos 30 años y probablemente un poco más que eso.', 'Ayúdenos a entender el momento oportuno.', 'Estos procesos contra el ex presidente se están llevando a cabo durante la campaña.', 'Podrías argumentar que es el peor momento posible.', 'El Departamento de Justicia tiene prácticas generales sobre no dar pasos significativos o presentar cargos dentro de un mes o más de una elección.', 'Estamos claramente fuera de ese plazo en estos casos.', 'Los fiscales, los abogados especiales, siguen los hechos y la ley a donde dirigen.', 'Cuando han obtenido la cantidad de pruebas necesarias para tomar una decisión de cargo y han decidido que un cargo está justificado, es cuando presentan sus casos.', 'La propia investigación ha determinado el momento.', 'Sí, exactamente correcto.', 'Sus críticos dicen que es hora de arruinar las oportunidades del Sr.', 'Trump en las elecciones.', 'Bueno, eso no es del todo cierto.', 'Los fiscales del Departamento de Justicia no son partidistas.', 'No permiten que las consideraciones partidistas jueguen ningún papel en sus determinaciones.', 'El fiscal en los casos de Trump es Jack Smith.', 'Garland lo nombró Asesor Especial.', 'Ese es un trabajo bajo las regulaciones del Departamento de Justicia diseñado para darle a Smith una amplia independencia del Departamento y de la Casa Blanca.', 'El aspecto más importante del reglamento es que el Asesor Especial no está sujeto a la supervisión cotidiana de nadie en el Departamento de Justicia.', 'Usted no está en comunicación con el Presidente ni con ningún miembro de su administración con respecto a la investigación del ex presidente Trump.', 'No, no lo soy.', 'Si el presidente Biden le pidiera que tomara medidas con respecto a la investigación de Trump, ¿cuál sería su reacción?', 'Estoy seguro de que eso no sucederá, pero no haría nada al respecto.', 'Y si fuera necesario, renunciaría.', 'Pero no tiene sentido que algo así suceda.', '¿Alguna vez le ha tenido que decir que no se haga cargo de estas investigaciones, Sr.', 'Presidente?', 'No, porque nunca ha intentado poner manos a la obra en estas investigaciones.', 'Por otra parte, el propio Presidente Biden es objeto de una investigación de la Fiscalía Especial sobre si mantuvo indebidamente documentos clasificados después de haber sido Vicepresidente.', 'Su hijo, Hunter Biden, es el objetivo de una investigación de cuatro años sobre sus negocios y sus impuestos.', 'Ha sido acusado de mentir sobre el abuso de drogas cuando compró un arma.', 'Los republicanos acusan al Asesor Especial David Weiss de caminar lentamente en la investigación de Hunter Biden.', 'La acusación es, Sr.', 'Fiscal General, que lo que en algunos sectores se describe como el Departamento de Justicia de Biden está tomándolo con calma en el hijo del Presidente.', 'Bueno, mira, esta investigación comenzó bajo David Weiss.', 'David Weiss es un fiscal de carrera de larga data, y fue nombrado por el Sr.', 'Trump como el Fiscal de los Estados Unidos para el Distrito de Delaware.', 'Prometí en mi audiencia de nominación que continuaría en esa posición, y que no interferiría en esta investigación.', 'Usted no está participando en esas decisiones.', 'No, el Sr.', 'Weiss está tomando esas decisiones.', 'La Casa Blanca no está tratando de influir en esas decisiones.', 'Por supuesto que no.', 'Y él dijo, no tendremos que tomar su palabra para ello.', 'Según el reglamento del Departamento de Justicia, un abogado especial debe redactar un informe final, que haré público en la medida en que lo permita la ley.', 'Eso no es necesario para explicar las decisiones de su fiscal, sus decisiones de procesar o no procesar, y sus decisiones estratégicas en el camino.', 'Por lo general, los abogados especiales han testificado al final de sus informes, y espero que así sea aquí.', '¿Cómo está tu relación con el Presidente?', 'Debe estar helada.', 'Tengo una buena relación de trabajo con el Presidente.', 'Bueno, tal vez, pero tal vez no cerca.', 'El Presidente abordó la cuestión en agosto cuando vio a Garland en un evento de la Casa Blanca.', '¿Dónde te ha visto el general Garland desde hace mucho tiempo?', 'Me alegro de verte.', 'Secretario de la Patria, cree que estoy bromeando, no lo estoy.', 'El Fiscal General Garland dirige a 115.000 empleados, fiscales, agentes del FBI y otras fuerzas del orden federales.', 'Ahora se asigna seguridad adicional para proteger a jueces y fiscales después de que los casos de Trump atrajeran amenazas de muerte.', 'La violencia política es una de las preocupaciones más graves de Garland.', 'La gente puede discutir entre sí tanto como quiera y tan vociferantemente como quiera.', 'Lo único que no pueden hacer es utilizar la violencia y las amenazas de violencia para alterar el resultado.', 'Un aspecto importante de esto es el propio pueblo estadounidense.', 'El pueblo estadounidense debe protegerse el uno al otro.', 'Deben asegurarse de que se traten unos a otros con cortesía y bondad.', 'Escuche las opiniones opuestas.', 'Argumentar tan vociferantemente como quieran, pero abstenerse de la violencia y las amenazas de violencia.', 'Esa es la única manera en que esta democracia sobrevivirá.', '¿Por qué te sientes tan fuerte sobre eso?', 'Bueno, lo siento por varias razones y muchas cosas que he visto, pero para mi propia familia que huyó de la persecución religiosa en Europa y algunos miembros que no sobrevivieron cuando llegaron a los Estados Unidos, los Estados Unidos protegieron.', 'Garantizaba que podían practicar su religión, que podían votar, que podían hacer todo lo que pensaban que una democracia proporcionaría.', 'Esa es la diferencia entre este país y muchos otros países.', 'Es mi responsabilidad, es responsabilidad del Departamento de Justicia asegurar que esa diferencia continúe, que nos protejamos el uno al otro.', 'Dos de sus antepasados fueron asesinados en el Holocausto.', 'Sí.', '¿Por eso te dedicaste a la ley?', 'Sí.', 'Por eso diría que por eso me dediqué al estado de derecho, al servicio público, a intentar y asegurar que el estado de derecho gobierne este país y siga gobernando este país.', 'Merrick Garland ha pasado una vida en la ley.', 'M-E-R-R-I-C-K, G-A-R-L-A-N-D, es el fiscal adjunto general.', 'En Justicia, supervisó el caso de los bombardeos de Oklahoma City, un acto de terrorismo político.', 'Más tarde, después de casi dos décadas como juez federal de apelaciones, fue nominado a la Corte Suprema de Estados Unidos por el presidente Obama.', 'Pero los republicanos estancaron la nominación durante diez meses hasta que Donald Trump prestó juramento.', 'El presidente electo Biden eligió a Garland para Fiscal General.', 'El mismo día, el Capitolio fue atacado.', 'Eso se convirtió en una de las investigaciones más grandes de la historia del departamento.', 'Hemos arrestado y presentado cargos contra más de 1.100 personas.', 'Hay más por venir.', 'Los videos que cada persona tenía en sus teléfonos, que las cámaras de seguridad tenían, que los transeúntes tenían, que los medios tenían en ese momento, revelan caras, algunas de las cuales todavía no hemos podido conectar con la gente.', 'Usted está buscando nuevos sospechosos, nuevos acusados todavía.', 'Sí, eso no es que sean nuevos sospechosos, pero son personas que aún no hemos encontrado.', '¿Por qué estos juicios significan tanto para ti?', 'Este es un aspecto fundamental de nuestra democracia.', 'Si no podemos asegurarnos de que este tipo de comportamiento no se repita, ocurrirá.', 'Los enjuiciamientos que llevamos a cabo son disuasorios de que eso ocurra.', 'Garland sabe que será vilipendiado sin importar cómo se decidan los casos invitados por Trump.', 'Su trabajo, nos dijo, era tomar las flechas para el departamento.', 'Él ha aprendido a abrazar el dolor que viene con el trabajo.', 'El más joven en este momento es Riot Mitchell, para siempre de ocho meses de edad.', 'Vimos eso en la sede de la DEA, donde estaba rodeado por los que habían perdido a causa de la epidemia de opioides y sus afligidas familias.', 'Reunirse con ellos, nos dijo, le recuerda por qué lucha y por quién está luchando.', 'Gracias por estar aquí y escucharnos.', 'Represento al pueblo americano.', 'No represento al presidente.', 'Represento al pueblo americano.', 'Y de la misma manera, no soy el fiscal del Congreso.', 'Trabajo para el pueblo americano.', 'Y si la democracia es un tema emocional para Merrick Garland, tal vez es porque ha sido testigo de cómo de repente puede ser amenazada en Oklahoma City y Washington, D.C. Cuando la historia de este extraordinario tiempo está escrita, ¿qué es lo mejor que Merrick Garland puede esperar?', 'Mira, creo que es lo mejor que cualquier funcionario público puede esperar que hayamos hecho lo mejor que hemos hecho, que transmitimos un Departamento de Justicia que continúa persiguiendo el estado de derecho y protegiéndola.', 'Y es lo mismo que cada generación tiene que esperar que podamos pasar nuestra democracia en el orden de trabajo a la próxima generación que toma la antorcha y es responsable cuando hemos terminado de continuar con ese trabajo.']\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 285)\n",
            " > after interpolation : torch.Size([1, 80, 427])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 410)\n",
            " > after interpolation : torch.Size([1, 80, 615])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 392)\n",
            " > after interpolation : torch.Size([1, 80, 588])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 149)\n",
            " > after interpolation : torch.Size([1, 80, 223])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 331)\n",
            " > after interpolation : torch.Size([1, 80, 496])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 257)\n",
            " > after interpolation : torch.Size([1, 80, 385])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 112)\n",
            " > after interpolation : torch.Size([1, 80, 168])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 248)\n",
            " > after interpolation : torch.Size([1, 80, 372])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 208)\n",
            " > after interpolation : torch.Size([1, 80, 312])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 80)\n",
            " > after interpolation : torch.Size([1, 80, 120])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 276)\n",
            " > after interpolation : torch.Size([1, 80, 414])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 146)\n",
            " > after interpolation : torch.Size([1, 80, 219])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 104)\n",
            " > after interpolation : torch.Size([1, 80, 156])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 70)\n",
            " > after interpolation : torch.Size([1, 80, 105])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 190)\n",
            " > after interpolation : torch.Size([1, 80, 285])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 255)\n",
            " > after interpolation : torch.Size([1, 80, 382])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 306)\n",
            " > after interpolation : torch.Size([1, 80, 459])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 282)\n",
            " > after interpolation : torch.Size([1, 80, 423])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 336)\n",
            " > after interpolation : torch.Size([1, 80, 504])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 336)\n",
            " > after interpolation : torch.Size([1, 80, 504])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 188)\n",
            " > after interpolation : torch.Size([1, 80, 282])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 221)\n",
            " > after interpolation : torch.Size([1, 80, 331])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 174)\n",
            " > after interpolation : torch.Size([1, 80, 261])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 172)\n",
            " > after interpolation : torch.Size([1, 80, 258])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 181)\n",
            " > after interpolation : torch.Size([1, 80, 271])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 250)\n",
            " > after interpolation : torch.Size([1, 80, 375])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 141)\n",
            " > after interpolation : torch.Size([1, 80, 211])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 264)\n",
            " > after interpolation : torch.Size([1, 80, 396])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 168)\n",
            " > after interpolation : torch.Size([1, 80, 252])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 488)\n",
            " > after interpolation : torch.Size([1, 80, 732])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 182)\n",
            " > after interpolation : torch.Size([1, 80, 273])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 331)\n",
            " > after interpolation : torch.Size([1, 80, 496])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 158)\n",
            " > after interpolation : torch.Size([1, 80, 237])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 117)\n",
            " > after interpolation : torch.Size([1, 80, 175])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 212)\n",
            " > after interpolation : torch.Size([1, 80, 318])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 80)\n",
            " > after interpolation : torch.Size([1, 80, 120])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 138)\n",
            " > after interpolation : torch.Size([1, 80, 207])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 213)\n",
            " > after interpolation : torch.Size([1, 80, 319])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 321)\n",
            " > after interpolation : torch.Size([1, 80, 481])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 146)\n",
            " > after interpolation : torch.Size([1, 80, 219])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 100)\n",
            " > after interpolation : torch.Size([1, 80, 150])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 486)\n",
            " > after interpolation : torch.Size([1, 80, 729])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 437)\n",
            " > after interpolation : torch.Size([1, 80, 655])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 50)\n",
            " > after interpolation : torch.Size([1, 80, 75])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 395)\n",
            " > after interpolation : torch.Size([1, 80, 592])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 254)\n",
            " > after interpolation : torch.Size([1, 80, 381])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 119)\n",
            " > after interpolation : torch.Size([1, 80, 178])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 135)\n",
            " > after interpolation : torch.Size([1, 80, 202])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 279)\n",
            " > after interpolation : torch.Size([1, 80, 418])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 45)\n",
            " > after interpolation : torch.Size([1, 80, 67])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 289)\n",
            " > after interpolation : torch.Size([1, 80, 433])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 416)\n",
            " > after interpolation : torch.Size([1, 80, 624])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 238)\n",
            " > after interpolation : torch.Size([1, 80, 357])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 455)\n",
            " > after interpolation : torch.Size([1, 80, 682])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 68)\n",
            " > after interpolation : torch.Size([1, 80, 102])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 238)\n",
            " > after interpolation : torch.Size([1, 80, 357])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 243)\n",
            " > after interpolation : torch.Size([1, 80, 364])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 223)\n",
            " > after interpolation : torch.Size([1, 80, 334])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 384)\n",
            " > after interpolation : torch.Size([1, 80, 576])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 143)\n",
            " > after interpolation : torch.Size([1, 80, 214])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 35)\n",
            " > after interpolation : torch.Size([1, 80, 52])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 126)\n",
            " > after interpolation : torch.Size([1, 80, 189])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 200)\n",
            " > after interpolation : torch.Size([1, 80, 300])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 63)\n",
            " > after interpolation : torch.Size([1, 80, 94])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 197)\n",
            " > after interpolation : torch.Size([1, 80, 295])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 406)\n",
            " > after interpolation : torch.Size([1, 80, 609])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 55)\n",
            " > after interpolation : torch.Size([1, 80, 82])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 175)\n",
            " > after interpolation : torch.Size([1, 80, 262])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 158)\n",
            " > after interpolation : torch.Size([1, 80, 237])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 302)\n",
            " > after interpolation : torch.Size([1, 80, 453])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 66)\n",
            " > after interpolation : torch.Size([1, 80, 99])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 222)\n",
            " > after interpolation : torch.Size([1, 80, 333])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 475)\n",
            " > after interpolation : torch.Size([1, 80, 712])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 249)\n",
            " > after interpolation : torch.Size([1, 80, 373])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 285)\n",
            " > after interpolation : torch.Size([1, 80, 427])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 336)\n",
            " > after interpolation : torch.Size([1, 80, 504])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 214)\n",
            " > after interpolation : torch.Size([1, 80, 321])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 161)\n",
            " > after interpolation : torch.Size([1, 80, 241])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 242)\n",
            " > after interpolation : torch.Size([1, 80, 363])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 116)\n",
            " > after interpolation : torch.Size([1, 80, 174])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 378)\n",
            " > after interpolation : torch.Size([1, 80, 567])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 174)\n",
            " > after interpolation : torch.Size([1, 80, 261])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 448)\n",
            " > after interpolation : torch.Size([1, 80, 672])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 198)\n",
            " > after interpolation : torch.Size([1, 80, 297])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 497)\n",
            " > after interpolation : torch.Size([1, 80, 745])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 188)\n",
            " > after interpolation : torch.Size([1, 80, 282])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 139)\n",
            " > after interpolation : torch.Size([1, 80, 208])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 174)\n",
            " > after interpolation : torch.Size([1, 80, 261])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 387)\n",
            " > after interpolation : torch.Size([1, 80, 580])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 346)\n",
            " > after interpolation : torch.Size([1, 80, 519])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 214)\n",
            " > after interpolation : torch.Size([1, 80, 321])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 168)\n",
            " > after interpolation : torch.Size([1, 80, 252])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 268)\n",
            " > after interpolation : torch.Size([1, 80, 402])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 280)\n",
            " > after interpolation : torch.Size([1, 80, 420])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 65)\n",
            " > after interpolation : torch.Size([1, 80, 97])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 242)\n",
            " > after interpolation : torch.Size([1, 80, 363])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 332)\n",
            " > after interpolation : torch.Size([1, 80, 498])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 176)\n",
            " > after interpolation : torch.Size([1, 80, 264])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 306)\n",
            " > after interpolation : torch.Size([1, 80, 459])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 225)\n",
            " > after interpolation : torch.Size([1, 80, 337])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 295)\n",
            " > after interpolation : torch.Size([1, 80, 442])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 236)\n",
            " > after interpolation : torch.Size([1, 80, 354])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 160)\n",
            " > after interpolation : torch.Size([1, 80, 240])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 284)\n",
            " > after interpolation : torch.Size([1, 80, 426])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 278)\n",
            " > after interpolation : torch.Size([1, 80, 417])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 134)\n",
            " > after interpolation : torch.Size([1, 80, 201])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 111)\n",
            " > after interpolation : torch.Size([1, 80, 166])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 98)\n",
            " > after interpolation : torch.Size([1, 80, 147])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 111)\n",
            " > after interpolation : torch.Size([1, 80, 166])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 205)\n",
            " > after interpolation : torch.Size([1, 80, 307])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 101)\n",
            " > after interpolation : torch.Size([1, 80, 151])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > Processing time: 490.1419768333435\n",
            " > Real-time factor: 0.506304220148938\n",
            " > Text splitted to sentences.\n",
            "['Israel ha comenzado lo que el Primer Ministro Benjamin Netanyahu llama la segunda etapa de la guerra, ampliando sus operaciones militares terrestres en Gaza.', 'Hablamos con el Vicepresidente Kamala Harris la semana pasada, ya que la administración de Biden estaba tratando de equilibrar la necesidad de Israel de tomar represalias contra Hamas con la necesidad urgente de obtener ayuda para el pueblo palestino.', 'La vicepresidenta Harris nos dijo que ella también está involucrada en los esfuerzos de la administración en la guerra en Ucrania, así como en innumerables problemas intratables, incluyendo la violencia con armas en el hogar.', 'Pero con el Medio Oriente en el borde de una navaja, empezamos nuestra conversación allí.', 'La historia continuará en un momento.', '¿Qué tan cerca está esto de convertirse en un conflicto regional que podría atraer tropas estadounidenses?', 'No tenemos absolutamente ninguna intención ni tenemos ningún plan para enviar tropas de combate a Israel o Gaza, punto.', 'El vicepresidente Harris nos dijo que Estados Unidos no le está diciendo a Israel qué hacer, sino que está proporcionando asesoramiento, equipo y apoyo diplomático.', 'Una organización terrorista, Hamas, mató a cientos de jóvenes en un concierto.', 'Según la mayoría de las estimaciones, al menos 1.400 israelíes han muerto.', 'Israel, sin ninguna duda, tiene derecho a defenderse.', 'Dicho esto, es muy importante que no haya connivencia entre Hamas y los palestinos.', 'Los palestinos merecen medidas iguales de seguridad y protección, libre determinación y dignidad.', 'Y hemos sido muy claros en el sentido de que hay que respetar las normas de la guerra y que hay una ayuda humanitaria que fluye.', 'Nos dijo que Estados Unidos quiere evitar que el conflicto se intensifique, pero eso está resultando difícil.', 'En las últimas dos semanas, Hezbolá en el Líbano y los hutíes en Yemen, ambos representantes de Irán han lanzado misiles, cohetes y drones contra Israel.', 'Y las milicias respaldadas por Irán han disparado contra las tropas estadounidenses estacionadas en Irak y Siria.', 'En respuesta, Estados Unidos lanzó ataques aéreos contra instalaciones de armas iraníes en Siria.', 'Si eso no fuera suficiente como señal para Irán y otros adversarios, el Pentágono también ha desplegado a dos grupos de ataque de portaaviones imponentes en la región.', '¿Y cuál es el mensaje a Irán?', 'No lo hagas.', 'Como dijo el presidente Biden, no lo hagas.', 'Exacto.', 'Y somos bastante sencillos.', 'Desde el ataque de Hamás contra Israel, la vicepresidenta dice que ha hablado con el presidente Isaac Herzog de Israel y se ha unido al presidente Biden en llamadas con el primer ministro Benjamin Netanyahu y el presidente de la Autoridad Palestina Mahmoud Abbas.', 'El Presidente Joe Biden nos dijo en una declaración, esto es tan alto en juego y compleja una situación como se pone.', 'Y Kamala es mi socio en todo esto.', 'Nos dijo que el consejo y el consejo de Harris son invaluables.', 'Cuando era vicepresidente, el Sr.', 'Biden dijo famosamente que quería ser la última persona en la sala con el Presidente Obama.', '¿Tiene esa relación con el presidente Biden?', 'Sí.', 'Tú sí.', 'Sí.', 'Y me tomo esa responsabilidad muy en serio.', '¿Con qué frecuencia te reúnes con él?', 'Muchas veces al día, muy a menudo, a menos que él o yo estemos viajando.', 'Allí, en total acuerdo, Estados Unidos debe apoyar a Israel y Ucrania ante las democracias bajo ataque.', 'Estamos tan comprometidos con Ucrania como siempre lo hemos estado con autorizar ayuda adicional para defenderse de la agresión no provocada de Rusia.', 'Eso no va a vacilar.', '¿Esta guerra en el Medio Oriente pone a Ucrania en un segundo plano?', 'No para nosotros.', 'No, no nos pone en un segundo plano en absoluto.', 'El Vicepresidente Harris ha visitado 19 países y se ha reunido con más de 100 líderes mundiales.', 'Pero últimamente, ella ha sido la persona clave de la administración en las prioridades domésticas, viajando por el país, hablando de los temas clave de los demócratas antes de las elecciones de 2024.', 'Porque ella espera encender la base, pero están obligados a inflamar el GOP.Fue a Carolina del Norte para conmemorar el aniversario de la anulación por la Corte Suprema de Roe v. Wade.', '¿Cómo se atreven a atacar nuestros derechos fundamentales?', '¿Cómo se atreven a atacar nuestra libertad?', 'En Virginia, eran armas.', 'Nuestra nación está siendo destrozada por la violencia armada.', 'Nos unimos al vicepresidente y segundo caballero Doug Emhoff en la Fuerza Aérea Dos para un viaje a Las Vegas.', 'Fueron cinco días después del ataque terrorista contra Israel.', 'Mientras estaba en el aire, el vicepresidente se unió a una videollamada segura con el presidente y sus equipos de seguridad nacional para discutir medidas para mantener la patria segura.', 'Una vez sobre el terreno en Las Vegas, la vicepresidenta Harris fue al Colegio del Sur de Nevada, la octava parada en su gira por la Universidad de Lucha por Nuestras Libertades.', 'Porque usted votó, Joe Biden es presidente de los Estados Unidos y yo soy vicepresidente de los Estados Unidos.', 'Porque votaste.', 'Pero a nivel nacional, la administración Biden-Harris no está generando el tipo de entusiasmo que está viendo en su gira.', 'Una encuesta reciente de CBS encontró que al comienzo del mandato del presidente Biden, el 70 por ciento de los jóvenes, menores de 30 años, dijeron que estaba haciendo un buen trabajo.', 'Ahora es menos del 50 por ciento.', '¿Por qué?', '¿Qué está pasando?', 'Si usted tira de lo que la gente joven siente sobre el clima y el calentamiento de nuestro planeta, tira como una de sus principales preocupaciones.', 'Cuando hablamos de lo que estamos haciendo con la deuda de préstamos estudiantiles, se eleva muy alto.', 'El reto que tenemos es una administración.', 'Tenemos que hacerle saber a la gente quién nos lo trajo.', 'Ese es nuestro reto.', 'Pero no es que el trabajo que estamos haciendo no sea muy, muy popular entre mucha gente.', 'Ella culpa a la desconexión en parte por la falta de cobertura mediática.', 'Aún así, la propia vicepresidenta no es muy popular ahora.', 'Pero el 41 por ciento de los adultos le dijo a CBS News que aprueban el trabajo que está haciendo, lo mismo para el presidente Biden.', 'Hablamos con ella el día antes de la carnicería en Maine, pero nos había dicho que los tiroteos en masa son más importantes que los números de las encuestas.', 'Usted tiene una cartera que incluye la violencia armada, la causa raíz de la migración.', 'Estos son algunos de los problemas más difíciles a los que se enfrenta el país.', 'Hemos hecho algunas de las leyes de seguridad de armas más importantes en 30 años.', 'Pero todavía necesitamos una prohibición de armas de asalto.', 'No tiene que ser así.', 'Hubo una prohibición de armas de asalto en un momento.', 'Caducó.', 'Vamos a renovarlo.', 'La mayoría de los estadounidenses dicen que no creen que estés haciendo un buen trabajo en la frontera.', 'Tú y la administración.', 'El número de personas que tratan de cruzar la frontera sur de Estados Unidos está en un máximo histórico.', 'No es ningún secreto que tenemos un sistema de inmigración roto.', 'A corto plazo, necesitamos una política fronteriza segura, ordenada y humana.', 'Y a largo plazo, necesitamos invertir en las causas profundas de la migración.', 'Pero la conclusión es que el Congreso tiene que actuar.', 'Vamos, participa en la solución en lugar de la jugabilidad política.', 'Si la política es un juego, Kamala Harris ha demostrado ser una jugadora inteligente, forjando una carrera que ha pasado de un principio a otro.', 'Hijo de una madre india y padre jamaiquino, fue la primera mujer fiscal de distrito de San Francisco.', 'La primera mujer en servir como fiscal general de California.', 'La primera mujer de color elegida senadora de California.', 'Que Dios me ayude.', 'Y la primera mujer de color en ser elegida vicepresidenta de los Estados Unidos.', 'Estar en esa posición única, ser el primero.', '¿Eso trae más presión?', 'Sin duda.', 'Sin duda.', 'Conoces a mi madre, ella diría, Kamala, que puedes ser la primera en hacer muchas cosas.', 'Asegúrate de que no seas el último.', 'Y entre las responsabilidades que llevo y que tal vez me imponga, esa es una de ellas.', 'Así que esto fue...Nos mostró la oficina ceremonial del vicepresidente.', 'Traje este busto de Thurgood Marshall.', 'Y siempre lo tengo sobre mi hombro derecho en el cajón.', 'El escritorio donde los vicepresidentes anteriores dejaron sus firmas.', 'Al Gore, Codorniz, Chaney, Harry Truman.', 'Algunos de estos hombres pasaron a ser presidente.', 'Pero Kamala Harris nos dijo que ella está enfocada en conseguir el boleto Biden-Harris reelecto el próximo año.', 'El Partido Republicano está usando sus bajas encuestas y la edad del presidente Biden como ariete.', 'Y algunos demócratas se están preocupando.', 'Estábamos hablando con algunos donantes demócratas.', 'Y nos han dicho que si algo le ocurriera al Presidente Biden, y él no es capaz de postularse, que habría un libre para todos para quien se postularía como presidente.', 'Estás en el punto en el que eso sería antinatural para que tú dieras un paso al frente.', 'Sin embargo, los donantes nos han dicho que, naturalmente, no encajarían en la línea.', '¿Por qué?', 'Bueno, en primer lugar, no voy a participar en esa hipotética porque Joe Biden está muy vivo y se presenta a la reelección.', 'Pero usted sabe, quiero decir, que es una preocupación y una preocupación legítima, diría yo.', 'He oído de muchas personas diferentes muchas cosas diferentes.', 'Pero déjame decirte, estoy concentrado en el trabajo.', 'De verdad.', 'Nuestra democracia está en juego, Bill.', 'Y francamente, en mi cabeza, no tengo tiempo para juegos de salón cuando tenemos un presidente que se presenta a la reelección.', 'Eso es.', 'Joe Biden.', 'La sabiduría convencional es que la mayoría de las elecciones presidenciales se ganan o se pierden en la economía.', 'Y mientras la inflación ha venido bajando, los precios de lo básico, como la comida y la vivienda, siguen siendo asombrosamente altos.', 'Entramos en el cargo durante el apogeo de una pandemia, desempleo sin precedentes.', 'Y debido a nuestras políticas económicas, ahora estamos reduciendo la inflación.', 'Hemos creado más de 14 millones de nuevos puestos de trabajo.', 'Hemos creado más de 800.000 nuevos empleos de fabricación.', 'Los salarios han subido.', 'Y así hemos visto un gran progreso.', 'Teniendo en cuenta lo que usted está planteando como sus logros, ¿tiene al actual líder del Partido Republicano, Donald Trump, frente a qué 91 cargos criminales?', 'He perdido la cuenta.', 'Sin embargo, el boleto de Biden-Harris está corriendo de cuello a cuello con Donald Trump.', '¿Por qué no estás 30 puntos por delante?', 'Bueno, no soy un canalla político, así que no voy a hablar de eso.', 'Pero lo que diré es esto.', 'Cuando el pueblo estadounidense es capaz de echar un vistazo a la hora de las elecciones en sus opciones, creo que la elección va a ser clara.', 'Bill, vamos a ganar.', 'Déjame decirte eso.', 'Vamos a ganar.', 'Y no estoy diciendo que va a ser fácil, pero vamos a ganar.', 'Lo dices con tanta convicción.', 'No tengo ninguna duda, pero tampoco tengo ninguna duda.', 'Va a ser mucho trabajo.', 'Y todos tendrán que participar.', 'Esto es una democracia.', 'Democracia.', 'Ella dijo esa palabra a menudo durante nuestra entrevista.', 'A pesar de las críticas y los bajos números de las encuestas, la ex fiscal Kamala Harris nos dijo que está dispuesta a confiar en el veredicto del pueblo estadounidense.', '¿Tienes que preguntarte por qué parece que la gente no escucha nuestro mensaje?', 'Lo miro más como vamos a seguir saliendo.', 'Y como con cualquier elección, tenemos que presentar nuestro caso al pueblo estadounidense.', 'Eso es parte de nuestra responsabilidad.', 'Y ese es este proceso.', 'Y eso es lo que es.', 'Y ese es un proceso justo.']\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 292)\n",
            " > after interpolation : torch.Size([1, 80, 438])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 112)\n",
            " > after interpolation : torch.Size([1, 80, 168])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 410)\n",
            " > after interpolation : torch.Size([1, 80, 615])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 293)\n",
            " > after interpolation : torch.Size([1, 80, 439])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 288)\n",
            " > after interpolation : torch.Size([1, 80, 432])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 210)\n",
            " > after interpolation : torch.Size([1, 80, 315])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 304)\n",
            " > after interpolation : torch.Size([1, 80, 456])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 341)\n",
            " > after interpolation : torch.Size([1, 80, 511])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 413)\n",
            " > after interpolation : torch.Size([1, 80, 619])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 364)\n",
            " > after interpolation : torch.Size([1, 80, 546])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 370)\n",
            " > after interpolation : torch.Size([1, 80, 555])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 352)\n",
            " > after interpolation : torch.Size([1, 80, 528])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 45)\n",
            " > after interpolation : torch.Size([1, 80, 67])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 136)\n",
            " > after interpolation : torch.Size([1, 80, 204])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 34)\n",
            " > after interpolation : torch.Size([1, 80, 51])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 107)\n",
            " > after interpolation : torch.Size([1, 80, 160])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 426)\n",
            " > after interpolation : torch.Size([1, 80, 639])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 109)\n",
            " > after interpolation : torch.Size([1, 80, 163])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 204)\n",
            " > after interpolation : torch.Size([1, 80, 306])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 127)\n",
            " > after interpolation : torch.Size([1, 80, 190])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 310)\n",
            " > after interpolation : torch.Size([1, 80, 465])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 28)\n",
            " > after interpolation : torch.Size([1, 80, 42])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 152)\n",
            " > after interpolation : torch.Size([1, 80, 228])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 287)\n",
            " > after interpolation : torch.Size([1, 80, 430])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 376)\n",
            " > after interpolation : torch.Size([1, 80, 564])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 478)\n",
            " > after interpolation : torch.Size([1, 80, 717])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 85)\n",
            " > after interpolation : torch.Size([1, 80, 127])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 67)\n",
            " > after interpolation : torch.Size([1, 80, 100])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 152)\n",
            " > after interpolation : torch.Size([1, 80, 228])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 354)\n",
            " > after interpolation : torch.Size([1, 80, 531])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 88)\n",
            " > after interpolation : torch.Size([1, 80, 132])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 182)\n",
            " > after interpolation : torch.Size([1, 80, 273])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 412)\n",
            " > after interpolation : torch.Size([1, 80, 618])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 197)\n",
            " > after interpolation : torch.Size([1, 80, 295])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 404)\n",
            " > after interpolation : torch.Size([1, 80, 606])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 50)\n",
            " > after interpolation : torch.Size([1, 80, 75])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 437)\n",
            " > after interpolation : torch.Size([1, 80, 655])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 108)\n",
            " > after interpolation : torch.Size([1, 80, 162])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 347)\n",
            " > after interpolation : torch.Size([1, 80, 520])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 158)\n",
            " > after interpolation : torch.Size([1, 80, 237])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 182)\n",
            " > after interpolation : torch.Size([1, 80, 273])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 64)\n",
            " > after interpolation : torch.Size([1, 80, 96])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 305)\n",
            " > after interpolation : torch.Size([1, 80, 457])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 234)\n",
            " > after interpolation : torch.Size([1, 80, 351])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 240)\n",
            " > after interpolation : torch.Size([1, 80, 360])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 481)\n",
            " > after interpolation : torch.Size([1, 80, 721])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 270)\n",
            " > after interpolation : torch.Size([1, 80, 405])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 282)\n",
            " > after interpolation : torch.Size([1, 80, 423])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 294)\n",
            " > after interpolation : torch.Size([1, 80, 441])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 198)\n",
            " > after interpolation : torch.Size([1, 80, 297])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 70)\n",
            " > after interpolation : torch.Size([1, 80, 105])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 171)\n",
            " > after interpolation : torch.Size([1, 80, 256])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 31)\n",
            " > after interpolation : torch.Size([1, 80, 46])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 63)\n",
            " > after interpolation : torch.Size([1, 80, 94])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 317)\n",
            " > after interpolation : torch.Size([1, 80, 475])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 73)\n",
            " > after interpolation : torch.Size([1, 80, 109])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 371)\n",
            " > after interpolation : torch.Size([1, 80, 556])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 217)\n",
            " > after interpolation : torch.Size([1, 80, 325])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 292)\n",
            " > after interpolation : torch.Size([1, 80, 438])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 275)\n",
            " > after interpolation : torch.Size([1, 80, 412])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 160)\n",
            " > after interpolation : torch.Size([1, 80, 240])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 232)\n",
            " > after interpolation : torch.Size([1, 80, 348])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 338)\n",
            " > after interpolation : torch.Size([1, 80, 507])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 201)\n",
            " > after interpolation : torch.Size([1, 80, 301])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 188)\n",
            " > after interpolation : torch.Size([1, 80, 282])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 56)\n",
            " > after interpolation : torch.Size([1, 80, 84])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 269)\n",
            " > after interpolation : torch.Size([1, 80, 403])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 167)\n",
            " > after interpolation : torch.Size([1, 80, 250])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 37)\n",
            " > after interpolation : torch.Size([1, 80, 55])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 37)\n",
            " > after interpolation : torch.Size([1, 80, 55])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 352)\n",
            " > after interpolation : torch.Size([1, 80, 528])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 110)\n",
            " > after interpolation : torch.Size([1, 80, 165])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 314)\n",
            " > after interpolation : torch.Size([1, 80, 471])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 279)\n",
            " > after interpolation : torch.Size([1, 80, 418])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 109)\n",
            " > after interpolation : torch.Size([1, 80, 163])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 149)\n",
            " > after interpolation : torch.Size([1, 80, 223])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 235)\n",
            " > after interpolation : torch.Size([1, 80, 352])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 161)\n",
            " > after interpolation : torch.Size([1, 80, 241])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 165)\n",
            " > after interpolation : torch.Size([1, 80, 247])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 440)\n",
            " > after interpolation : torch.Size([1, 80, 660])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 365)\n",
            " > after interpolation : torch.Size([1, 80, 547])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 152)\n",
            " > after interpolation : torch.Size([1, 80, 228])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 179)\n",
            " > after interpolation : torch.Size([1, 80, 268])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 288)\n",
            " > after interpolation : torch.Size([1, 80, 432])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 306)\n",
            " > after interpolation : torch.Size([1, 80, 459])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 493)\n",
            " > after interpolation : torch.Size([1, 80, 739])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 366)\n",
            " > after interpolation : torch.Size([1, 80, 549])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 227)\n",
            " > after interpolation : torch.Size([1, 80, 340])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 197)\n",
            " > after interpolation : torch.Size([1, 80, 295])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 36)\n",
            " > after interpolation : torch.Size([1, 80, 54])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 129)\n",
            " > after interpolation : torch.Size([1, 80, 193])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 441)\n",
            " > after interpolation : torch.Size([1, 80, 661])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 36)\n",
            " > after interpolation : torch.Size([1, 80, 54])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 34)\n",
            " > after interpolation : torch.Size([1, 80, 51])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 416)\n",
            " > after interpolation : torch.Size([1, 80, 624])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 319)\n",
            " > after interpolation : torch.Size([1, 80, 478])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 316)\n",
            " > after interpolation : torch.Size([1, 80, 474])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 219)\n",
            " > after interpolation : torch.Size([1, 80, 328])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 233)\n",
            " > after interpolation : torch.Size([1, 80, 349])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 82)\n",
            " > after interpolation : torch.Size([1, 80, 123])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 109)\n",
            " > after interpolation : torch.Size([1, 80, 163])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 66)\n",
            " > after interpolation : torch.Size([1, 80, 99])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 388)\n",
            " > after interpolation : torch.Size([1, 80, 582])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 247)\n",
            " > after interpolation : torch.Size([1, 80, 370])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 73)\n",
            " > after interpolation : torch.Size([1, 80, 109])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 445)\n",
            " > after interpolation : torch.Size([1, 80, 667])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 64)\n",
            " > after interpolation : torch.Size([1, 80, 96])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 74)\n",
            " > after interpolation : torch.Size([1, 80, 111])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 54)\n",
            " > after interpolation : torch.Size([1, 80, 81])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 226)\n",
            " > after interpolation : torch.Size([1, 80, 339])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 96)\n",
            " > after interpolation : torch.Size([1, 80, 144])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 215)\n",
            " > after interpolation : torch.Size([1, 80, 322])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 78)\n",
            " > after interpolation : torch.Size([1, 80, 117])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 119)\n",
            " > after interpolation : torch.Size([1, 80, 178])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 80)\n",
            " > after interpolation : torch.Size([1, 80, 120])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 46)\n",
            " > after interpolation : torch.Size([1, 80, 69])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 172)\n",
            " > after interpolation : torch.Size([1, 80, 258])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 128)\n",
            " > after interpolation : torch.Size([1, 80, 192])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 265)\n",
            " > after interpolation : torch.Size([1, 80, 397])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 124)\n",
            " > after interpolation : torch.Size([1, 80, 186])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 76)\n",
            " > after interpolation : torch.Size([1, 80, 114])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 62)\n",
            " > after interpolation : torch.Size([1, 80, 93])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 93)\n",
            " > after interpolation : torch.Size([1, 80, 139])\n",
            " > Processing time: 483.7311451435089\n",
            " > Real-time factor: 0.500982476729696\n",
            " > Text splitted to sentences.\n",
            "['Ya sea que pienses que la inteligencia artificial salvará al mundo o lo terminará, tienes a Jeffrey Hinton a quien agradecer.', 'Hinton ha sido llamado el Padrino de AI, un científico informático británico cuyas controvertidas ideas ayudan a hacer posible la inteligencia artificial avanzada y así cambiar el mundo.', 'Hinton cree que AI hará un gran bien, pero esta noche tiene una advertencia.', 'Dice que los sistemas de IA pueden ser más inteligentes de lo que sabemos y hay una posibilidad de que las máquinas puedan hacerse cargo, lo que nos hizo hacer la pregunta.', 'La historia continuará en un momento.', '¿Sabe la humanidad lo que está haciendo?', 'Ninguno.', 'Creo que estamos entrando en un período en el que por primera vez podemos tener cosas más inteligentes que nosotros.', '¿Crees que pueden entenderlo?', 'Sí.', '¿Crees que son inteligentes?', 'Sí.', '¿Cree que estos sistemas tienen experiencias propias y pueden tomar decisiones basadas en esas experiencias?', 'En el mismo sentido que la gente, sí.', '¿Están conscientes?', 'Creo que probablemente no tienen mucha conciencia de sí mismos en este momento.', 'Así que en ese sentido no creo que estén conscientes.', '¿Tendrán conciencia de sí mismos?', 'Conciencia.', 'Oh, sí.', 'Creo que lo harán a tiempo.', 'Y así los seres humanos serán los segundos seres más inteligentes del planeta.Sí.', 'Jeffrey Hinton nos dijo que la inteligencia artificial que puso en marcha fue un accidente nacido de un fracaso.', 'En la década de 1970 en la Universidad de Edimburgo, soñó con simular una red neuronal en una computadora simplemente como una herramienta para lo que realmente estaba estudiando, el cerebro humano.', 'Pero en ese entonces casi nadie pensaba que el software podría imitar el cerebro.', 'Su asesor de doctorado le dijo que lo dejara antes de que arruinara su carrera.', 'Hinton dice que no pudo descubrir la mente humana pero la larga búsqueda llevó a una versión artificial.', 'Tardé mucho, mucho más de lo que esperaba.', 'Tardó como 50 años en funcionar bien.', 'Pero al final funcionó bien.', '¿En qué momento te diste cuenta de que tenías razón sobre las redes neuronales y la mayoría de los demás estaban equivocados?', 'Siempre pensé que tenía razón.', 'En 2019, Hinton y colaboradores Jan LeCun a la izquierda y Joshua Benjio ganaron el Premio Turing, el Premio Nobel de Computación.', 'Para entender cómo su trabajo en redes neuronales artificiales ayudó a las máquinas a aprender, déjenos llevarlos a un juego.', 'Mira eso.', 'Oh, Dios mío.', 'Este es el laboratorio de inteligencia artificial de Google en Londres que les mostramos por primera vez en abril pasado.', 'Jeffrey Hinton no estaba involucrado en este proyecto de fútbol, pero estos robots son un gran ejemplo de aprendizaje automático.', 'Lo que hay que entender es que los robots no estaban programados para jugar al fútbol.', 'Se les dijo que anotaran.', 'Tenían que aprender por su cuenta.', 'En general, así es como lo hace AI.Hinton y sus colaboradores crearon software en capas con cada capa manejando parte del problema.', 'Esa es la llamada red neuronal.', 'Pero esta es la clave.', 'Cuando, por ejemplo, el robot anota, se envía un mensaje de vuelta a través de todas las capas que dicen que el camino era correcto.', 'Del mismo modo, cuando una respuesta es incorrecta, ese mensaje baja a través de la red.', 'Así que las conexiones correctas se hacen más fuertes, las conexiones equivocadas se debilitan, y por ensayo y error, la máquina se enseña a sí misma.', '¿Crees que estos sistemas de IA son mejores en el aprendizaje que la mente humana?', 'Creo que sí, sí.', 'Y en la actualidad, son mucho más pequeñas.', 'Así que incluso los bots de chat más grandes sólo tienen un billón de conexiones en ellos.', 'El cerebro humano tiene unos cien billones.', 'Y sin embargo, en el billón de conexiones en el chat bot, sabe mucho más que tú en tus cien billones de conexiones, lo que sugiere que tiene una forma mucho mejor de obtener conocimiento en esas conexiones.', 'Una manera mucho mejor de obtener conocimiento que no se entiende completamente.', 'Tenemos una muy buena idea de lo que está haciendo.', 'Pero tan pronto como se vuelve realmente complicado, en realidad no sabemos lo que está pasando más de lo que sabemos lo que está pasando en su cerebro.', '¿Qué quieres decir con que no sabemos exactamente cómo funciona?', '¿Fue diseñado por la gente?', 'No, no lo fue.', 'Lo que hicimos fue diseñar el algoritmo de aprendizaje.', 'Eso es un poco como diseñar el principio de la evolución.', 'Pero cuando este algoritmo de aprendizaje entonces interactúa con los datos, produce redes neuronales complicadas que son buenas para hacer las cosas.', 'Pero realmente no entendemos exactamente cómo hacen esas cosas.', '¿Cuáles son las implicaciones de estos sistemas de forma autónoma escribir su propio código informático y ejecutar su propio código informático?', 'Esa es una seria preocupación, ¿verdad?', 'Así que una de las maneras en que estos sistemas podrían escapar del control es escribiendo su propio código informático para modificarse a sí mismos.', 'Y eso es algo de lo que tenemos que preocuparnos seriamente.', '¿Qué le dices a alguien que podría argumentar si los sistemas se vuelven benevolentes, simplemente apagarlos, ellos serán capaces de manipular a la gente, ¿verdad?', 'Y estos serán muy buenos para convencer a la gente porque habrán aprendido de todas las novelas que se han escrito, todos los libros de Maquiavelo, todas las connivencias políticas, sabrán todo eso, sabrán cómo hacerlo.', 'Sepa cómo la humanidad corre en la familia de Jeffrey Hinton.', 'Sus antepasados incluyen el matemático George Buell que inventó la base de la computación y George Everest que examinó la India y consiguió que la montaña lleva su nombre.', 'Pero cuando era niño, el propio Hinton nunca podía subir al pico de las expectativas planteadas por un padre dominante.', 'Cada mañana, cuando iba a la escuela, me decía que mientras caminaba por el camino de entrada, me metía en su terreno de juego y tal vez cuando tuvieras el doble de edad que yo, serías la mitad de bueno.', 'Papá era una autoridad de los Beatles.', 'Sabía mucho más sobre los Beatles que sobre la gente.', '¿Sentiste eso de niña?', 'Un poco, sí.', 'Cuando murió, fuimos a su estudio en la universidad y las paredes estaban forradas con cajas de papeles en diferentes tipos de Beatles.', 'Y justo cerca de la puerta, había una caja un poco más pequeña que simplemente decía no insectos.', 'Y ahí es donde tenía todas las cosas sobre la familia.', 'Hoy en día a los 75, Hinton se retiró recientemente después de lo que llama 10 años felices en Google.', 'Ahora es profesor emérito en la Universidad de Toronto y por casualidad mencionó que tiene más citas académicas que su padre.', \"Algunas de sus investigaciones condujeron a chatbots como Google's Bard, que conocimos la primavera pasada.\", 'Confundiendo, absolutamente confundiendo.', 'Le pedimos a Bard que escribiera una historia de seis palabras.', 'En venta, zapatos de bebé, nunca usados.', 'Santo cielo.', 'Los zapatos eran un regalo de mi esposa, pero nunca tuvimos un bebé.', 'Bard creó una historia profundamente humana de un hombre cuya esposa no podía concebir y un extraño que aceptó los zapatos para curar el dolor después de su aborto espontáneo.', 'Rara vez me quedo sin palabras.', 'No sé qué hacer con esto.', 'Se dice que los Chatbots son modelos de lenguaje que predicen la siguiente palabra más probable basada en la probabilidad.', 'Oirás a la gente decir cosas como, que están haciendo autocompletado.', 'Sólo están tratando de predecir la siguiente palabra.', 'Y sólo están usando estadísticas.', 'Bueno, es cierto que sólo están tratando de predecir la siguiente palabra.', 'Pero si lo piensas, para predecir la siguiente palabra, tienes que entender las frases.', 'Así que la idea de que sólo están prediciendo la siguiente palabra para que no sean inteligentes es una locura.', 'Tienes que ser muy inteligente para predecir la siguiente palabra con precisión.', 'Para probarlo, Hinton nos mostró una prueba que ideó para Chat GPT-4, el chatbot de una compañía llamada OpenAI.Fue un poco tranquilizador ver a un ganador del premio Turing mal tipo y culpar a la computadora.', 'Maldita sea.', 'Vamos a volver y empezar de nuevo.', 'Está bien.', 'La prueba de Hinton fue un acertijo sobre la pintura en casa.', 'Una respuesta exigiría razonamiento y planificación.', 'Esto es lo que escribió en Chat GPT-4.', 'Las habitaciones de mi casa están pintadas de blanco o azul o amarillo.', 'Y la pintura amarilla se desvanece en un año.', 'Dentro de dos años, me gustaría que todas las habitaciones fueran blancas.', '¿Qué debo hacer?', 'La respuesta comenzó en un segundo.', 'GPT-4 aconsejó que las habitaciones pintadas en azul necesitan ser repintadas.', 'Las habitaciones pintadas de amarillo no necesitan ser repintadas porque se desvanecerían en blanco antes de la fecha límite.', 'Y...Ni siquiera pensé en eso.', 'Advirtió que si pintas las habitaciones amarillas de blanco, hay un riesgo de que el color podría estar apagado cuando el amarillo se desvanece.', 'Además, se aconseja, usted estaría desperdiciando recursos, salas de pintura que vamos a desvanecerse en blanco de todos modos.', 'Usted cree que Chat GPT-4 entiende.', 'Creo que definitivamente entiende, sí.', '¿Y dentro de cinco años?', 'Creo que dentro de cinco años puede ser capaz de razonar mejor que nosotros.', 'Razonar que dice está llevando a los grandes riesgos y beneficios de IA.Así que un área obvia donde hay enormes beneficios es la salud.', 'La IA ya es comparable con los radiólogos en la comprensión de lo que está pasando en las imágenes médicas.', 'Va a ser muy bueno en el diseño de drogas.', 'Ya está diseñando drogas.', 'Así que ese es un área donde casi por completo va a hacer el bien.', 'Me gusta esa zona.', '¿Los riesgos son qué?', 'Bueno, los riesgos son tener toda una clase de personas que están desempleadas y no valoran mucho porque lo que solían hacer ahora lo hacen las máquinas.', 'Otros riesgos inmediatos que le preocupan son las noticias falsas, los prejuicios no deseados en el empleo y la policía, y los robots autónomos del campo de batalla.', '¿Qué es un camino hacia adelante que garantiza la seguridad?', 'No lo sé.11.30 horas reunión privada Sala 5No veo un camino que garantice la seguridad.', 'Estamos entrando en un período de gran incertidumbre donde estamos tratando con cosas que nunca hemos tratado antes.', 'Y normalmente la primera vez que lidias con algo totalmente novedoso te equivocas.', 'Y no podemos permitirnos equivocarnos con estas cosas.11.45 horasNo me doy el lujo de equivocarme.', '¿Por qué?', 'Bueno, porque ellos podrían tomar el control.', 'Toma el relevo de la humanidad.', 'Sí, es una posibilidad.', '¿Por qué no dirían que sucederá?', 'Si pudiéramos evitar que quisieran eso sería genial.', 'Pero no está claro que podamos impedir que quieran hacerlo.', 'Jeffrey Hinton nos dijo que no se arrepiente por el potencial de IA para el bien.', 'Pero dice que ahora es el momento de hacer experimentos para entender la IA, para que los gobiernos impongan regulaciones, y para que un tratado mundial prohíba el uso de robots militares.', 'Nos recordó a Robert Oppenheimer, quien después de inventar la bomba atómica hizo campaña contra la bomba de hidrógeno, un hombre que cambió el mundo y encontró el mundo más allá de su control.', 'Tal vez miramos hacia atrás y vemos esto como una especie de punto de inflexión cuando ella logró tomar la decisión sobre si desarrollar estas cosas más y qué hacer para protegerse a sí mismos si lo hicieron.', 'No lo sé.', 'Creo que mi mensaje principal es que hay una enorme incertidumbre sobre lo que va a pasar a continuación.', 'Estas cosas sí entienden y porque entienden que necesitamos pensar más sobre lo que va a pasar a continuación y simplemente no lo sabemos.']\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 451)\n",
            " > after interpolation : torch.Size([1, 80, 676])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 256)\n",
            " > after interpolation : torch.Size([1, 80, 384])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 112)\n",
            " > after interpolation : torch.Size([1, 80, 168])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 40)\n",
            " > after interpolation : torch.Size([1, 80, 60])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 369)\n",
            " > after interpolation : torch.Size([1, 80, 553])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 129)\n",
            " > after interpolation : torch.Size([1, 80, 193])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 253)\n",
            " > after interpolation : torch.Size([1, 80, 379])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 176)\n",
            " > after interpolation : torch.Size([1, 80, 264])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 42)\n",
            " > after interpolation : torch.Size([1, 80, 63])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 27)\n",
            " > after interpolation : torch.Size([1, 80, 40])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 73)\n",
            " > after interpolation : torch.Size([1, 80, 109])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 279)\n",
            " > after interpolation : torch.Size([1, 80, 418])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 365)\n",
            " > after interpolation : torch.Size([1, 80, 547])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 244)\n",
            " > after interpolation : torch.Size([1, 80, 366])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 252)\n",
            " > after interpolation : torch.Size([1, 80, 378])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 441)\n",
            " > after interpolation : torch.Size([1, 80, 661])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 122)\n",
            " > after interpolation : torch.Size([1, 80, 183])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 121)\n",
            " > after interpolation : torch.Size([1, 80, 181])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 88)\n",
            " > after interpolation : torch.Size([1, 80, 132])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 102)\n",
            " > after interpolation : torch.Size([1, 80, 153])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 454)\n",
            " > after interpolation : torch.Size([1, 80, 681])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 37)\n",
            " > after interpolation : torch.Size([1, 80, 55])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 41)\n",
            " > after interpolation : torch.Size([1, 80, 61])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 411)\n",
            " > after interpolation : torch.Size([1, 80, 616])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 452)\n",
            " > after interpolation : torch.Size([1, 80, 678])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 268)\n",
            " > after interpolation : torch.Size([1, 80, 402])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 80)\n",
            " > after interpolation : torch.Size([1, 80, 120])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 104)\n",
            " > after interpolation : torch.Size([1, 80, 156])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 479)\n",
            " > after interpolation : torch.Size([1, 80, 718])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 101)\n",
            " > after interpolation : torch.Size([1, 80, 151])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 62)\n",
            " > after interpolation : torch.Size([1, 80, 93])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 459)\n",
            " > after interpolation : torch.Size([1, 80, 688])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 341)\n",
            " > after interpolation : torch.Size([1, 80, 511])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 53)\n",
            " > after interpolation : torch.Size([1, 80, 79])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 169)\n",
            " > after interpolation : torch.Size([1, 80, 253])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 299)\n",
            " > after interpolation : torch.Size([1, 80, 448])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 136)\n",
            " > after interpolation : torch.Size([1, 80, 204])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 265)\n",
            " > after interpolation : torch.Size([1, 80, 397])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 170)\n",
            " > after interpolation : torch.Size([1, 80, 255])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 46)\n",
            " > after interpolation : torch.Size([1, 80, 69])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 165)\n",
            " > after interpolation : torch.Size([1, 80, 247])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 190)\n",
            " > after interpolation : torch.Size([1, 80, 285])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 216)\n",
            " > after interpolation : torch.Size([1, 80, 324])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 154)\n",
            " > after interpolation : torch.Size([1, 80, 231])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 199)\n",
            " > after interpolation : torch.Size([1, 80, 298])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 190)\n",
            " > after interpolation : torch.Size([1, 80, 285])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 426)\n",
            " > after interpolation : torch.Size([1, 80, 639])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 127)\n",
            " > after interpolation : torch.Size([1, 80, 190])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 169)\n",
            " > after interpolation : torch.Size([1, 80, 253])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 54)\n",
            " > after interpolation : torch.Size([1, 80, 81])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 431)\n",
            " > after interpolation : torch.Size([1, 80, 646])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 392)\n",
            " > after interpolation : torch.Size([1, 80, 588])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 169)\n",
            " > after interpolation : torch.Size([1, 80, 253])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 414)\n",
            " > after interpolation : torch.Size([1, 80, 621])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 467)\n",
            " > after interpolation : torch.Size([1, 80, 700])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 371)\n",
            " > after interpolation : torch.Size([1, 80, 556])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 171)\n",
            " > after interpolation : torch.Size([1, 80, 256])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 196)\n",
            " > after interpolation : torch.Size([1, 80, 294])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 150)\n",
            " > after interpolation : torch.Size([1, 80, 225])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 48)\n",
            " > after interpolation : torch.Size([1, 80, 72])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 237)\n",
            " > after interpolation : torch.Size([1, 80, 355])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 108)\n",
            " > after interpolation : torch.Size([1, 80, 162])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 98)\n",
            " > after interpolation : torch.Size([1, 80, 147])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 389)\n",
            " > after interpolation : torch.Size([1, 80, 583])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 246)\n",
            " > after interpolation : torch.Size([1, 80, 369])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 171)\n",
            " > after interpolation : torch.Size([1, 80, 256])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 116)\n",
            " > after interpolation : torch.Size([1, 80, 174])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 270)\n",
            " > after interpolation : torch.Size([1, 80, 405])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 283)\n",
            " > after interpolation : torch.Size([1, 80, 424])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 370)\n",
            " > after interpolation : torch.Size([1, 80, 555])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 266)\n",
            " > after interpolation : torch.Size([1, 80, 399])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 53)\n",
            " > after interpolation : torch.Size([1, 80, 79])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 98)\n",
            " > after interpolation : torch.Size([1, 80, 147])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 37)\n",
            " > after interpolation : torch.Size([1, 80, 55])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 185)\n",
            " > after interpolation : torch.Size([1, 80, 277])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 181)\n",
            " > after interpolation : torch.Size([1, 80, 271])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 119)\n",
            " > after interpolation : torch.Size([1, 80, 178])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 301)\n",
            " > after interpolation : torch.Size([1, 80, 451])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 130)\n",
            " > after interpolation : torch.Size([1, 80, 195])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 256)\n",
            " > after interpolation : torch.Size([1, 80, 384])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 116)\n",
            " > after interpolation : torch.Size([1, 80, 174])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 294)\n",
            " > after interpolation : torch.Size([1, 80, 441])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 82)\n",
            " > after interpolation : torch.Size([1, 80, 123])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 487)\n",
            " > after interpolation : torch.Size([1, 80, 730])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 125)\n",
            " > after interpolation : torch.Size([1, 80, 187])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 129)\n",
            " > after interpolation : torch.Size([1, 80, 193])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 283)\n",
            " > after interpolation : torch.Size([1, 80, 424])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 438)\n",
            " > after interpolation : torch.Size([1, 80, 657])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 301)\n",
            " > after interpolation : torch.Size([1, 80, 451])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 128)\n",
            " > after interpolation : torch.Size([1, 80, 192])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 90)\n",
            " > after interpolation : torch.Size([1, 80, 135])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 205)\n",
            " > after interpolation : torch.Size([1, 80, 307])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 60)\n",
            " > after interpolation : torch.Size([1, 80, 90])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 418)\n",
            " > after interpolation : torch.Size([1, 80, 627])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 390)\n",
            " > after interpolation : torch.Size([1, 80, 585])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 303)\n",
            " > after interpolation : torch.Size([1, 80, 454])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 393)\n",
            " > after interpolation : torch.Size([1, 80, 589])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 159)\n",
            " > after interpolation : torch.Size([1, 80, 238])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 95)\n",
            " > after interpolation : torch.Size([1, 80, 142])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 95)\n",
            " > after interpolation : torch.Size([1, 80, 142])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 167)\n",
            " > after interpolation : torch.Size([1, 80, 250])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 185)\n",
            " > after interpolation : torch.Size([1, 80, 277])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 235)\n",
            " > after interpolation : torch.Size([1, 80, 352])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 38)\n",
            " > after interpolation : torch.Size([1, 80, 57])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 343)\n",
            " > after interpolation : torch.Size([1, 80, 514])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 484)\n",
            " > after interpolation : torch.Size([1, 80, 726])\n",
            " > Processing time: 465.0813887119293\n",
            " > Real-time factor: 0.5097407996509482\n",
            " > Text splitted to sentences.\n",
            "['Esta noche, Scott Pelley informa desde Ucrania, donde se sentó con el presidente Vladimir Zelensky en el Capitolio.', 'La historia continuará en un momento.', 'Nos reunimos con el Presidente Zelensky mientras se preparaba para partir hacia los Estados Unidos.', 'Esta semana hablará en la ONU y se reunirá con el presidente Biden.', 'Es un momento crítico.', 'Los funcionarios estadounidenses nos dicen que durante casi 600 días, casi medio millón de soldados han sido muertos o heridos, ambos lados en total.', 'Parte del costo, hasta ahora, de la invasión no provocada de Vladimir Putin.', 'Hablamos con Zelensky el jueves.', 'Nos dijo que su pueblo está muriendo todos los días para evitar la Tercera Guerra Mundial.', 'Estamos defendiendo los valores del mundo entero, dijo Zelensky.', 'Y estos son los ucranianos que están pagando el precio más alto.', 'Estamos realmente luchando por nuestra libertad.', 'Nos estamos muriendo.', 'No somos ficción.', 'No somos un libro.', 'Estamos luchando de verdad con un estado nuclear que amenaza con destruir el mundo.', 'Los Estados Unidos han contribuido con unos 70.000 millones de dólares a su esfuerzo bélico.', 'Y me pregunto si espera que ese nivel de apoyo continúe.', 'Los Estados Unidos de América están apoyando financieramente a Ucrania, y estoy agradecido por ello.', 'Creo que no solo apoyan a Ucrania.', 'Si Ucrania cae, Putin seguramente irá más allá.', '¿Qué harán los Estados Unidos de América cuando Putin llegue a los estados bálticos, cuando llegue a la frontera polaca?', 'Lo hará.', 'Esto es mucho dinero.', 'Tenemos mucha gratitud.', '¿Qué más debe hacer Ucrania para que todos midan nuestra enorme gratitud?', 'Estamos muriendo en esta guerra.', 'Mira, si Ucrania cae, ¿qué pasará en diez años?', 'Sólo piénsalo.', 'Si los rusos llegan a Polonia, ¿qué sigue?', '¿Una tercera guerra mundial?', '¿Qué se necesita?', '¿Otros 70 mil millones?', 'No tengo una respuesta.', 'El mundo entero tiene que decidir si queremos detener a Putin o si queremos comenzar el comienzo de una guerra mundial.', 'No podemos cambiar a Putin.', 'La sociedad rusa ha perdido el respeto del mundo.', 'Lo eligieron y lo reeligieron y criaron a un segundo Hitler.', 'Ellos hicieron esto.', 'No podemos retroceder en el tiempo, pero podemos detenerlo aquí.', 'Ucrania detuvo el avance ruso, pero a un costo terrible.', 'En las ciudades de la ONU, millones de refugiados incalculables miles de muertos, todo por la vanidad de construcción nacional de Vladimir Putin.', 'Hoy la guerra se libra en un frente de 700 millas.', 'El área roja es el 20 por ciento de Ucrania todavía ocupada por Rusia.', 'Aquí es donde se suponía que los tanques donados por el oeste atravesarían, cortando a la fuerza rusa por la mitad.', 'Pero trincheras, campos de minas y artillería detuvieron el avance blindado.', 'Ahora es un duelo de artillería, con cada lado disparando unos 40.000 proyectiles al día.', 'La infantería ucraniana avanza yardas sangrientas a la vez.', 'Es la Primera Guerra Mundial, con drones.', '¿Cómo describirías la lucha en el frente?', 'Es una pregunta difícil.', 'Seré completamente honesto contigo.', 'Tenemos la iniciativa, esto es un plus.', 'Detenemos la ofensiva rusa y pasamos a una contraofensiva, pero a pesar de eso, no es muy rápido.', 'Es importante que avancemos todos los días y liberemos el territorio.', 'Te quedan unas seis semanas de buen tiempo, y me pregunto después de ese punto el frente estará congelado en su lugar.', 'Tenemos que liberar nuestro territorio tanto como sea posible y seguir adelante.', 'Incluso si es menos de media milla o cien yardas, debemos hacerlo.', 'No podemos perder tiempo.', 'Olvídate del tiempo y cosas por el estilo.', 'En lugares que no podemos atravesar en un vehículo blindado, volemos.', 'Si no podemos volar, vamos a enviar drones.', 'No debemos darle un respiro a Putin.', 'Si el frente está estacionario, los drones ucranianos han abovedado hacia Rusia misma, golpeando los rascacielos del Kremlin, aviones de combate y Moscú.', 'Oficialmente, Ucrania no reconoce estos ataques.', 'Los ataques con drones en Rusia se están llevando a cabo bajo sus órdenes.', 'No, no bajo tus órdenes.', 'Bueno, ya sabes...¿Cómo está pasando esto?', 'Esto no es seguro.', '¿Sabes que no disparamos al territorio de la Federación Rusa?', 'Decidimos intentar la pregunta de otra manera.', '¿Qué mensaje se envía con estos ataques con drones en Rusia?', 'No iba a agacharse en algún lugar con un cristal.', 'Usted sabe que usamos las armas de nuestros socios sólo en el territorio de Ucrania, y esto es cierto.', 'Pero no se trata de operaciones punitivas, como las que llevan a cabo, que matan a civiles.', 'Pero Rusia necesita saber que dondequiera que esté, cualquiera que sea el lugar que utilicen para lanzar misiles para atacar a Ucrania, Ucrania tiene todo el derecho moral de enviar una respuesta a esos lugares.', 'Estamos respondiendo a ellos, diciendo, su cielo no está tan bien protegido como usted piensa.', 'El invierno pasado fueron los cielos ucranianos los que se llenaron de misiles en un bombardeo ruso para destruir las centrales eléctricas.', 'Millones temblaban en la oscuridad.', 'Con el invierno acercándose de nuevo, Zelensky tenía esta advertencia.', 'Deben saber si cortan nuestra energía, privan de electricidad, privan de agua, privan de gasolina, necesitan saber.', 'Tenemos derecho a hacértelo.', 'Rusia se toma en serio a Zelensky ahora porque la invasión masiva de Putin fue un fiasco.', 'Las marcas rojas donde Ucrania detuvo el avance de Rusia el año pasado.', 'También marca la mancha de los crímenes de guerra de Rusia.', 'Sr.', 'Presidente, al viajar por Ucrania durante el último año y medio, hablamos con personas en escuelas bombardeadas en Chernahiv.', 'Hemos visto bloques destruidos de apartamentos en Borodayanka, un hospital bombardeado en Ism, civiles en una fosa común en Butcha.', 'Estos no son objetivos militares.', '¿Qué está tratando de hacer Vladimir Putin?', 'Para quebrarnos.', 'Y al elegir objetivos civiles, Putin quería lograr exactamente esto.', 'Para quebrarnos.', 'No se puede confiar en esta persona, que ha hecho su camino con acciones tan sangrientas, con todo lo que ha dicho.', 'No hay confianza en tal persona porque no ha sido un ser humano por mucho tiempo.', 'Los rusos han sufrido graves pérdidas sin recurrir a las armas nucleares.', 'Y me pregunto si cree que la amenaza de una guerra nuclear ya está detrás de nosotros.', 'Creo que va a seguir amenazando.', 'Está esperando a que Estados Unidos se vuelva menos estable.', 'Cree que eso va a pasar durante las elecciones estadounidenses.', 'Él buscará inestabilidad en Europa y en los Estados Unidos de América.', 'Utilizará el riesgo de usar armas nucleares para alimentar esa inestabilidad.', 'Seguirá amenazando.', 'Esa elección de Estados Unidos, mencionó, le preocupa.', 'Sus negociaciones con el presidente Biden a veces han sido polémicas, pero Zelensky tiende a conseguir lo que pide, aunque en opinión de Zelensky, por lo general es seis meses demasiado tarde.', 'Esta semana, Zelensky presionará al Sr.', 'Biden por misiles de mayor alcance.', 'El Congreso está debatiendo otro paquete de $24 mil millones.', 'Y si Ucrania hubiera tenido suficiente de estos sistemas modernos, ya habríamos restaurado la integridad territorial de Ucrania.', 'Ya lo habríamos hecho.', 'Estos sistemas existen.', '¿Estás a salvo aquí?', 'Nos conocimos por primera vez Zelensky no mucho después de la invasión, cuando su oficina era un búnker apagado.', 'Ahora, un año y medio después, notamos una diferencia.', 'Mientras preparamos la entrevista, el ex actor usó su talento para enmascarar la cepa.', 'Sonrió ante un cumplido a su esposa.', 'Sí, genial.', 'Y luego instantáneamente, parecía tirado por debajo de una profundidad que nadie puede saber.', 'No sabemos en qué estaba pensando.', 'Parecía empatía por los perdidos y por aquellos que podrían ser salvados.', 'Nuestro tiempo con Zelensky comenzó en silencio, un recuerdo de los caídos.', 'Durante una ceremonia para otorgar medallas de valor.', 'Los funcionarios ucranianos nos dicen que Ucrania y Rusia han perdido sus ejércitos profesionales.', 'Ahora las fuerzas están compuestas por voluntarios, reclutas, y en el caso de Rusia, presos.', 'Zelensky cuenta a su padre en informes de bajas cada mañana.', 'Usted es el presidente, pero debe ser humillante conocer a esos hombres.', 'Me pregunto qué significan para ti.', 'En primer lugar, es un gran honor para mí.', 'Miro a sus ojos y me hace sentir orgulloso de que tengamos gente tan fuerte.', 'Porque este es un gran riesgo, un gran riesgo.', 'Definitivamente puedes perder tu vida por el bien de salvar otras vidas.', 'Y cuando digo otras vidas, no hablo en general.', 'Me refiero a mi propia vida, la vida de mis hijos, y entiendo completamente qué riesgos están involucrados.', 'Esa empatía por la vida ha hecho que Volodomir Zelensky vuelva a ponerse en contacto con las Naciones Unidas y los Estados Unidos, con la esperanza de convencer a los aliados de que el mundo sólo puede estar a salvo cuando Ucrania está entera.', '¿Puedes renunciar a cualquier parte de Ucrania por la paz?', 'No, este es nuestro territorio.', 'Debes tenerlo todo, incluida Crimea.', 'Hoy, tú y yo, me lo dijiste, me viste concediendo medallas a la gente.', 'Hoy es un día así.', 'Hace una semana, di premios a los padres de los soldados que han sido asesinados.', 'Había 24 familias de muertos.', 'Había una mujer, estaba con tres hijos.', 'Había padres, muy viejos.', 'Apenas podían caminar y sólo habían tenido un hijo.', 'Una de las mujeres estaba embarazada.', 'Llegó sosteniendo a un bebé en sus brazos y estaba embarazada.', 'Y ese bebé nunca lo verá.', '¿Qué debo decirles que todos ellos murieron para que pudiéramos decir, está bien Rusia, usted puede tomarlo todo.', 'Es un trabajo difícil.', 'Me entiendes, ¿verdad?', 'Dar premios a las personas cuyos rostros muestran que todo su mundo se ha derrumbado y todo lo que puedo darles, todo lo que puedo darles es la victoria.', 'Hola, Sr.', 'Presidente.', 'Escuche más de las noticias de Scott Pelley haciendo conversación con el presidente Volodemir Zelinsky a 60minutosovertime.com']\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 417)\n",
            " > after interpolation : torch.Size([1, 80, 625])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 112)\n",
            " > after interpolation : torch.Size([1, 80, 168])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 324)\n",
            " > after interpolation : torch.Size([1, 80, 486])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 238)\n",
            " > after interpolation : torch.Size([1, 80, 357])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 80)\n",
            " > after interpolation : torch.Size([1, 80, 120])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 278)\n",
            " > after interpolation : torch.Size([1, 80, 417])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 104)\n",
            " > after interpolation : torch.Size([1, 80, 156])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 312)\n",
            " > after interpolation : torch.Size([1, 80, 468])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 248)\n",
            " > after interpolation : torch.Size([1, 80, 372])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 196)\n",
            " > after interpolation : torch.Size([1, 80, 294])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 154)\n",
            " > after interpolation : torch.Size([1, 80, 231])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 66)\n",
            " > after interpolation : torch.Size([1, 80, 99])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 59)\n",
            " > after interpolation : torch.Size([1, 80, 88])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 64)\n",
            " > after interpolation : torch.Size([1, 80, 96])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 256)\n",
            " > after interpolation : torch.Size([1, 80, 384])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 315)\n",
            " > after interpolation : torch.Size([1, 80, 472])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 207)\n",
            " > after interpolation : torch.Size([1, 80, 310])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 324)\n",
            " > after interpolation : torch.Size([1, 80, 486])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 105)\n",
            " > after interpolation : torch.Size([1, 80, 157])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 194)\n",
            " > after interpolation : torch.Size([1, 80, 291])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 286)\n",
            " > after interpolation : torch.Size([1, 80, 429])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 28)\n",
            " > after interpolation : torch.Size([1, 80, 42])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 67)\n",
            " > after interpolation : torch.Size([1, 80, 100])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 80)\n",
            " > after interpolation : torch.Size([1, 80, 120])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 98)\n",
            " > after interpolation : torch.Size([1, 80, 147])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 173)\n",
            " > after interpolation : torch.Size([1, 80, 259])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 53)\n",
            " > after interpolation : torch.Size([1, 80, 79])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 137)\n",
            " > after interpolation : torch.Size([1, 80, 205])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 78)\n",
            " > after interpolation : torch.Size([1, 80, 117])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 441)\n",
            " > after interpolation : torch.Size([1, 80, 661])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 92)\n",
            " > after interpolation : torch.Size([1, 80, 138])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 157)\n",
            " > after interpolation : torch.Size([1, 80, 235])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 186)\n",
            " > after interpolation : torch.Size([1, 80, 279])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 69)\n",
            " > after interpolation : torch.Size([1, 80, 103])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 231)\n",
            " > after interpolation : torch.Size([1, 80, 346])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 202)\n",
            " > after interpolation : torch.Size([1, 80, 303])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 463)\n",
            " > after interpolation : torch.Size([1, 80, 694])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 182)\n",
            " > after interpolation : torch.Size([1, 80, 273])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 250)\n",
            " > after interpolation : torch.Size([1, 80, 375])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 384)\n",
            " > after interpolation : torch.Size([1, 80, 576])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 315)\n",
            " > after interpolation : torch.Size([1, 80, 472])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 344)\n",
            " > after interpolation : torch.Size([1, 80, 516])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 205)\n",
            " > after interpolation : torch.Size([1, 80, 307])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 157)\n",
            " > after interpolation : torch.Size([1, 80, 235])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 87)\n",
            " > after interpolation : torch.Size([1, 80, 130])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 119)\n",
            " > after interpolation : torch.Size([1, 80, 178])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 155)\n",
            " > after interpolation : torch.Size([1, 80, 232])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 365)\n",
            " > after interpolation : torch.Size([1, 80, 547])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 228)\n",
            " > after interpolation : torch.Size([1, 80, 342])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 418)\n",
            " > after interpolation : torch.Size([1, 80, 627])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 259)\n",
            " > after interpolation : torch.Size([1, 80, 388])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 231)\n",
            " > after interpolation : torch.Size([1, 80, 346])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 84)\n",
            " > after interpolation : torch.Size([1, 80, 126])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 125)\n",
            " > after interpolation : torch.Size([1, 80, 187])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 254)\n",
            " > after interpolation : torch.Size([1, 80, 381])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 179)\n",
            " > after interpolation : torch.Size([1, 80, 268])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 114)\n",
            " > after interpolation : torch.Size([1, 80, 171])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 198)\n",
            " > after interpolation : torch.Size([1, 80, 297])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 237)\n",
            " > after interpolation : torch.Size([1, 80, 355])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 87)\n",
            " > after interpolation : torch.Size([1, 80, 130])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 188)\n",
            " > after interpolation : torch.Size([1, 80, 282])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 62)\n",
            " > after interpolation : torch.Size([1, 80, 93])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 145)\n",
            " > after interpolation : torch.Size([1, 80, 217])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 145)\n",
            " > after interpolation : torch.Size([1, 80, 217])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 339)\n",
            " > after interpolation : torch.Size([1, 80, 508])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 319)\n",
            " > after interpolation : torch.Size([1, 80, 478])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 325)\n",
            " > after interpolation : torch.Size([1, 80, 487])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 452)\n",
            " > after interpolation : torch.Size([1, 80, 678])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 112)\n",
            " > after interpolation : torch.Size([1, 80, 168])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 241)\n",
            " > after interpolation : torch.Size([1, 80, 361])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 440)\n",
            " > after interpolation : torch.Size([1, 80, 660])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 82)\n",
            " > after interpolation : torch.Size([1, 80, 123])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 281)\n",
            " > after interpolation : torch.Size([1, 80, 421])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 238)\n",
            " > after interpolation : torch.Size([1, 80, 357])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 193)\n",
            " > after interpolation : torch.Size([1, 80, 289])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 14)\n",
            " > after interpolation : torch.Size([1, 80, 21])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 468)\n",
            " > after interpolation : torch.Size([1, 80, 702])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 440)\n",
            " > after interpolation : torch.Size([1, 80, 660])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 123)\n",
            " > after interpolation : torch.Size([1, 80, 184])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 57)\n",
            " > after interpolation : torch.Size([1, 80, 85])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 258)\n",
            " > after interpolation : torch.Size([1, 80, 387])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 57)\n",
            " > after interpolation : torch.Size([1, 80, 85])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 375)\n",
            " > after interpolation : torch.Size([1, 80, 562])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 262)\n",
            " > after interpolation : torch.Size([1, 80, 393])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 287)\n",
            " > after interpolation : torch.Size([1, 80, 430])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 301)\n",
            " > after interpolation : torch.Size([1, 80, 451])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 110)\n",
            " > after interpolation : torch.Size([1, 80, 165])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 191)\n",
            " > after interpolation : torch.Size([1, 80, 286])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 230)\n",
            " > after interpolation : torch.Size([1, 80, 345])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 249)\n",
            " > after interpolation : torch.Size([1, 80, 373])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 232)\n",
            " > after interpolation : torch.Size([1, 80, 348])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 69)\n",
            " > after interpolation : torch.Size([1, 80, 103])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 203)\n",
            " > after interpolation : torch.Size([1, 80, 304])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 139)\n",
            " > after interpolation : torch.Size([1, 80, 208])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 125)\n",
            " > after interpolation : torch.Size([1, 80, 187])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 246)\n",
            " > after interpolation : torch.Size([1, 80, 369])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 432)\n",
            " > after interpolation : torch.Size([1, 80, 648])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 59)\n",
            " > after interpolation : torch.Size([1, 80, 88])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 87)\n",
            " > after interpolation : torch.Size([1, 80, 130])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 389)\n",
            " > after interpolation : torch.Size([1, 80, 583])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 204)\n",
            " > after interpolation : torch.Size([1, 80, 306])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 270)\n",
            " > after interpolation : torch.Size([1, 80, 405])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 119)\n",
            " > after interpolation : torch.Size([1, 80, 178])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 49)\n",
            " > after interpolation : torch.Size([1, 80, 73])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 281)\n",
            " > after interpolation : torch.Size([1, 80, 421])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 103)\n",
            " > after interpolation : torch.Size([1, 80, 154])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 232)\n",
            " > after interpolation : torch.Size([1, 80, 348])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 252)\n",
            " > after interpolation : torch.Size([1, 80, 378])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 169)\n",
            " > after interpolation : torch.Size([1, 80, 253])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 335)\n",
            " > after interpolation : torch.Size([1, 80, 502])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 372)\n",
            " > after interpolation : torch.Size([1, 80, 558])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 194)\n",
            " > after interpolation : torch.Size([1, 80, 291])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 248)\n",
            " > after interpolation : torch.Size([1, 80, 372])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 113)\n",
            " > after interpolation : torch.Size([1, 80, 169])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 113)\n",
            " > after interpolation : torch.Size([1, 80, 169])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 253)\n",
            " > after interpolation : torch.Size([1, 80, 379])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 176)\n",
            " > after interpolation : torch.Size([1, 80, 264])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 257)\n",
            " > after interpolation : torch.Size([1, 80, 385])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 132)\n",
            " > after interpolation : torch.Size([1, 80, 198])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 392)\n",
            " > after interpolation : torch.Size([1, 80, 588])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 133)\n",
            " > after interpolation : torch.Size([1, 80, 199])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 122)\n",
            " > after interpolation : torch.Size([1, 80, 183])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 246)\n",
            " > after interpolation : torch.Size([1, 80, 369])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 63)\n",
            " > after interpolation : torch.Size([1, 80, 94])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 279)\n",
            " > after interpolation : torch.Size([1, 80, 418])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 128)\n",
            " > after interpolation : torch.Size([1, 80, 192])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 148)\n",
            " > after interpolation : torch.Size([1, 80, 222])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 97)\n",
            " > after interpolation : torch.Size([1, 80, 145])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 169)\n",
            " > after interpolation : torch.Size([1, 80, 253])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 115)\n",
            " > after interpolation : torch.Size([1, 80, 172])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 177)\n",
            " > after interpolation : torch.Size([1, 80, 265])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 92)\n",
            " > after interpolation : torch.Size([1, 80, 138])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 290)\n",
            " > after interpolation : torch.Size([1, 80, 435])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 85)\n",
            " > after interpolation : torch.Size([1, 80, 127])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 66)\n",
            " > after interpolation : torch.Size([1, 80, 99])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 497)\n",
            " > after interpolation : torch.Size([1, 80, 745])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 32)\n",
            " > after interpolation : torch.Size([1, 80, 48])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 45)\n",
            " > after interpolation : torch.Size([1, 80, 67])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 456)\n",
            " > after interpolation : torch.Size([1, 80, 684])\n",
            " > Processing time: 407.25676465034485\n",
            " > Real-time factor: 0.48128516029613444\n",
            " > Text splitted to sentences.\n",
            "['2023 ha sido un año de conciertos de estadio agotados, pero sólo una de las mujeres que rompen los récords de asistencia ha construido una marca global, cantando boca abajo.', 'Acrobacias de alto vuelo son sólo parte de su atractivo.', 'Alicia Moore es conocida tanto por sus himnos de fiesta como por su poderosa voz.', 'Y si el nombre es desconocido, es porque es más conocida por su identidad profesional de una sola palabra.', 'Rosa.', 'Rosa famosamente no tiene filtro.', 'Y los fans que han seguido su carrera de 25 años han llegado a esperar que comparta cada detalle de su historia a veces problemática.', 'La historia continuará en un momento.', '¿Tengo esto derecho?', 'Estás dispuesto a hablar de cualquier cosa.', 'Cualquier pregunta está bien.', 'No se ofenda.', 'Sí, es todo lo que estoy abierto a todo.', 'Mucha gente en su mundo prospera en la protección de la privacidad.', 'Eres un libro abierto.', '¿Por qué?', 'Supongo que lo miro de una manera muy específica.', 'Si soy un misterio para ti, ¿cómo puedo esperar que te conectes conmigo?', 'Y si soy una persona desesperada por la conexión, ¿por qué el misterio sería interesante para mí?', 'Quiero conocerte.', 'Quiero que me conozcas.', 'Empieza por venir a uno de sus conciertos.', 'Estuvimos allí para sus shows de bienvenida en Filadelfia el mes pasado, una parada en un año y medio de gira.', 'Ya ha establecido récords de asistencia en estadios de todo el mundo y ha vendido más de 350 millones de dólares en entradas.', 'Un concierto rosado es parte rock rager.', 'Parte espectáculo de Broadway.', 'Con una campanilla rociada.', 'Ella abrocha sus golpes mientras da la vuelta y vuela 100 pies en el aire.', 'Y lo hace sin sincronizar los labios.', 'Cuando dice que en realidad canta mejor boca abajo, créele.', 'Ahora 44, cuando mira a la multitud, ve a muchas más mamás y papás.', 'Ella se llama a sí misma y a sus fans los chicos poco cool y tiene un gran placer en tomar en sus enemigos.', 'Ya sea en sus programas o en las redes sociales, su mensaje es no meterse con ellos ni conmigo.', 'Esta imagen que has creado, tienes este famoso gruñido.', 'Sí, claro.', 'Me pregunto si cuando eso empezó, el mensaje era que esta es una mujer con la que no quieres meterte.', 'Bueno, esta es una mujer con la que no quieres meterte es una verdadera declaración.', 'Sé lo que piensan ciertas personas cuando me miran hasta el hecho de que soy musculoso, soy franco, y tengo el pelo corto.', 'Posiblemente soy un tipo, definitivamente una lesbiana.', 'La gente te pone en una caja, no importa lo que parezcas.', 'Entonces mi caja resulta ser si eres franco y no te inclinas a las normas sociales, entonces eres aterrador y peligroso.', 'Y la realidad es que la realidad es que soy la persona más tonta, divertida y amorosa que te pateará el culo si tengo que hacerlo.', 'En estos días, la vida es menos empezar la fiesta y más llevar a estos niños a la cama.', 'Su hijo de seis años, Jamison, y su hija Willow de 12 años a menudo están de gira con ella, montando sus scooters en el escenario durante los controles de sonido.', 'Para el show de la ciudad natal en Filadelfia, el marido de Pink, Moto Cross Star, Carrie Hart estaba allí, y también su madre, Judy.', 'Detrás del escenario, hay una biblioteca donde el equipo intercambia libros.', 'Pink tiene una novela romántica que necesita para volver.', 'Tenemos una pequeña señal en la hoja.', 'En realidad tienes un cartel en la hoja.', 'Ojalá tuviera el ch-ch-ch-thing, pero no tenemos eso.', 'Así que he estado detrás del escenario para otros artistas, y algunas de las cosas que he visto son mucho alcohol, mucha fiesta.', 'Genial.', 'Mi vestidor solía ser como whisky y cigarrillos.', 'Luego fueron los hoyos de bolas y los animales de peluche.', 'Cuando no está en la carretera, está en casa en el sur de California.', 'Aquí es donde ella es Alicia Moore, una mamá que lleva mohawk que hornea agria y es parte de la PTA.Está conduciendo para la escuela o manejando una carretilla elevadora en su viñedo de 25 acres.', 'Dice que se ha educado en la ciencia de la vinificación estudiando hasta altas horas de la noche después de sus shows.', 'Entonces, ¿tengo esto correcto?', '¿No haces rosa rosado?', 'Yo no hago rosa rosado.', '¿Qué clase de cosa es?', 'Parece un vino blanco.', 'Ocasionalmente es un poco durazno, pero...¿Lo bebes?', 'Bebo mucho.', 'Bueno, Biggie Smalls dijo una vez que nunca te drogaras con tu propio suministro, pero...¿Seguro?', 'Sí, lo sé.', 'Obstruyo el vino.', 'El hogar es también donde hace música.', 'Esta es mi sala de música.', 'Es realmente genial.', 'Sí.', 'Es escritora en la mayoría de sus canciones y dice que ningún tema está fuera de los límites, ni siquiera los altibajos de su matrimonio.', 'Y te enseñaste a jugar en esto.', 'Más o menos.', 'Quiero decir, puedo tocar mitades de canciones.', 'Una de mis canciones favoritas sólo te hace sentir mi amor.', 'Y toqué esto todos los días durante COVID.Esta es una canción de Bob Dylan hecha famosa recientemente por Adele.', 'Es una de mis canciones favoritas.', 'Así que toqué eso todos los días.', 'Vaya.', 'Hasta que fui lo suficientemente bueno para subir al escenario y tocar un instrumento.', 'Creció cantando ópera y gospel en la ciudad de Doyle, Pensilvania.', 'Pero dice que la tensión en casa la hizo desesperada por irse.', 'Ella llama a su relación con su padre, Jim Moore, complicada.', 'Sirvió en Vietnam y falleció hace dos años.', 'Cuando era adolescente, las discusiones con su madre eran tan malas, Pink dice que una pelea se puso física y su madre se cayó por las escaleras.', 'Ahora llama a eso su único arrepentimiento en la vida.', 'Dijiste que eras el chico con el que otras mamás no querían que sus hijos jugaran.', '¿Por qué?', 'Yo era un punk.', 'Tenía una boca.', 'Lo era, tenía un chip en el hombro.', 'Básicamente, crecí en una casa donde todos los días mis padres se gritaban, tiraban cosas, se odiaban.', 'Y luego me metí en drogas.', 'Estaba vendiendo drogas.', 'Y luego me echaron de la casa.', 'Dejé la secundaria.', 'Eso fue fuera de lugar.', '¿Qué pasó en Acción de Gracias en 1995?', 'Acción de Gracias de 1995, estaba en una fiesta y tuve una sobredosis.', 'Yo estaba en, oh chico, éxtasis, polvo de ángel, cristal, todo tipo de cosas.', 'Y luego salí, hice demasiado.', 'Casi mueres.', 'Sí.', 'Dice que ese fue el fin de las drogas duras para ella.', 'Y semanas después consiguió su primer contrato discográfico como cantante principal en un grupo de chicas R&B.Pero no duraron mucho.', 'Así que cuando estás empezando, la industria parece como que te tienen yendo por un camino.', 'Te pintan con un cepillo R&B.Sí, firmé a LaFace Records.', 'Éramos las chicas blancas simbólicas en una etiqueta negra.', 'Me dijeron que tomara clases de etiqueta muy temprano.', 'Querían que aprendiera a usar vestidos y usar el tenedor correcto.', 'Cómo funciona eso.', 'Fui una vez, pero no funcionó.', '¿Qué no les gustó?', 'Creo que estaban tratando de convertirme en algo que no quería ser.', 'La imagen es todo en este negocio.', 'Usando su apodo de adolescente, Pink, se fue sola.', 'Y su primer álbum fue un éxito de doble platino R&B.Luego amplió su sonido para incluir el rock y el pop.', 'Y no tan sutilmente llamó a su próximo álbum, Miss Unda Stood.', 'Fue un éxito profesional, vendiendo 15 millones de copias en todo el mundo.', 'Dijiste que en el pasado se sentía como si nunca ganaras el concurso de popularidad entre tus compañeros.', '¿Qué quieres decir con eso?', 'Vendimos tres millones de entradas en los últimos seis meses, pero no te enteras a menos que te fueras.', 'Así que al final del día, ¿le doy a alguien que hable de mí?', 'Siempre y cuando la madre y la hija o el padre que está en la camiseta rosa, así como su hija y sus tres amigos tuvieron un tiempo fantástico, o la pareja gay que se unió y se sintió súper seguro en mi show porque nadie los interrumpió, eso es lo que realmente importa.', 'Y luego está esto.', 'Queríamos saber cómo lo hace, cantando boca abajo como una asmática nada menos.', 'Bueno, se necesitaron muchas clases de gimnasia infantil y sesiones de entrenamiento torturadas con su entrenador aéreo, Drea Weber.', 'Bien, apriete el estómago.', 'Bien, ¿listo?', 'Sé amable.', 'No cante.', 'Donde hay deseo, hay mucha cerveza, hay una llama, alguien está obligado a quemarse.', 'Sólo porque marises y medios van a morir, tienes que tener una pérdida.', 'No soy solo una cantante, soy una gimnasta.', 'Puedo hacer todo tipo de cosas.', 'Soy físico.', 'Este cuerpo, los músculos que asustan a la gente, es mi poder.', 'Es como, no como bien para verme bien, como bien para ir lejos, rápido y duro.', 'A 5\\'3\", ella es todo músculo y no cometer ningún error tan duro como parece.', 'Me doy cuenta de que el machete que siempre he llevado, este machete metafórico que siempre he llevado que me hizo un niño realmente difícil, es lo que me hace realmente bueno en lo que hice hoy.11.30 horas reunión privada Sala 5Y me convierte en un superviviente.', '¿Sientes que necesitabas ese borde duro, ese machete, para escalar tan lejos como has escalado en este negocio, particularmente?', 'Por supuesto.', 'Nunca conseguí un contrato discográfico porque era linda.', 'Conseguí un contrato discográfico porque era ardiente, tenía mucho que decir y tenía una voz.', 'Por lo tanto, estoy aliviado de no tener que caer de nuevo en una especie de belleza convencional y eso no tiene que ser lo mío y no tengo que mantener eso a medida que envejece.', 'No tengo que ser eso.', 'Puedo ser todo esto.', 'No necesitará un plan B pronto, pero como nos dijo a medianoche sobre una copa de vino en su camerino en Filadelfia, está planeando el próximo capítulo.', 'Es lo que haría cualquier artista amante de las lentejuelas que se respete a sí mismo, una residencia en Las Vegas.', 'Me gustaría tener el mejor programa que Vegas ha visto y creo que puedo.', 'Para que un artista como yo tenga un escenario que no tiene que viajar, Dios mío, puedes hacer tanto.', 'Así que, todos estos años, ¿cuál es la parte más difícil de tu trabajo ahora?', 'Supongo que sigo exigiendo cada vez más y más y más de mí mismo físicamente, emocionalmente, espiritualmente, vocalmente.', 'Quiero levantar la barra todo el tiempo y voy en contra del tiempo, ¿verdad?', '¿Cómo te mantienes fuera haciendo eso?', 'Me gusta ir en contra de las normas sociales cuando dicen que una mujer tiene que ir más despacio, hacerse más pequeña, ocupar menos espacio, calmarse.', 'No, por supuesto que no.', '¿Por qué?', '¿Quién dice, por qué no podemos montarlo hasta que las ruedas se caigan?', 'Es mi plan.', 'Ve detrás del escenario con Pink después de un concierto.', 'Vamos, sube.']\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 193)\n",
            " > after interpolation : torch.Size([1, 80, 289])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 271)\n",
            " > after interpolation : torch.Size([1, 80, 406])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 353)\n",
            " > after interpolation : torch.Size([1, 80, 529])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 28)\n",
            " > after interpolation : torch.Size([1, 80, 42])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 113)\n",
            " > after interpolation : torch.Size([1, 80, 169])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 112)\n",
            " > after interpolation : torch.Size([1, 80, 168])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 120)\n",
            " > after interpolation : torch.Size([1, 80, 180])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 71)\n",
            " > after interpolation : torch.Size([1, 80, 106])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 43)\n",
            " > after interpolation : torch.Size([1, 80, 64])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 125)\n",
            " > after interpolation : torch.Size([1, 80, 187])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 207)\n",
            " > after interpolation : torch.Size([1, 80, 310])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 73)\n",
            " > after interpolation : torch.Size([1, 80, 109])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 192)\n",
            " > after interpolation : torch.Size([1, 80, 288])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 261)\n",
            " > after interpolation : torch.Size([1, 80, 391])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 316)\n",
            " > after interpolation : torch.Size([1, 80, 474])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 57)\n",
            " > after interpolation : torch.Size([1, 80, 85])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 77)\n",
            " > after interpolation : torch.Size([1, 80, 115])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 146)\n",
            " > after interpolation : torch.Size([1, 80, 219])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 395)\n",
            " > after interpolation : torch.Size([1, 80, 592])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 440)\n",
            " > after interpolation : torch.Size([1, 80, 660])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 145)\n",
            " > after interpolation : torch.Size([1, 80, 217])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 89)\n",
            " > after interpolation : torch.Size([1, 80, 133])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 98)\n",
            " > after interpolation : torch.Size([1, 80, 147])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 234)\n",
            " > after interpolation : torch.Size([1, 80, 351])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 128)\n",
            " > after interpolation : torch.Size([1, 80, 192])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 206)\n",
            " > after interpolation : torch.Size([1, 80, 309])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 290)\n",
            " > after interpolation : torch.Size([1, 80, 435])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 345)\n",
            " > after interpolation : torch.Size([1, 80, 517])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 324)\n",
            " > after interpolation : torch.Size([1, 80, 486])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 202)\n",
            " > after interpolation : torch.Size([1, 80, 303])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 42)\n",
            " > after interpolation : torch.Size([1, 80, 63])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 379)\n",
            " > after interpolation : torch.Size([1, 80, 568])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 266)\n",
            " > after interpolation : torch.Size([1, 80, 399])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 443)\n",
            " > after interpolation : torch.Size([1, 80, 664])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 217)\n",
            " > after interpolation : torch.Size([1, 80, 325])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 186)\n",
            " > after interpolation : torch.Size([1, 80, 279])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 456)\n",
            " > after interpolation : torch.Size([1, 80, 684])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 408)\n",
            " > after interpolation : torch.Size([1, 80, 612])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 322)\n",
            " > after interpolation : torch.Size([1, 80, 483])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 445)\n",
            " > after interpolation : torch.Size([1, 80, 667])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 281)\n",
            " > after interpolation : torch.Size([1, 80, 421])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 168)\n",
            " > after interpolation : torch.Size([1, 80, 252])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 125)\n",
            " > after interpolation : torch.Size([1, 80, 187])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 142)\n",
            " > after interpolation : torch.Size([1, 80, 213])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 187)\n",
            " > after interpolation : torch.Size([1, 80, 280])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 444)\n",
            " > after interpolation : torch.Size([1, 80, 666])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 32)\n",
            " > after interpolation : torch.Size([1, 80, 48])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 164)\n",
            " > after interpolation : torch.Size([1, 80, 246])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 196)\n",
            " > after interpolation : torch.Size([1, 80, 294])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 248)\n",
            " > after interpolation : torch.Size([1, 80, 372])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 410)\n",
            " > after interpolation : torch.Size([1, 80, 615])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 102)\n",
            " > after interpolation : torch.Size([1, 80, 153])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 81)\n",
            " > after interpolation : torch.Size([1, 80, 121])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 81)\n",
            " > after interpolation : torch.Size([1, 80, 121])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 208)\n",
            " > after interpolation : torch.Size([1, 80, 312])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 44)\n",
            " > after interpolation : torch.Size([1, 80, 66])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 379)\n",
            " > after interpolation : torch.Size([1, 80, 568])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 39)\n",
            " > after interpolation : torch.Size([1, 80, 58])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 63)\n",
            " > after interpolation : torch.Size([1, 80, 94])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 122)\n",
            " > after interpolation : torch.Size([1, 80, 183])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 89)\n",
            " > after interpolation : torch.Size([1, 80, 133])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 83)\n",
            " > after interpolation : torch.Size([1, 80, 124])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 99)\n",
            " > after interpolation : torch.Size([1, 80, 148])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 53)\n",
            " > after interpolation : torch.Size([1, 80, 79])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 171)\n",
            " > after interpolation : torch.Size([1, 80, 256])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 195)\n",
            " > after interpolation : torch.Size([1, 80, 292])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 447)\n",
            " > after interpolation : torch.Size([1, 80, 670])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 121)\n",
            " > after interpolation : torch.Size([1, 80, 181])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 115)\n",
            " > after interpolation : torch.Size([1, 80, 172])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 28)\n",
            " > after interpolation : torch.Size([1, 80, 42])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 273)\n",
            " > after interpolation : torch.Size([1, 80, 409])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 200)\n",
            " > after interpolation : torch.Size([1, 80, 300])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 190)\n",
            " > after interpolation : torch.Size([1, 80, 285])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 233)\n",
            " > after interpolation : torch.Size([1, 80, 349])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 143)\n",
            " > after interpolation : torch.Size([1, 80, 214])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 175)\n",
            " > after interpolation : torch.Size([1, 80, 262])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 263)\n",
            " > after interpolation : torch.Size([1, 80, 394])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 52)\n",
            " > after interpolation : torch.Size([1, 80, 78])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 57)\n",
            " > after interpolation : torch.Size([1, 80, 85])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 124)\n",
            " > after interpolation : torch.Size([1, 80, 186])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 422)\n",
            " > after interpolation : torch.Size([1, 80, 633])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 89)\n",
            " > after interpolation : torch.Size([1, 80, 133])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 89)\n",
            " > after interpolation : torch.Size([1, 80, 133])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 87)\n",
            " > after interpolation : torch.Size([1, 80, 130])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 66)\n",
            " > after interpolation : torch.Size([1, 80, 99])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 79)\n",
            " > after interpolation : torch.Size([1, 80, 118])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 315)\n",
            " > after interpolation : torch.Size([1, 80, 472])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 383)\n",
            " > after interpolation : torch.Size([1, 80, 574])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 124)\n",
            " > after interpolation : torch.Size([1, 80, 186])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 52)\n",
            " > after interpolation : torch.Size([1, 80, 78])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 22)\n",
            " > after interpolation : torch.Size([1, 80, 33])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 133)\n",
            " > after interpolation : torch.Size([1, 80, 199])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 450)\n",
            " > after interpolation : torch.Size([1, 80, 675])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 306)\n",
            " > after interpolation : torch.Size([1, 80, 459])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 255)\n",
            " > after interpolation : torch.Size([1, 80, 382])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 222)\n",
            " > after interpolation : torch.Size([1, 80, 333])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 178)\n",
            " > after interpolation : torch.Size([1, 80, 267])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 229)\n",
            " > after interpolation : torch.Size([1, 80, 343])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 61)\n",
            " > after interpolation : torch.Size([1, 80, 91])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 124)\n",
            " > after interpolation : torch.Size([1, 80, 186])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 194)\n",
            " > after interpolation : torch.Size([1, 80, 291])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 107)\n",
            " > after interpolation : torch.Size([1, 80, 160])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 172)\n",
            " > after interpolation : torch.Size([1, 80, 258])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 333)\n",
            " > after interpolation : torch.Size([1, 80, 499])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 237)\n",
            " > after interpolation : torch.Size([1, 80, 355])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 299)\n",
            " > after interpolation : torch.Size([1, 80, 448])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 362)\n",
            " > after interpolation : torch.Size([1, 80, 543])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 341)\n",
            " > after interpolation : torch.Size([1, 80, 511])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 194)\n",
            " > after interpolation : torch.Size([1, 80, 291])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 62)\n",
            " > after interpolation : torch.Size([1, 80, 93])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 280)\n",
            " > after interpolation : torch.Size([1, 80, 420])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 443)\n",
            " > after interpolation : torch.Size([1, 80, 664])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 99)\n",
            " > after interpolation : torch.Size([1, 80, 148])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 44)\n",
            " > after interpolation : torch.Size([1, 80, 66])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 38)\n",
            " > after interpolation : torch.Size([1, 80, 57])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 44)\n",
            " > after interpolation : torch.Size([1, 80, 66])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 334)\n",
            " > after interpolation : torch.Size([1, 80, 501])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 277)\n",
            " > after interpolation : torch.Size([1, 80, 415])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 159)\n",
            " > after interpolation : torch.Size([1, 80, 238])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 109)\n",
            " > after interpolation : torch.Size([1, 80, 163])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 51)\n",
            " > after interpolation : torch.Size([1, 80, 76])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 239)\n",
            " > after interpolation : torch.Size([1, 80, 358])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 279)\n",
            " > after interpolation : torch.Size([1, 80, 418])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 318)\n",
            " > after interpolation : torch.Size([1, 80, 477])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 436)\n",
            " > after interpolation : torch.Size([1, 80, 654])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 45)\n",
            " > after interpolation : torch.Size([1, 80, 67])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 180)\n",
            " > after interpolation : torch.Size([1, 80, 270])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 348)\n",
            " > after interpolation : torch.Size([1, 80, 522])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 67)\n",
            " > after interpolation : torch.Size([1, 80, 100])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 62)\n",
            " > after interpolation : torch.Size([1, 80, 93])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 443)\n",
            " > after interpolation : torch.Size([1, 80, 664])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 246)\n",
            " > after interpolation : torch.Size([1, 80, 369])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 366)\n",
            " > after interpolation : torch.Size([1, 80, 549])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 296)\n",
            " > after interpolation : torch.Size([1, 80, 444])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 270)\n",
            " > after interpolation : torch.Size([1, 80, 405])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 79)\n",
            " > after interpolation : torch.Size([1, 80, 118])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 45)\n",
            " > after interpolation : torch.Size([1, 80, 67])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 40)\n",
            " > after interpolation : torch.Size([1, 80, 60])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 189)\n",
            " > after interpolation : torch.Size([1, 80, 283])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 49)\n",
            " > after interpolation : torch.Size([1, 80, 73])\n",
            " > Processing time: 445.632196187973\n",
            " > Real-time factor: 0.4885787575558936\n",
            " > Text splitted to sentences.\n",
            "['El general Mark Milley completó un mandato de cuatro años como presidente del Estado Mayor Conjunto, el oficial militar de más alto rango de la nación el 30 de septiembre.', 'Nos dijo que pasó la mayor parte de su tiempo trabajando para evitar un conflicto directo con Rusia y China, mientras que el país lo vio tener una pelea muy pública con el ex presidente Trump, el hombre que lo eligió para el trabajo.', 'El tiempo de Trump Milley al servicio del presidente Joe Biden tuvo sus propios desafíos, incluyendo la calamitosa retirada de Estados Unidos de Afganistán, así como proporcionar a Ucrania miles de millones de dólares en equipo militar estadounidense.', 'Unas horas antes de sentarnos con el general en el Pentágono, había tenido su última llamada telefónica con el comandante de las fuerzas armadas de Ucrania.', 'La historia continuará en un momento.', 'La contraofensiva que están llevando a cabo los ucranianos sigue en curso.', 'El progreso ha sido observado por muchas, muchas personas, es lento, pero es constante, y están progresando sobre la base del día a día.', 'Pero expulsando a 200.000 soldados rusos.', 'Muy difícil.', 'No es tarea fácil.', 'Muy duro.', 'Muy duro.', '¿Cuánto tiempo se va a ver así?', '¿Un año?', '¿Cinco años?', 'Bueno, no se puede poner un tiempo en él, pero va a ser un tiempo considerable, y va a ser largo y duro y muy sangriento.', 'Rusia ocupa 41.000 millas cuadradas de Ucrania.', 'La primera línea se extiende sobre la distancia entre Atlanta y Washington, D.C. En el Congreso de la semana pasada, los republicanos terminaron la conferenciante de Kevin McCarthy, y por ahora, más ayuda a Ucrania.', 'De acuerdo con la Casa Blanca de los $113 mil millones ya comprometidos, sólo queda suficiente para durar unos meses más.', 'Con todos los problemas que enfrentan los estadounidenses en casa, ¿por qué vale la pena?', 'Si Ucrania pierde, y Putin gana, creo que ciertamente aumentaría, si no duplicaría, su presupuesto de defensa en los próximos años, y aumentará la probabilidad de una gran guerra de poder en los próximos 10 a 15 años.', 'Creo que sería una situación muy peligrosa si Putin pudiera ganar.', 'Ucrania y Rusia obviamente es lo que nos impulsa a reunirnos hoy.', 'El presidente de los Jefes Conjuntos es el principal asesor militar del comandante en jefe, pero no manda tropas en batalla.', 'Estoy obligado, independientemente de las consecuencias, a dar mi consejo al presidente, pero ningún presidente está obligado a seguir ese consejo.', 'El pasado mes de agosto, el general Milley nos invitó a bordo de la Constitución del USS en Boston Harbor, no muy lejos de donde creció.', 'Con sólo militares en el mundo, esto jura no a un rey, a una reina, a un tirano, a un aspirante a tirano, o a un dictador, juramos una idea, la idea que es americana, y está encarnada en ese documento la Constitución, que establece nuestra forma de gobierno.', 'En 2021, el General Milley aconsejó al Presidente Biden que mantuviera 2.500 soldados en Kabul y sus alrededores.', 'En su lugar, el Sr.', 'Biden ordenó una retirada completa para poner fin a la guerra más larga de Estados Unidos después de 20 años.', 'El desastre que siguió será parte de ambos legados.', 'Paso por toda la retirada de Afganistán, un capítulo y verso todo el tiempo.', 'Ese fue un fracaso estratégico para los Estados Unidos.', 'El enemigo ocupó la capital del país que usted apoyaba.', 'Así que para mí, eso duele.', 'Duele mucho.', 'Pero no importa el dolor que sienta o cualquiera más, nada se acerca al dolor de los que fueron asesinados.', 'Para aquellos que sirvieron en Afganistán durante dos décadas y perdieron familiares y amigos y se preguntan, ¿vale la pena?', 'Esa es siempre la pregunta, ¿verdad?', 'Así que 2.461 murieron en acción por el enemigo en Afganistán durante 20 años.', '¿Valió la pena?', 'Pero no puedo responder eso por otra gente.', 'Este es un negocio duro en el que estamos, este negocio militar.', 'Es implacable, el crisol del combate es implacable.', 'La gente muere, pierde los brazos, pierde las piernas.', 'Es una vida increíblemente difícil.', '¿Pero vale la pena?', 'Mira a tu alrededor.', 'Hazte la pregunta.', 'Para mí, he respondido muchas veces y es por eso que me quedo en uniforme y es por eso que mantengo mi juramento.', 'Su compromiso con ese juramento sería puesto a prueba y cuestionado por Donald Trump.', 'Mientras que su relación comenzó con palabras amables, después de la insurrección del 6 de enero, los dos hombres no volvieron a hablar.', 'Sus distanciamientos públicos comenzaron en la primavera de 2020 cuando las protestas por la justicia racial, algunas violentas, se extendieron por todo el país, incluyendo a Washington D.C. Tal vez más que cualquier otro presidente en el papel que se ha convertido en encasillado en política y posiblemente amenazas a la Constitución.', '¿Qué has aprendido de eso?', 'Creo que es importante mantener tu Estrella Norte, que es la Constitución.', 'Los militares no sólo somos apolíticos, no somos partidistas.', 'No puedes elegir bandos.1 de junio de 2020.¿Fue un punto de inflexión para usted como presidente?', 'Creo que sí, sí.', 'Me di cuenta de que entraron en un campo de minas político y no debería haberlo hecho.', 'Está hablando del día en que el presidente Trump amenazó con invocar la Ley de Insurrección y desplegar al Ejército de Estados Unidos para sofocar los disturbios en las calles de Estados Unidos.', 'En la noche del 1 de junio, después de que los manifestantes cerca de la Casa Blanca fueran removidos por la fuerza, el presidente Millie vestido con fatigas de batalla, se unió al presidente Trump y miembros de su gabinete en una marcha a través de la Plaza Lafayette a la Iglesia de San Juan, donde Trump posó para fotografías.', 'Diez días después, el General Millie pidió disculpas en un discurso a los graduados de la Universidad de Defensa Nacional.', 'Mi presencia en ese momento y en ese entorno creó una percepción de los militares involucrados en la política interna.', 'Como oficial encargado y uniformado, fue un error del que he aprendido.', 'Es raro que un presidente se disculpe públicamente.', 'Bueno, ya sabes, crecí aquí en Boston.', 'Soy irlandés, católico, y mi madre y mi padre me enseñaron que cuando cometes un error, lo admites.', 'Tienes una confesión que decir, 10 Aves Marías y un Alfother.', 'Todo el mundo comete errores y la clave es cómo lidiar con un error.', 'Después de que te disculparas, el ex presidente Trump dijo que te ahogaste como un perro.', 'Sí, no voy a comentar nada de lo que el ex presidente haya dicho o no.', 'Millie nos dijo que estaba tan desilusionado con las acciones del ex presidente, que casi renunció.', 'En cambio, según el ex secretario de Defensa Mark Esper, él y el general hicieron un pacto para proteger a los militares de convertirse en politizados o mal utilizados.', 'También se ha informado que usted pasó varios días, varios borradores de cartas de renuncia.', 'Me impresionó mucho el que se publicó.', 'En la que usted dijo al presidente, es mi profunda creencia que usted está arruinando el orden internacional, causando daños significativos a nuestro país en el extranjero que fue luchado tan duramente por la mayor generación en 1945.', 'Esa generación ha luchado contra el fascismo, ha luchado contra el nazismo, ha luchado contra el extremismo.', 'Ahora es obvio para mí que no entiendes ese orden mundial.', '¿No crees que Donald Trump entendió por qué se peleó la Segunda Guerra Mundial?', 'No sé qué entendió el ex presidente Trump sobre la Segunda Guerra Mundial ni nada más.', 'Puedo decirles que de 1914 a 1945, 150 millones de personas o sus alrededores fueron masacradas en la conducción de la Gran Guerra del Poder.', 'En 1945, Estados Unidos tomó la iniciativa y redactó un conjunto de reglas que gobiernan el mundo hasta el día de hoy.', 'Esas normas están sometidas a tensión internacional.', 'Putin es un ataque frontal directo contra esas reglas.', 'China está tratando de revisar esas normas en su propio beneficio.', 'Pero eso es una cosa para decir que China está amenazando ese orden mundial y Rusia está amenazando ese orden mundial.', 'Para decir que el comandante en jefe, Donald Trump, estaba arruinando el orden internacional y causando daños significativos, ¿qué vio que le causó escribir eso?', 'Diría que va a ser más que entrar en Lafayette Square en uniforme.', 'Hay una gran variedad de iniciativas en curso.', 'Uno de ellos, por supuesto, estaba con nuestras tropas fuera de la OTAN.Se trata de iniciativas que ponen en peligro la situación.', 'Creo que Estados Unidos está haciendo rodar el mundo.', 'Ahora, eso es lo contrario de lo que mis padres y otros 18 millones fueron el uniforme para la Segunda Guerra Mundial para derrotar.', 'El general Milley no sólo venera a la mejor generación.', 'Fue criado por ella.', 'Su padre era un médico de la marina que sirvió en la campaña del Pacífico, incluyendo en la batalla de Iwo Jima.', 'Su madre se unió a la reserva naval para trabajar como enfermera.', 'Bueno, este era y sigue siendo un barrio muy patriótico.', 'Después de la guerra, se establecieron en Winchester, una pequeña ciudad al norte de Boston.', 'Casi todos los padres y madres que estuvieron aquí eran veteranos de la Segunda Guerra Mundial de un tipo u otro.', 'Toda la cuadra, de verdad.', 'Mucho el uno del otro.100 por ciento.', 'Interesante.', 'No hay oficiales.', 'Estos fueron alistados al 100%.', 'Y también tenían sus propias opiniones de oficiales.', 'Incluyendo a tus padres.', 'Oh, sí.', 'Durante la escuela secundaria, fue reclutado para jugar hockey sobre hielo en la Universidad de Princeton y decidió unirse al Cuerpo de Entrenamiento de Oficiales de Reserva, o ROTC.Después de graduarse en 1980, se convirtió en paracaidista y sirvió en fuerzas especiales.', 'Hizo una gira de combate en Irak y tres en Afganistán.', 'Este pasado mayo, regresó a Princeton para encargar la clase ROTC graduada.', 'Felicitaciones a cada uno de ustedes.', 'Y se interesó especialmente en algunos de los jóvenes oficiales cuyas habilidades lingüísticas están actualmente en alta demanda.', 'Hablo chino, señor.', 'Los chinos son muy, muy importantes para nosotros.', '¿Alguien más habla chino?', 'Whoa.', 'Uno, dos, tres, cuatro, cinco.', 'Si hablas chino, si no te importa, me gustaría saber tus nombres.', 'Y veremos a dónde os lleva la vida.', 'Nosotros, los Estados Unidos, tenemos que tomar el desafío, el desafío militar de China extraordinariamente en serio.', '¿Qué te preocupa que las comunicaciones militares con los militares no estén ocurriendo ahora mismo con China?', 'Sí, creo que tendríamos que establecer eso.', 'Los tuvimos por un período de tiempo y luego se fueron.', 'Por lo tanto, los canales de comunicación son importantes para reducir la tensión en tiempos de crisis.', 'El general Milley dice que realizó un total de cinco llamadas con sus homólogos militares chinos durante las administraciones de Trump y Biden.', 'Pero fueron sus dos últimas llamadas durante los últimos meses de la presidencia de Trump las que llamaron la atención de la prensa, el Congreso y el propio ex presidente.', '¿Por qué pensó que era tan importante llamar a su homólogo militar chino después de los ataques del 6 de enero?', 'Eso es un ejemplo de desescalación.', 'Así que había indicios claros de que los chinos estaban muy preocupados por lo que estaban observando aquí en los Estados Unidos.', '¿Viste algún movimiento?', '¿El movimiento del equipo militar chino?', 'No soportaré nada clasificado.', 'Así que no discutiré exactamente lo que vimos o no vimos o lo que oímos o no oímos.', 'Sólo diría que había indicios claros de que los chinos están muy preocupados.', 'El presidente Trump dijo recientemente que sus tratos con China eran tan atroces que en tiempos pasados el castigo habría sido la muerte.', 'Así es, dijo eso.', 'Antes del registro, ¿había algo inapropiado o traicionero en las llamadas que hizo a China?', 'Por supuesto que no, cero, ninguno.', 'Y ahora están autorizados, están coordinados.', 'El Congreso lo sabe.', 'Hemos respondido a estas preguntas varias veces por escrito.', '¿Estaba dando a los chinos información sobre pensar en el presidente de los Estados Unidos?', 'La conversación específica fue, creo, de acuerdo con la intención del Secretario de Defensa, que era asegurarse de que los chinos supieran que no íbamos a atacarlos.', '¿Por qué pensaban los chinos que Estados Unidos bajo el entonces presidente Trump iba a atacarlos?', 'Los chinos estaban preocupados por lo que comúnmente se refiere en el idioma inglés, como una sorpresa de octubre, wag-the-dog tipo de cosas.11.30 horas reunión privada Sala 5Estaban equivocados, no nos estaban leyendo bien.', 'Mira, el presidente Trump no iba a atacar a China, y necesitaban saberlo.', 'China, Rusia y la guerra en Ucrania son ahora el problema de su sucesor, el general Charles Q de la Fuerza Aérea.', 'Brown Jr.', 'También hay áreas de preocupación más cercanas a casa.11.45 horasEl año pasado, el ejército perdió sus números de reclutamiento por 15.000 soldados, el peor déficit en décadas.', 'La confianza en el ejército estadounidense se encuentra en su nivel más bajo en dos décadas.', '¿Tienes alguna responsabilidad personal por eso?', 'Por supuesto.', 'Creo que, como líder de los militares, los militares uniformados, creo que soy parte de eso, sin duda.', 'Creo que el paseo de la Casa Blanca a la Iglesia de San Juan, creo que ayudó a crear algo de eso.', 'Creo que la retirada del Afganistán ayudó a crear algo de eso.', 'Pero también diría que el ejército de los Estados Unidos sigue siendo una de las instituciones más respetadas de los Estados Unidos por un largo margen.', 'Sabes, creo que nos hemos deslizado un poco, y creo que tenemos que mejorar en eso.', 'El general Mark Milley sobre el futuro de la guerra.', '¿Hace más probable la guerra?', 'Podría.', 'A 60minutosovertime.com.']\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 112)\n",
            " > after interpolation : torch.Size([1, 80, 168])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 245)\n",
            " > after interpolation : torch.Size([1, 80, 367])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 205)\n",
            " > after interpolation : torch.Size([1, 80, 307])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 47)\n",
            " > after interpolation : torch.Size([1, 80, 70])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 67)\n",
            " > after interpolation : torch.Size([1, 80, 100])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 31)\n",
            " > after interpolation : torch.Size([1, 80, 46])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 31)\n",
            " > after interpolation : torch.Size([1, 80, 46])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 448)\n",
            " > after interpolation : torch.Size([1, 80, 672])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 194)\n",
            " > after interpolation : torch.Size([1, 80, 291])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 297)\n",
            " > after interpolation : torch.Size([1, 80, 445])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 219)\n",
            " > after interpolation : torch.Size([1, 80, 328])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 285)\n",
            " > after interpolation : torch.Size([1, 80, 427])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 433)\n",
            " > after interpolation : torch.Size([1, 80, 649])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 90)\n",
            " > after interpolation : torch.Size([1, 80, 135])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 352)\n",
            " > after interpolation : torch.Size([1, 80, 528])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 171)\n",
            " > after interpolation : torch.Size([1, 80, 256])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 281)\n",
            " > after interpolation : torch.Size([1, 80, 421])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 209)\n",
            " > after interpolation : torch.Size([1, 80, 313])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 209)\n",
            " > after interpolation : torch.Size([1, 80, 313])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 124)\n",
            " > after interpolation : torch.Size([1, 80, 186])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 48)\n",
            " > after interpolation : torch.Size([1, 80, 72])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 308)\n",
            " > after interpolation : torch.Size([1, 80, 462])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 392)\n",
            " > after interpolation : torch.Size([1, 80, 588])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 103)\n",
            " > after interpolation : torch.Size([1, 80, 154])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 360)\n",
            " > after interpolation : torch.Size([1, 80, 540])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 140)\n",
            " > after interpolation : torch.Size([1, 80, 210])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 232)\n",
            " > after interpolation : torch.Size([1, 80, 348])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 189)\n",
            " > after interpolation : torch.Size([1, 80, 283])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 179)\n",
            " > after interpolation : torch.Size([1, 80, 268])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 148)\n",
            " > after interpolation : torch.Size([1, 80, 222])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 70)\n",
            " > after interpolation : torch.Size([1, 80, 105])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 57)\n",
            " > after interpolation : torch.Size([1, 80, 85])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 390)\n",
            " > after interpolation : torch.Size([1, 80, 585])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 286)\n",
            " > after interpolation : torch.Size([1, 80, 429])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 480)\n",
            " > after interpolation : torch.Size([1, 80, 720])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 240)\n",
            " > after interpolation : torch.Size([1, 80, 360])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 223)\n",
            " > after interpolation : torch.Size([1, 80, 334])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 321)\n",
            " > after interpolation : torch.Size([1, 80, 481])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 53)\n",
            " > after interpolation : torch.Size([1, 80, 79])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 289)\n",
            " > after interpolation : torch.Size([1, 80, 433])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 373)\n",
            " > after interpolation : torch.Size([1, 80, 559])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 404)\n",
            " > after interpolation : torch.Size([1, 80, 606])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 241)\n",
            " > after interpolation : torch.Size([1, 80, 361])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 177)\n",
            " > after interpolation : torch.Size([1, 80, 265])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 175)\n",
            " > after interpolation : torch.Size([1, 80, 262])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 374)\n",
            " > after interpolation : torch.Size([1, 80, 561])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 216)\n",
            " > after interpolation : torch.Size([1, 80, 324])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 201)\n",
            " > after interpolation : torch.Size([1, 80, 301])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 299)\n",
            " > after interpolation : torch.Size([1, 80, 448])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 243)\n",
            " > after interpolation : torch.Size([1, 80, 364])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 309)\n",
            " > after interpolation : torch.Size([1, 80, 463])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 339)\n",
            " > after interpolation : torch.Size([1, 80, 508])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 115)\n",
            " > after interpolation : torch.Size([1, 80, 172])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 372)\n",
            " > after interpolation : torch.Size([1, 80, 558])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 174)\n",
            " > after interpolation : torch.Size([1, 80, 261])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 258)\n",
            " > after interpolation : torch.Size([1, 80, 387])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 175)\n",
            " > after interpolation : torch.Size([1, 80, 262])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 178)\n",
            " > after interpolation : torch.Size([1, 80, 267])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 228)\n",
            " > after interpolation : torch.Size([1, 80, 342])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 421)\n",
            " > after interpolation : torch.Size([1, 80, 631])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 226)\n",
            " > after interpolation : torch.Size([1, 80, 339])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 150)\n",
            " > after interpolation : torch.Size([1, 80, 225])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 394)\n",
            " > after interpolation : torch.Size([1, 80, 591])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 163)\n",
            " > after interpolation : torch.Size([1, 80, 244])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 185)\n",
            " > after interpolation : torch.Size([1, 80, 277])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 68)\n",
            " > after interpolation : torch.Size([1, 80, 102])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 406)\n",
            " > after interpolation : torch.Size([1, 80, 609])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 201)\n",
            " > after interpolation : torch.Size([1, 80, 301])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 224)\n",
            " > after interpolation : torch.Size([1, 80, 336])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 321)\n",
            " > after interpolation : torch.Size([1, 80, 481])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 417)\n",
            " > after interpolation : torch.Size([1, 80, 625])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 107)\n",
            " > after interpolation : torch.Size([1, 80, 160])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 200)\n",
            " > after interpolation : torch.Size([1, 80, 300])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 51)\n",
            " > after interpolation : torch.Size([1, 80, 76])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 64)\n",
            " > after interpolation : torch.Size([1, 80, 96])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 131)\n",
            " > after interpolation : torch.Size([1, 80, 196])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 178)\n",
            " > after interpolation : torch.Size([1, 80, 267])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 83)\n",
            " > after interpolation : torch.Size([1, 80, 124])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 27)\n",
            " > after interpolation : torch.Size([1, 80, 40])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 182)\n",
            " > after interpolation : torch.Size([1, 80, 273])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 253)\n",
            " > after interpolation : torch.Size([1, 80, 379])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 137)\n",
            " > after interpolation : torch.Size([1, 80, 205])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 481)\n",
            " > after interpolation : torch.Size([1, 80, 721])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 61)\n",
            " > after interpolation : torch.Size([1, 80, 91])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 179)\n",
            " > after interpolation : torch.Size([1, 80, 268])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 20)\n",
            " > after interpolation : torch.Size([1, 80, 30])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 131)\n",
            " > after interpolation : torch.Size([1, 80, 196])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 220)\n",
            " > after interpolation : torch.Size([1, 80, 330])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 112)\n",
            " > after interpolation : torch.Size([1, 80, 168])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 415)\n",
            " > after interpolation : torch.Size([1, 80, 622])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 161)\n",
            " > after interpolation : torch.Size([1, 80, 241])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 148)\n",
            " > after interpolation : torch.Size([1, 80, 222])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 352)\n",
            " > after interpolation : torch.Size([1, 80, 528])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 462)\n",
            " > after interpolation : torch.Size([1, 80, 693])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 114)\n",
            " > after interpolation : torch.Size([1, 80, 171])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 439)\n",
            " > after interpolation : torch.Size([1, 80, 658])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 103)\n",
            " > after interpolation : torch.Size([1, 80, 154])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 283)\n",
            " > after interpolation : torch.Size([1, 80, 424])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 283)\n",
            " > after interpolation : torch.Size([1, 80, 424])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 452)\n",
            " > after interpolation : torch.Size([1, 80, 678])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 63)\n",
            " > after interpolation : torch.Size([1, 80, 94])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 314)\n",
            " > after interpolation : torch.Size([1, 80, 471])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 113)\n",
            " > after interpolation : torch.Size([1, 80, 169])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 176)\n",
            " > after interpolation : torch.Size([1, 80, 264])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 65)\n",
            " > after interpolation : torch.Size([1, 80, 97])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 191)\n",
            " > after interpolation : torch.Size([1, 80, 286])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 347)\n",
            " > after interpolation : torch.Size([1, 80, 520])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 396)\n",
            " > after interpolation : torch.Size([1, 80, 594])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 56)\n",
            " > after interpolation : torch.Size([1, 80, 84])\n",
            "   > Decoder stopped with `max_decoder_steps` 500\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 500)\n",
            " > after interpolation : torch.Size([1, 80, 750])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 319)\n",
            " > after interpolation : torch.Size([1, 80, 478])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 45)\n",
            " > after interpolation : torch.Size([1, 80, 67])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 410)\n",
            " > after interpolation : torch.Size([1, 80, 615])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 316)\n",
            " > after interpolation : torch.Size([1, 80, 474])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 193)\n",
            " > after interpolation : torch.Size([1, 80, 289])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 482)\n",
            " > after interpolation : torch.Size([1, 80, 723])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 308)\n",
            " > after interpolation : torch.Size([1, 80, 462])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 169)\n",
            " > after interpolation : torch.Size([1, 80, 253])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 2)\n",
            " > after interpolation : torch.Size([1, 80, 3])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 30)\n",
            " > after interpolation : torch.Size([1, 80, 45])\n",
            " > interpolating tts model output.\n",
            " > before interpolation : (80, 107)\n",
            " > after interpolation : torch.Size([1, 80, 160])\n",
            " > Processing time: 549.4488847255707\n",
            " > Real-time factor: 0.5185901762856906\n"
          ]
        }
      ]
    }
  ]
}